{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-7a35025f58a1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7a35025f58a1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Das Bitte in die entsprechenden Funktionen packen, danke!\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Das Bitte in die entsprechenden Funktionen packen, danke!\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import glob, os\n",
    "#import math\n",
    "#import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing \n",
    "\n",
    "Aus deiner Arbeit Bilder und Theorie \n",
    "Schön Lehrveranstung 20 - 30 min Frontal schön.\n",
    "\n",
    "aber die Themen die Später kommen acuh später mit Bildern und ein bisschen Text zeigen\n",
    "Wenn passen Code ding dazwischen setzen (hier villeich direkt spacy verwenden)\n",
    "\n",
    "![Was ist NLP](<https://s2.qwant.com/thumbr/0x380/c/e/10c54c87272bdae830c4378495ff38b0e0af52906cdb0b0f6836eb4ad110f0/NLP-word-cloud-e1432237783661.jpg?u=https%3A%2F%2Fwww.thoughtmodels.com%2Fwp-content%2Fuploads%2F2016%2F06%2FNLP-word-cloud-e1432237783661.jpg&q=0&b=1&p=0&a=1>)\n",
    "\n",
    "![NLP Random](<https://s2.qwant.com/thumbr/0x380/e/5/527af4afd005a161f69ca22c8788d5e033bc518839c429f55d950bd917adf8/maxresdefault.jpg?u=https%3A%2F%2Fi.ytimg.com%2Fvi%2FFLZvOKSCkxY%2Fmaxresdefault.jpg&q=0&b=1&p=0&a=1>)\n",
    "\n",
    "\n",
    "## Spacy Beispiel --- Entity Recognition ---\n",
    "\n",
    "ANN etc ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition mit spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import de_core_news_sm\n",
    "nlp = de_core_news_sm.load()\n",
    "\n",
    "text = 'Stephan Becker fährt mit dem Auto zur TDWI nach München.'\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "sentences = [x for x in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Stephan Becker\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " fährt mit dem Auto zur \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    TDWI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " nach \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    München\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(sentences[0].string), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"3-0\" class=\"displacy\" width=\"1250\" height=\"317.0\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Stephan</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">Becker</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">fährt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">mit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">dem</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Auto</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">zur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">TDWI</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">nach</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">München.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,122.0 160.0,122.0 160.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pnc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-1\" stroke-width=\"2px\" d=\"M190,182.0 C190,122.0 280.0,122.0 280.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,184.0 L182,172.0 198,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-2\" stroke-width=\"2px\" d=\"M310,182.0 C310,122.0 400.0,122.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,184.0 L408.0,172.0 392.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-3\" stroke-width=\"2px\" d=\"M550,182.0 C550,122.0 640.0,122.0 640.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550,184.0 L542,172.0 558,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-4\" stroke-width=\"2px\" d=\"M430,182.0 C430,62.0 645.0,62.0 645.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M645.0,184.0 L653.0,172.0 637.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-5\" stroke-width=\"2px\" d=\"M310,182.0 C310,2.0 770.0,2.0 770.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,184.0 L778.0,172.0 762.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-6\" stroke-width=\"2px\" d=\"M790,182.0 C790,122.0 880.0,122.0 880.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880.0,184.0 L888.0,172.0 872.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-7\" stroke-width=\"2px\" d=\"M910,182.0 C910,122.0 1000.0,122.0 1000.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mnr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1000.0,184.0 L1008.0,172.0 992.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3-0-8\" stroke-width=\"2px\" d=\"M1030,182.0 C1030,122.0 1120.0,122.0 1120.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120.0,184.0 L1128.0,172.0 1112.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp((sentences[0].string)), style='dep', jupyter = True, options = {'distance': 120})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsmöglichkeiten?\n",
    "\n",
    "-> z.B. zur Anonymisierung von Personen in Texten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Stephan Becker fährt mit dem Auto zur TDWI nach München.'\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "typeList = []\n",
    "censored = []\n",
    "for word in doc:\n",
    "    if word.ent_type_ == 'PER' and len(word) > 1:\n",
    "        cens = 'X'*5\n",
    "        censored.append(cens)\n",
    "    else:\n",
    "        censored.append(word.text)\n",
    "#Fancy Beispiel \n",
    "#Tolle output Graphik "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['XXXXX', 'XXXXX', 'fährt', 'mit', 'dem', 'Auto', 'zur', 'TDWI', 'nach', 'München', '.']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(censored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wo bin ich Übersicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents(fqn :str):\n",
    "    import glob, os\n",
    "    documents = {}\n",
    "    \n",
    "    for file in glob.glob(fqn):\n",
    "\n",
    "        filename = open(file, \"r\", encoding='cp1252')\n",
    "        text = str(filename.readlines())\n",
    "\n",
    "        path = os.path.basename(file)\n",
    "        extension = os.path.splitext(file)[1]\n",
    "        filename, extension = path.split('.')\n",
    "\n",
    "        documents[filename] = text\n",
    "            \n",
    "    return(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen des Dokumenten Korpus\n",
    "documents = read_documents(\"./Artikel/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dokument_1 = 'Das Auto fährt schnell. Ein Auto ist kein Motorrad.'\n",
    "Dokument_2 = 'Der Zug fährt schneller als das Auto'\n",
    "Dokument_3 = 'Ein Flugzeug fliegt'\n",
    "\n",
    "beispiel = {}\n",
    "beispiel['Dokument_1'] = Dokument_1\n",
    "beispiel['Dokument_2'] = Dokument_2\n",
    "beispiel['Dokument_3'] = Dokument_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wo bin ich Übersicht\n",
    "\n",
    "Zeig doch gleich mal zuerst was passiert wenn man das nicht macht!!\n",
    "\n",
    "Und dann kommst du mit der Lösung!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw = documents.get('BMW setzt noch einen drauf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"['Für alle, denen der mächtige X5 nicht groß genug ist, hat BMW jetzt den X7 im Angebot. Bald sogar mit einem neuen V8. \\\\n', 'Als sich BMW mit dem X5 vor mehr als 20 Jahren ins Segment der SUV wagte, war das noch eine mittlere Sensation. Heute besetzen die Münchner vom X1 an jede Ziffer aufsteigend, und von Mai an ist erst bei der 7 Schluss. Bei 84.300 Euro beginnt dann der Einstieg in die Welt der wahren Full-Size-SUV. Mit einer Länge von 5,15 Meter ist der X7 23 Zentimeter länger als der schon stattliche X5.\\\\n', 'Dabei sei das Riesen-SUV nicht einfach ein verlängerter X5, lässt BMW wissen. Zwar sei die Plattform bis zur B-Säule gleich, aber sämtliche Karosserieteile seien verschieden, mit Ausnahme der Außenspiegelkappen. Außerdem sei die Windschutzscheibe gleich, gibt BMW zu. Nun, alle X7 haben drei Sitzreihen, Allradantrieb, eine Achtgang-Automatik und Luftfederung. Gebaut werden sie auf einem Band zusammen mit X5 und dem „Coupé“ X6 in Spartanburg, South Carolina. Das X7-Basismodell treibt ein Sechszylinder-Diesel mit drei Liter Hubraum und 265 PS an. Die Variante mit gleich großem Sechszylinder-Benziner bietet 340 PS und kostet 86.300 Euro. Das Spitzenmodell M50d holt aus den drei Litern 400 PS und verlangt nach 109.900 Euro.\\\\n', '\\\\n', 'Wert legt BMW vor allem auf den Langstrecken- und somit auf den Reisekomfort. Mit auf große Fahrt können bis zu sieben Personen, allerdings ist dann der noch verbleibende Kofferraum mit 326 Liter Fassungsvermögen schmal. Aber an eine Anhängerkupplung dürfen bis zu 3,5 Tonnen Last.\\\\n', 'Als Fünfsitzer genutzt, bietet der BMW Raum für 750 Liter Gepäck, maximal passen rechnerisch gar 2120 Liter hinein. Dann darf man allerdings nicht die beiden Einzelsitze für die mittlere Reihe bestellt haben (660 Euro extra), diese lassen sich nicht umlegen, sondern nur vorschieben. Alle Sitzgelegenheiten werden elektrisch bewegt, wie auch die zweigeteilte Heckklappe und das Glasdach, das ebenfalls zum Lieferumfang gehört. Sitzen kann man überall sehr gut, sogar in der letzten Reihe ist noch passabel Platz. Allerdings muss man für den Einstieg schon gelenkig sein. Das Armaturenbrett-Layout unterscheidet sich kaum vom unlängst erneuerten X5, alles ist digital. Das Ausstattungsniveau ist generell höher als im X5. Dort kostet beispielsweise die Luftfederung Aufpreis.\\\\n', 'Die drei Motoren sind die gleichen wie im X5, die Verbrauchswerte sind aufgrund der höheren Masse etwas schlechter. Wobei die nach Norm 10,5 Liter für den Benziner und die 7,3 oder 8,0 Liter für die beiden Diesel gewiss nur auf dem Papier Bestand haben. Die jeweiligen Höchstgeschwindigkeiten betragen 227, 245 und 250 km/h.\\\\n', 'Ein 4,4-Liter-V8-Motor mit 462 PS ist nicht für Deutschland vorgesehen, sondern vor allem für Amerika gedacht, einen der Hauptmärkte. Allerdings sei eine neue V8-Maschine – der Effizienz wegen wahrscheinlich mit weniger Hubraum – für Europa in Vorbereitung, heißt es. Eine elektrifizierte Variante (Plug-in-Hybrid) sei noch nicht definitiv beschlossen. Das „Schaun mer mal“ der Verantwortlichen darf aber als starkes Indiz für einen Plug-in gewertet werden. Schließlich ist auch für den X5 eine solche Motorenkombination in Vorbereitung. Dort wird der Sechszylinder-Benzinmotor mit einer Elektromaschine kombiniert, die Systemleistung beträgt 394 PS, das maximale Drehmoment 600 Newtonmeter. Die drei Motoren für den X7 bieten 450, 620 sowie 760 Nm auf. Die höheren Werte gelten für die Diesel.Was Multimedia, Konnektivität und Assistenten angeht, zieht der X7 so ziemlich alle Register. Wie für den X5 gibt es auch ein Offroad-Paket, das 1900 Euro zusätzlich kostet. Dazu gehören unter anderem Verstärkungen am Unterboden, vier spezielle Fahrprogramme und eine mechanische Differentialsperre. Auf ersten Probefahrten beeindruckte der X7 mit seiner Ruhe und Souveränität. In Europa stören wird nicht nur die Größe an sich, sondern auch der Wendekreis von 13 Metern.']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw = bmw.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\"['Für\", 'alle,', 'denen', 'der', 'mächtige', 'X5', 'nicht', 'groß', 'genug', 'ist,', 'hat', 'BMW', 'jetzt', 'den', 'X7', 'im', 'Angebot.', 'Bald', 'sogar', 'mit', 'einem', 'neuen', 'V8.', \"\\\\n',\", \"'Als\", 'sich', 'BMW', 'mit', 'dem', 'X5', 'vor', 'mehr', 'als', '20', 'Jahren', 'ins', 'Segment', 'der', 'SUV', 'wagte,', 'war', 'das', 'noch', 'eine', 'mittlere', 'Sensation.', 'Heute', 'besetzen', 'die', 'Münchner', 'vom', 'X1', 'an', 'jede', 'Ziffer', 'aufsteigend,', 'und', 'von', 'Mai', 'an', 'ist', 'erst', 'bei', 'der', '7', 'Schluss.', 'Bei', '84.300', 'Euro', 'beginnt', 'dann', 'der', 'Einstieg', 'in', 'die', 'Welt', 'der', 'wahren', 'Full-Size-SUV.', 'Mit', 'einer', 'Länge', 'von', '5,15', 'Meter', 'ist', 'der', 'X7', '23', 'Zentimeter', 'länger', 'als', 'der', 'schon', 'stattliche', \"X5.\\\\n',\", \"'Dabei\", 'sei', 'das', 'Riesen-SUV', 'nicht', 'einfach', 'ein', 'verlängerter', 'X5,', 'lässt', 'BMW', 'wissen.', 'Zwar', 'sei', 'die', 'Plattform', 'bis', 'zur', 'B-Säule', 'gleich,', 'aber', 'sämtliche', 'Karosserieteile', 'seien', 'verschieden,', 'mit', 'Ausnahme', 'der', 'Außenspiegelkappen.', 'Außerdem', 'sei', 'die', 'Windschutzscheibe', 'gleich,', 'gibt', 'BMW', 'zu.', 'Nun,', 'alle', 'X7', 'haben', 'drei', 'Sitzreihen,', 'Allradantrieb,', 'eine', 'Achtgang-Automatik', 'und', 'Luftfederung.', 'Gebaut', 'werden', 'sie', 'auf', 'einem', 'Band', 'zusammen', 'mit', 'X5', 'und', 'dem', '„Coupé“', 'X6', 'in', 'Spartanburg,', 'South', 'Carolina.', 'Das', 'X7-Basismodell', 'treibt', 'ein', 'Sechszylinder-Diesel', 'mit', 'drei', 'Liter', 'Hubraum', 'und', '265', 'PS', 'an.', 'Die', 'Variante', 'mit', 'gleich', 'großem', 'Sechszylinder-Benziner', 'bietet', '340', 'PS', 'und', 'kostet', '86.300', 'Euro.', 'Das', 'Spitzenmodell', 'M50d', 'holt', 'aus', 'den', 'drei', 'Litern', '400', 'PS', 'und', 'verlangt', 'nach', '109.900', \"Euro.\\\\n',\", \"'\\\\n',\", \"'Wert\", 'legt', 'BMW', 'vor', 'allem', 'auf', 'den', 'Langstrecken-', 'und', 'somit', 'auf', 'den', 'Reisekomfort.', 'Mit', 'auf', 'große', 'Fahrt', 'können', 'bis', 'zu', 'sieben', 'Personen,', 'allerdings', 'ist', 'dann', 'der', 'noch', 'verbleibende', 'Kofferraum', 'mit', '326', 'Liter', 'Fassungsvermögen', 'schmal.', 'Aber', 'an', 'eine', 'Anhängerkupplung', 'dürfen', 'bis', 'zu', '3,5', 'Tonnen', \"Last.\\\\n',\", \"'Als\", 'Fünfsitzer', 'genutzt,', 'bietet', 'der', 'BMW', 'Raum', 'für', '750', 'Liter', 'Gepäck,', 'maximal', 'passen', 'rechnerisch', 'gar', '2120', 'Liter', 'hinein.', 'Dann', 'darf', 'man', 'allerdings', 'nicht', 'die', 'beiden', 'Einzelsitze', 'für', 'die', 'mittlere', 'Reihe', 'bestellt', 'haben', '(660', 'Euro', 'extra),', 'diese', 'lassen', 'sich', 'nicht', 'umlegen,', 'sondern', 'nur', 'vorschieben.', 'Alle', 'Sitzgelegenheiten', 'werden', 'elektrisch', 'bewegt,', 'wie', 'auch', 'die', 'zweigeteilte', 'Heckklappe', 'und', 'das', 'Glasdach,', 'das', 'ebenfalls', 'zum', 'Lieferumfang', 'gehört.', 'Sitzen', 'kann', 'man', 'überall', 'sehr', 'gut,', 'sogar', 'in', 'der', 'letzten', 'Reihe', 'ist', 'noch', 'passabel', 'Platz.', 'Allerdings', 'muss', 'man', 'für', 'den', 'Einstieg', 'schon', 'gelenkig', 'sein.', 'Das', 'Armaturenbrett-Layout', 'unterscheidet', 'sich', 'kaum', 'vom', 'unlängst', 'erneuerten', 'X5,', 'alles', 'ist', 'digital.', 'Das', 'Ausstattungsniveau', 'ist', 'generell', 'höher', 'als', 'im', 'X5.', 'Dort', 'kostet', 'beispielsweise', 'die', 'Luftfederung', \"Aufpreis.\\\\n',\", \"'Die\", 'drei', 'Motoren', 'sind', 'die', 'gleichen', 'wie', 'im', 'X5,', 'die', 'Verbrauchswerte', 'sind', 'aufgrund', 'der', 'höheren', 'Masse', 'etwas', 'schlechter.', 'Wobei', 'die', 'nach', 'Norm', '10,5', 'Liter', 'für', 'den', 'Benziner', 'und', 'die', '7,3', 'oder', '8,0', 'Liter', 'für', 'die', 'beiden', 'Diesel', 'gewiss', 'nur', 'auf', 'dem', 'Papier', 'Bestand', 'haben.', 'Die', 'jeweiligen', 'Höchstgeschwindigkeiten', 'betragen', '227,', '245', 'und', '250', \"km/h.\\\\n',\", \"'Ein\", '4,4-Liter-V8-Motor', 'mit', '462', 'PS', 'ist', 'nicht', 'für', 'Deutschland', 'vorgesehen,', 'sondern', 'vor', 'allem', 'für', 'Amerika', 'gedacht,', 'einen', 'der', 'Hauptmärkte.', 'Allerdings', 'sei', 'eine', 'neue', 'V8-Maschine', '–', 'der', 'Effizienz', 'wegen', 'wahrscheinlich', 'mit', 'weniger', 'Hubraum', '–', 'für', 'Europa', 'in', 'Vorbereitung,', 'heißt', 'es.', 'Eine', 'elektrifizierte', 'Variante', '(Plug-in-Hybrid)', 'sei', 'noch', 'nicht', 'definitiv', 'beschlossen.', 'Das', '„Schaun', 'mer', 'mal“', 'der', 'Verantwortlichen', 'darf', 'aber', 'als', 'starkes', 'Indiz', 'für', 'einen', 'Plug-in', 'gewertet', 'werden.', 'Schließlich', 'ist', 'auch', 'für', 'den', 'X5', 'eine', 'solche', 'Motorenkombination', 'in', 'Vorbereitung.', 'Dort', 'wird', 'der', 'Sechszylinder-Benzinmotor', 'mit', 'einer', 'Elektromaschine', 'kombiniert,', 'die', 'Systemleistung', 'beträgt', '394', 'PS,', 'das', 'maximale', 'Drehmoment', '600', 'Newtonmeter.', 'Die', 'drei', 'Motoren', 'für', 'den', 'X7', 'bieten', '450,', '620', 'sowie', '760', 'Nm', 'auf.', 'Die', 'höheren', 'Werte', 'gelten', 'für', 'die', 'Diesel.Was', 'Multimedia,', 'Konnektivität', 'und', 'Assistenten', 'angeht,', 'zieht', 'der', 'X7', 'so', 'ziemlich', 'alle', 'Register.', 'Wie', 'für', 'den', 'X5', 'gibt', 'es', 'auch', 'ein', 'Offroad-Paket,', 'das', '1900', 'Euro', 'zusätzlich', 'kostet.', 'Dazu', 'gehören', 'unter', 'anderem', 'Verstärkungen', 'am', 'Unterboden,', 'vier', 'spezielle', 'Fahrprogramme', 'und', 'eine', 'mechanische', 'Differentialsperre.', 'Auf', 'ersten', 'Probefahrten', 'beeindruckte', 'der', 'X7', 'mit', 'seiner', 'Ruhe', 'und', 'Souveränität.', 'In', 'Europa', 'stören', 'wird', 'nicht', 'nur', 'die', 'Größe', 'an', 'sich,', 'sondern', 'auch', 'der', 'Wendekreis', 'von', '13', \"Metern.']\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Angebot.'     \"\\\\n',\"     \"Euro.\\\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(documents):\n",
    "    tokenized = {}\n",
    "    \n",
    "    for doc in documents:\n",
    "        \n",
    "        document = documents.get(doc)\n",
    "        punctuations = ['(',')',';',':','[',']','{','}',',','.','-','``',\"''\",'!','\\\"','§','$','%','&','?','@','+','–','~','*','#','\\'','\\\\n','\\\\','„','“']\n",
    "        cleaned = []\n",
    "\n",
    "        token = document.split(' ')\n",
    "\n",
    "        for t in token:\n",
    "            temp = t\n",
    "            for p in punctuations:\n",
    "                if p in t:\n",
    "                    temp = temp.replace(p, '')\n",
    "            cleaned.append(temp.lower())\n",
    "            \n",
    "        tokenized[doc] = cleaned\n",
    "        #bei kMeans: str(cleaned)\n",
    "\n",
    "    return(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokinisieren der Corpi\n",
    "tokenized = tokenizer(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dokument_1': ['das',\n",
       "  'auto',\n",
       "  'fährt',\n",
       "  'schnell',\n",
       "  'ein',\n",
       "  'auto',\n",
       "  'ist',\n",
       "  'kein',\n",
       "  'motorrad'],\n",
       " 'Dokument_2': ['der', 'zug', 'fährt', 'schneller', 'als', 'das', 'auto'],\n",
       " 'Dokument_3': ['ein', 'flugzeug', 'fliegt']}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_tokenized = tokenizer(beispiel)\n",
    "beispiel_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw = tokenized.get('BMW setzt noch einen drauf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['für', 'alle', 'denen', 'der', 'mächtige', 'x5', 'nicht', 'groß', 'genug', 'ist', 'hat', 'bmw', 'jetzt', 'den', 'x7', 'im', 'angebot', 'bald', 'sogar', 'mit', 'einem', 'neuen', 'v8', '', 'als', 'sich', 'bmw', 'mit', 'dem', 'x5', 'vor', 'mehr', 'als', '20', 'jahren', 'ins', 'segment', 'der', 'suv', 'wagte', 'war', 'das', 'noch', 'eine', 'mittlere', 'sensation', 'heute', 'besetzen', 'die', 'münchner', 'vom', 'x1', 'an', 'jede', 'ziffer', 'aufsteigend', 'und', 'von', 'mai', 'an', 'ist', 'erst', 'bei', 'der', '7', 'schluss', 'bei', '84300', 'euro', 'beginnt', 'dann', 'der', 'einstieg', 'in', 'die', 'welt', 'der', 'wahren', 'fullsizesuv', 'mit', 'einer', 'länge', 'von', '515', 'meter', 'ist', 'der', 'x7', '23', 'zentimeter', 'länger', 'als', 'der', 'schon', 'stattliche', 'x5', 'dabei', 'sei', 'das', 'riesensuv', 'nicht', 'einfach', 'ein', 'verlängerter', 'x5', 'lässt', 'bmw', 'wissen', 'zwar', 'sei', 'die', 'plattform', 'bis', 'zur', 'bsäule', 'gleich', 'aber', 'sämtliche', 'karosserieteile', 'seien', 'verschieden', 'mit', 'ausnahme', 'der', 'außenspiegelkappen', 'außerdem', 'sei', 'die', 'windschutzscheibe', 'gleich', 'gibt', 'bmw', 'zu', 'nun', 'alle', 'x7', 'haben', 'drei', 'sitzreihen', 'allradantrieb', 'eine', 'achtgangautomatik', 'und', 'luftfederung', 'gebaut', 'werden', 'sie', 'auf', 'einem', 'band', 'zusammen', 'mit', 'x5', 'und', 'dem', 'coupé', 'x6', 'in', 'spartanburg', 'south', 'carolina', 'das', 'x7basismodell', 'treibt', 'ein', 'sechszylinderdiesel', 'mit', 'drei', 'liter', 'hubraum', 'und', '265', 'ps', 'an', 'die', 'variante', 'mit', 'gleich', 'großem', 'sechszylinderbenziner', 'bietet', '340', 'ps', 'und', 'kostet', '86300', 'euro', 'das', 'spitzenmodell', 'm50d', 'holt', 'aus', 'den', 'drei', 'litern', '400', 'ps', 'und', 'verlangt', 'nach', '109900', 'euro', '', 'wert', 'legt', 'bmw', 'vor', 'allem', 'auf', 'den', 'langstrecken', 'und', 'somit', 'auf', 'den', 'reisekomfort', 'mit', 'auf', 'große', 'fahrt', 'können', 'bis', 'zu', 'sieben', 'personen', 'allerdings', 'ist', 'dann', 'der', 'noch', 'verbleibende', 'kofferraum', 'mit', '326', 'liter', 'fassungsvermögen', 'schmal', 'aber', 'an', 'eine', 'anhängerkupplung', 'dürfen', 'bis', 'zu', '35', 'tonnen', 'last', 'als', 'fünfsitzer', 'genutzt', 'bietet', 'der', 'bmw', 'raum', 'für', '750', 'liter', 'gepäck', 'maximal', 'passen', 'rechnerisch', 'gar', '2120', 'liter', 'hinein', 'dann', 'darf', 'man', 'allerdings', 'nicht', 'die', 'beiden', 'einzelsitze', 'für', 'die', 'mittlere', 'reihe', 'bestellt', 'haben', '660', 'euro', 'extra', 'diese', 'lassen', 'sich', 'nicht', 'umlegen', 'sondern', 'nur', 'vorschieben', 'alle', 'sitzgelegenheiten', 'werden', 'elektrisch', 'bewegt', 'wie', 'auch', 'die', 'zweigeteilte', 'heckklappe', 'und', 'das', 'glasdach', 'das', 'ebenfalls', 'zum', 'lieferumfang', 'gehört', 'sitzen', 'kann', 'man', 'überall', 'sehr', 'gut', 'sogar', 'in', 'der', 'letzten', 'reihe', 'ist', 'noch', 'passabel', 'platz', 'allerdings', 'muss', 'man', 'für', 'den', 'einstieg', 'schon', 'gelenkig', 'sein', 'das', 'armaturenbrettlayout', 'unterscheidet', 'sich', 'kaum', 'vom', 'unlängst', 'erneuerten', 'x5', 'alles', 'ist', 'digital', 'das', 'ausstattungsniveau', 'ist', 'generell', 'höher', 'als', 'im', 'x5', 'dort', 'kostet', 'beispielsweise', 'die', 'luftfederung', 'aufpreis', 'die', 'drei', 'motoren', 'sind', 'die', 'gleichen', 'wie', 'im', 'x5', 'die', 'verbrauchswerte', 'sind', 'aufgrund', 'der', 'höheren', 'masse', 'etwas', 'schlechter', 'wobei', 'die', 'nach', 'norm', '105', 'liter', 'für', 'den', 'benziner', 'und', 'die', '73', 'oder', '80', 'liter', 'für', 'die', 'beiden', 'diesel', 'gewiss', 'nur', 'auf', 'dem', 'papier', 'bestand', 'haben', 'die', 'jeweiligen', 'höchstgeschwindigkeiten', 'betragen', '227', '245', 'und', '250', 'km/h', 'ein', '44literv8motor', 'mit', '462', 'ps', 'ist', 'nicht', 'für', 'deutschland', 'vorgesehen', 'sondern', 'vor', 'allem', 'für', 'amerika', 'gedacht', 'einen', 'der', 'hauptmärkte', 'allerdings', 'sei', 'eine', 'neue', 'v8maschine', '', 'der', 'effizienz', 'wegen', 'wahrscheinlich', 'mit', 'weniger', 'hubraum', '', 'für', 'europa', 'in', 'vorbereitung', 'heißt', 'es', 'eine', 'elektrifizierte', 'variante', 'pluginhybrid', 'sei', 'noch', 'nicht', 'definitiv', 'beschlossen', 'das', 'schaun', 'mer', 'mal', 'der', 'verantwortlichen', 'darf', 'aber', 'als', 'starkes', 'indiz', 'für', 'einen', 'plugin', 'gewertet', 'werden', 'schließlich', 'ist', 'auch', 'für', 'den', 'x5', 'eine', 'solche', 'motorenkombination', 'in', 'vorbereitung', 'dort', 'wird', 'der', 'sechszylinderbenzinmotor', 'mit', 'einer', 'elektromaschine', 'kombiniert', 'die', 'systemleistung', 'beträgt', '394', 'ps', 'das', 'maximale', 'drehmoment', '600', 'newtonmeter', 'die', 'drei', 'motoren', 'für', 'den', 'x7', 'bieten', '450', '620', 'sowie', '760', 'nm', 'auf', 'die', 'höheren', 'werte', 'gelten', 'für', 'die', 'dieselwas', 'multimedia', 'konnektivität', 'und', 'assistenten', 'angeht', 'zieht', 'der', 'x7', 'so', 'ziemlich', 'alle', 'register', 'wie', 'für', 'den', 'x5', 'gibt', 'es', 'auch', 'ein', 'offroadpaket', 'das', '1900', 'euro', 'zusätzlich', 'kostet', 'dazu', 'gehören', 'unter', 'anderem', 'verstärkungen', 'am', 'unterboden', 'vier', 'spezielle', 'fahrprogramme', 'und', 'eine', 'mechanische', 'differentialsperre', 'auf', 'ersten', 'probefahrten', 'beeindruckte', 'der', 'x7', 'mit', 'seiner', 'ruhe', 'und', 'souveränität', 'in', 'europa', 'stören', 'wird', 'nicht', 'nur', 'die', 'größe', 'an', 'sich', 'sondern', 'auch', 'der', 'wendekreis', 'von', '13', 'metern']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords = Blacklist\n",
    "#### Startwords = Whitelist\n",
    "\n",
    "\n",
    "Text Ohne Stopwörter formulieren und Lesen\n",
    "\n",
    "\n",
    "Textbeispiel \n",
    "Nullnummer im Nachholspiel\n",
    "Viel Kampf, keine Tore: <span style=\"color:red\">Im</span> Nachholspiel der zweiten Bundesliga trennen sich Greuther Fürth und Dynamo Dresden remis. Für Aufregung sorgt lediglich ein Pfostentreffer. \n",
    "Die SpVgg Greuther Fürth hat Dynamo Dresden in der 2. Fußball-Bundesliga auf Distanz gehalten. Im Nachholspiel des 25. Spieltags trennten sich beide Mannschaften am Donnerstagabend mit 0:0. Vor 12.590 Zuschauern wäre ein Sieg der Fürther nach einer Leistungssteigerung in der zweiten Hälfte nicht unverdient gewesen. Die Sachsen blieben aber auch in der vierten Partie unter ihrem neuen Coach Cristian Fiel ungeschlagen. In der Tabelle liegen die Fürther mit 34 Zählern weiter zwei Punkte vor Dynamo im gesicherten Mittelfeld.\n",
    "Die Neuansetzung der Partie vom 25. Spieltag war notwendig geworden, nachdem das Spiel wegen orkanartiger Windböen und daraus resultierender Sicherheitsbedenken abgesagt wurde.\n",
    "\n",
    "Die Fürther hatten erhebliche Probleme im Spielaufbau, da die Dresdner den Rivalen schon in der eigenen Hälfte attackierten. Die Franken traten nach der Pause entschlossener auf und setzten die Dresdner früher unter Druck. In der 61. Minute scheiterte Kapitän Marco Caligiuri am linken Pfosten. Auf der Gegenseite strich ein Schuss von Dresdens Erich Berko (79.) am linken Außenpfosten vorbei.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(tokenized):\n",
    "    stopwords = [\"ab\",\"aber\",\"ach\",\"acht\",\"achte\",\"achten\",\"achter\",\"achtes\",\"ag\",\"alle\",\"allein\",\"allem\",\"allen\",\"aller\",\"allerdings\",\"alles\",\"allgemeinen\",\"als\",\"also\",\"am\",\"an\",\"ander\",\"andere\",\"anderem\",\"anderen\",\"anderer\",\"anderes\",\"anderm\",\"andern\",\"anderr\",\"anders\",\"au\",\"auch\",\"auf\",\"aus\",\"ausser\",\"ausserdem\",\"außer\",\"außerdem\",\"b\",\"bald\",\"bei\",\"beide\",\"beiden\",\"beim\",\"beispiel\",\"bekannt\",\"bereits\",\"besonders\",\"besser\",\"besten\",\"bin\",\"bis\",\"bisher\",\"bist\",\"c\",\"d\",\"d.h\",\"da\",\"dabei\",\"dadurch\",\"dafür\",\"dagegen\",\"daher\",\"dahin\",\"dahinter\",\"damals\",\"damit\",\"danach\",\"daneben\",\"dank\",\"dann\",\"daran\",\"darauf\",\"daraus\",\"darf\",\"darfst\",\"darin\",\"darum\",\"darunter\",\"darüber\",\"das\",\"dasein\",\"daselbst\",\"dass\",\"dasselbe\",\"davon\",\"davor\",\"dazu\",\"dazwischen\",\"daß\",\"dein\",\"deine\",\"deinem\",\"deinen\",\"deiner\",\"deines\",\"dem\",\"dementsprechend\",\"demgegenüber\",\"demgemäss\",\"demgemäß\",\"demselben\",\"demzufolge\",\"den\",\"denen\",\"denn\",\"denselben\",\"der\",\"deren\",\"derer\",\"derjenige\",\"derjenigen\",\"dermassen\",\"dermaßen\",\"derselbe\",\"derselben\",\"des\",\"deshalb\",\"desselben\",\"dessen\",\"deswegen\",\"dich\",\"die\",\"diejenige\",\"diejenigen\",\"dies\",\"diese\",\"dieselbe\",\"dieselben\",\"diesem\",\"diesen\",\"dieser\",\"dieses\",\"dir\",\"doch\",\"dort\",\"drei\",\"drin\",\"dritte\",\"dritten\",\"dritter\",\"drittes\",\"du\",\"durch\",\"durchaus\",\"durfte\",\"durften\",\"dürfen\",\"dürft\",\"e\",\"eben\",\"ebenso\",\"ehrlich\",\"ei\",\"ei,\",\"eigen\",\"eigene\",\"eigenen\",\"eigener\",\"eigenes\",\"ein\",\"einander\",\"eine\",\"einem\",\"einen\",\"einer\",\"eines\",\"einig\",\"einige\",\"einigem\",\"einigen\",\"einiger\",\"einiges\",\"einmal\",\"eins\",\"elf\",\"en\",\"ende\",\"endlich\",\"entweder\",\"er\",\"ernst\",\"erst\",\"erste\",\"ersten\",\"erster\",\"erstes\",\"es\",\"etwa\",\"etwas\",\"euch\",\"euer\",\"eure\",\"eurem\",\"euren\",\"eurer\",\"eures\",\"f\",\"folgende\",\"früher\",\"fünf\",\"fünfte\",\"fünften\",\"fünfter\",\"fünftes\",\"für\",\"g\",\"gab\",\"ganz\",\"ganze\",\"ganzen\",\"ganzer\",\"ganzes\",\"gar\",\"gedurft\",\"gegen\",\"gegenüber\",\"gehabt\",\"gehen\",\"geht\",\"gekannt\",\"gekonnt\",\"gemacht\",\"gemocht\",\"gemusst\",\"genug\",\"gerade\",\"gern\",\"gesagt\",\"geschweige\",\"gewesen\",\"gewollt\",\"geworden\",\"gibt\",\"ging\",\"gleich\",\"gott\",\"gross\",\"grosse\",\"grossen\",\"grosser\",\"grosses\",\"groß\",\"große\",\"großen\",\"großer\",\"großes\",\"gut\",\"gute\",\"guter\",\"gutes\",\"h\",\"hab\",\"habe\",\"haben\",\"habt\",\"hast\",\"hat\",\"hatte\",\"hatten\",\"hattest\",\"hattet\",\"heisst\",\"her\",\"heute\",\"hier\",\"hin\",\"hinter\",\"hoch\",\"hätte\",\"hätten\",\"i\",\"ich\",\"ihm\",\"ihn\",\"ihnen\",\"ihr\",\"ihre\",\"ihrem\",\"ihren\",\"ihrer\",\"ihres\",\"im\",\"immer\",\"in\",\"indem\",\"infolgedessen\",\"ins\",\"irgend\",\"ist\",\"j\",\"ja\",\"jahr\",\"jahre\",\"jahren\",\"je\",\"jede\",\"jedem\",\"jeden\",\"jeder\",\"jedermann\",\"jedermanns\",\"jedes\",\"jedoch\",\"jemand\",\"jemandem\",\"jemanden\",\"jene\",\"jenem\",\"jenen\",\"jener\",\"jenes\",\"jetzt\",\"k\",\"kam\",\"kann\",\"kannst\",\"kaum\",\"kein\",\"keine\",\"keinem\",\"keinen\",\"keiner\",\"keines\",\"kleine\",\"kleinen\",\"kleiner\",\"kleines\",\"kommen\",\"kommt\",\"konnte\",\"konnten\",\"kurz\",\"können\",\"könnt\",\"könnte\",\"l\",\"lang\",\"lange\",\"leicht\",\"leide\",\"lieber\",\"los\",\"m\",\"machen\",\"macht\",\"machte\",\"mag\",\"magst\",\"mahn\",\"mal\",\"man\",\"manche\",\"manchem\",\"manchen\",\"mancher\",\"manches\",\"mann\",\"mehr\",\"mein\",\"meine\",\"meinem\",\"meinen\",\"meiner\",\"meines\",\"mensch\",\"menschen\",\"mich\",\"mir\",\"mit\",\"mittel\",\"mochte\",\"mochten\",\"morgen\",\"muss\",\"musst\",\"musste\",\"mussten\",\"muß\",\"mußt\",\"möchte\",\"mögen\",\"möglich\",\"mögt\",\"müssen\",\"müsst\",\"müßt\",\"n\",\"na\",\"nach\",\"nachdem\",\"nahm\",\"natürlich\",\"neben\",\"nein\",\"neue\",\"neuen\",\"neun\",\"neunte\",\"neunten\",\"neunter\",\"neuntes\",\"nicht\",\"nichts\",\"nie\",\"niemand\",\"niemandem\",\"niemanden\",\"noch\",\"nun\",\"nur\",\"o\",\"ob\",\"oben\",\"oder\",\"offen\",\"oft\",\"ohne\",\"ordnung\",\"p\",\"q\",\"r\",\"recht\",\"rechte\",\"rechten\",\"rechter\",\"rechtes\",\"richtig\",\"rund\",\"s\",\"sa\",\"sache\",\"sagt\",\"sagte\",\"sah\",\"satt\",\"schlecht\",\"schluss\",\"schon\",\"sechs\",\"sechste\",\"sechsten\",\"sechster\",\"sechstes\",\"sehr\",\"sei\",\"seid\",\"seien\",\"sein\",\"seine\",\"seinem\",\"seinen\",\"seiner\",\"seines\",\"seit\",\"seitdem\",\"selbst\",\"sich\",\"sie\",\"sieben\",\"siebente\",\"siebenten\",\"siebenter\",\"siebentes\",\"sind\",\"so\",\"solang\",\"solche\",\"solchem\",\"solchen\",\"solcher\",\"solches\",\"soll\",\"sollen\",\"sollst\",\"sollt\",\"sollte\",\"sollten\",\"sondern\",\"sonst\",\"soweit\",\"sowie\",\"später\",\"startseite\",\"statt\",\"steht\",\"suche\",\"t\",\"tag\",\"tage\",\"tagen\",\"tat\",\"teil\",\"tel\",\"tritt\",\"trotzdem\",\"tun\",\"u\",\"uhr\",\"um\",\"und\",\"und?\",\"uns\",\"unse\",\"unsem\",\"unsen\",\"unser\",\"unsere\",\"unserer\",\"unses\",\"unter\",\"v\",\"vergangenen\",\"viel\",\"viele\",\"vielem\",\"vielen\",\"vielleicht\",\"vier\",\"vierte\",\"vierten\",\"vierter\",\"viertes\",\"vom\",\"von\",\"vor\",\"w\",\"wahr?\",\"wann\",\"war\",\"waren\",\"warst\",\"wart\",\"warum\",\"was\",\"weg\",\"wegen\",\"weil\",\"weit\",\"weiter\",\"weitere\",\"weiteren\",\"weiteres\",\"welche\",\"welchem\",\"welchen\",\"welcher\",\"welches\",\"wem\",\"wen\",\"wenig\",\"wenige\",\"weniger\",\"weniges\",\"wenigstens\",\"wenn\",\"wer\",\"werde\",\"werden\",\"werdet\",\"weshalb\",\"wessen\",\"wie\",\"wieder\",\"wieso\",\"will\",\"willst\",\"wir\",\"wird\",\"wirklich\",\"wirst\",\"wissen\",\"wo\",\"woher\",\"wohin\",\"wohl\",\"wollen\",\"wollt\",\"wollte\",\"wollten\",\"worden\",\"wurde\",\"wurden\",\"während\",\"währenddem\",\"währenddessen\",\"wäre\",\"würde\",\"würden\",\"x\",\"y\",\"z\",\"z.b\",\"zehn\",\"zehnte\",\"zehnten\",\"zehnter\",\"zehntes\",\"zeit\",\"zu\",\"zuerst\",\"zugleich\",\"zum\",\"zunächst\",\"zur\",\"zurück\",\"zusammen\",\"zwanzig\",\"zwar\",\"zwei\",\"zweite\",\"zweiten\",\"zweiter\",\"zweites\",\"zwischen\",\"zwölf\",\"über\",\"überhaupt\",\"übrigens\"]\n",
    "    \n",
    "    removed = {}\n",
    "    \n",
    "    for doc in tokenized:\n",
    "        document = tokenized.get(doc)\n",
    "        no_stopwords = [token for token in document if not token in stopwords]\n",
    "        removed[doc] = no_stopwords\n",
    "    \n",
    "    return(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsRemoved = stopwords(tokenized)\n",
    "#stopwordsRemoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dokument_1': ['auto', 'fährt', 'schnell', 'auto', 'motorrad'],\n",
       " 'Dokument_2': ['zug', 'fährt', 'schneller', 'auto'],\n",
       " 'Dokument_3': ['flugzeug', 'fliegt']}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_stopwords = stopwords(beispiel_tokenized)\n",
    "beispiel_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmw = stopwordsRemoved.get('BMW setzt noch einen drauf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['mächtige', 'x5', 'bmw', 'x7', 'angebot', 'sogar', 'v8', '', 'bmw', 'x5', '20', 'segment', 'suv', 'wagte', 'mittlere', 'sensation', 'besetzen', 'münchner', 'x1', 'ziffer', 'aufsteigend', 'mai', '7', '84300', 'euro', 'beginnt', 'einstieg', 'welt', 'wahren', 'fullsizesuv', 'länge', '515', 'meter', 'x7', '23', 'zentimeter', 'länger', 'stattliche', 'x5', 'riesensuv', 'einfach', 'verlängerter', 'x5', 'lässt', 'bmw', 'plattform', 'bsäule', 'sämtliche', 'karosserieteile', 'verschieden', 'ausnahme', 'außenspiegelkappen', 'windschutzscheibe', 'bmw', 'x7', 'sitzreihen', 'allradantrieb', 'achtgangautomatik', 'luftfederung', 'gebaut', 'band', 'x5', 'coupé', 'x6', 'spartanburg', 'south', 'carolina', 'x7basismodell', 'treibt', 'sechszylinderdiesel', 'liter', 'hubraum', '265', 'ps', 'variante', 'großem', 'sechszylinderbenziner', 'bietet', '340', 'ps', 'kostet', '86300', 'euro', 'spitzenmodell', 'm50d', 'holt', 'litern', '400', 'ps', 'verlangt', '109900', 'euro', '', 'wert', 'legt', 'bmw', 'langstrecken', 'somit', 'reisekomfort', 'fahrt', 'personen', 'verbleibende', 'kofferraum', '326', 'liter', 'fassungsvermögen', 'schmal', 'anhängerkupplung', '35', 'tonnen', 'last', 'fünfsitzer', 'genutzt', 'bietet', 'bmw', 'raum', '750', 'liter', 'gepäck', 'maximal', 'passen', 'rechnerisch', '2120', 'liter', 'hinein', 'einzelsitze', 'mittlere', 'reihe', 'bestellt', '660', 'euro', 'extra', 'lassen', 'umlegen', 'vorschieben', 'sitzgelegenheiten', 'elektrisch', 'bewegt', 'zweigeteilte', 'heckklappe', 'glasdach', 'ebenfalls', 'lieferumfang', 'gehört', 'sitzen', 'überall', 'sogar', 'letzten', 'reihe', 'passabel', 'platz', 'einstieg', 'gelenkig', 'armaturenbrettlayout', 'unterscheidet', 'unlängst', 'erneuerten', 'x5', 'digital', 'ausstattungsniveau', 'generell', 'höher', 'x5', 'kostet', 'beispielsweise', 'luftfederung', 'aufpreis', 'motoren', 'gleichen', 'x5', 'verbrauchswerte', 'aufgrund', 'höheren', 'masse', 'schlechter', 'wobei', 'norm', '105', 'liter', 'benziner', '73', '80', 'liter', 'diesel', 'gewiss', 'papier', 'bestand', 'jeweiligen', 'höchstgeschwindigkeiten', 'betragen', '227', '245', '250', 'km/h', '44literv8motor', '462', 'ps', 'deutschland', 'vorgesehen', 'amerika', 'gedacht', 'hauptmärkte', 'v8maschine', '', 'effizienz', 'wahrscheinlich', 'hubraum', '', 'europa', 'vorbereitung', 'heißt', 'elektrifizierte', 'variante', 'pluginhybrid', 'definitiv', 'beschlossen', 'schaun', 'mer', 'verantwortlichen', 'starkes', 'indiz', 'plugin', 'gewertet', 'schließlich', 'x5', 'motorenkombination', 'vorbereitung', 'sechszylinderbenzinmotor', 'elektromaschine', 'kombiniert', 'systemleistung', 'beträgt', '394', 'ps', 'maximale', 'drehmoment', '600', 'newtonmeter', 'motoren', 'x7', 'bieten', '450', '620', '760', 'nm', 'höheren', 'werte', 'gelten', 'dieselwas', 'multimedia', 'konnektivität', 'assistenten', 'angeht', 'zieht', 'x7', 'ziemlich', 'register', 'x5', 'offroadpaket', '1900', 'euro', 'zusätzlich', 'kostet', 'gehören', 'verstärkungen', 'unterboden', 'spezielle', 'fahrprogramme', 'mechanische', 'differentialsperre', 'probefahrten', 'beeindruckte', 'x7', 'ruhe', 'souveränität', 'europa', 'stören', 'größe', 'wendekreis', '13', 'metern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(documents):\n",
    "    import json\n",
    "    with open('./SentimentAnalysis/positive.json') as positive:  \n",
    "        positiveWords = json.load(positive)\n",
    "    with open('./SentimentAnalysis/negative.json') as negative:  \n",
    "        negativeWords = json.load(negative)\n",
    "    \n",
    "    for doc in documents:\n",
    "        \n",
    "        trackP = []\n",
    "        trackN = []\n",
    "        \n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        text = documents.get(doc)\n",
    "        for token in text:\n",
    "            if token in positiveWords:\n",
    "                trackP.append(token)\n",
    "                positive += 1\n",
    "            elif token in negativeWords:\n",
    "                trackN.append(token)\n",
    "                negative += 1\n",
    "        # Ich würde das hier durch alle Worte im Dokument ersetzen! summe = alle Worte\n",
    "        summe = positive + negative\n",
    "        if positive > negative:\n",
    "            print(\"Der Artikel '\" + doc + \"' ist überwiegend positiv (\" + str(round((positive/summe)*100, 2)) + \"%)\")\n",
    "        elif negative > positive:\n",
    "            print(\"Der Artikel '\" + doc + \"' ist überwiegend negativ (\" + str(round((negative/summe)*100, 2)) + \"%)\")\n",
    "        elif positive == negative:\n",
    "            print(\"Der Artikel '\" + doc + \"' ist neutral\")\n",
    "        #print(trackP)\n",
    "        #print(trackN)\n",
    "        print('___________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Artikel 'Zweite Bundesliga' ist überwiegend negativ (62.5%)\n",
      "___________________________________\n",
      "Der Artikel 'Joachim Löw und die Nationalelf' ist überwiegend positiv (60.0%)\n",
      "___________________________________\n",
      "Der Artikel 'Konkurrenz für Netflix' ist überwiegend positiv (80.77%)\n",
      "___________________________________\n",
      "Der Artikel 'Blitz und Schatten' ist überwiegend positiv (83.33%)\n",
      "___________________________________\n",
      "Der Artikel 'Ladematte AirPower' ist überwiegend negativ (75.0%)\n",
      "___________________________________\n",
      "Der Artikel 'Weißes Haus rechnet mit Schließung der Grenze zu Mexiko' ist überwiegend positiv (53.33%)\n",
      "___________________________________\n",
      "Der Artikel 'Was Kim kann, kann Trump auch' ist überwiegend positiv (100.0%)\n",
      "___________________________________\n",
      "Der Artikel 'Dramatischer Liverpool-Sieg durch spätes Eigentor' ist überwiegend positiv (83.33%)\n",
      "___________________________________\n",
      "Der Artikel 'Hollywood-Stars präsentieren' ist überwiegend positiv (91.67%)\n",
      "___________________________________\n",
      "Der Artikel 'Tesla im Fahrtest' ist überwiegend positiv (73.53%)\n",
      "___________________________________\n",
      "Der Artikel 'Lebensrettende Massnahmen für Apple TV' ist überwiegend positiv (75.0%)\n",
      "___________________________________\n",
      "Der Artikel 'Der Vorwurf eines unerwünschten Kusses' ist neutral\n",
      "___________________________________\n",
      "Der Artikel 'Natixis im Gespräch' ist überwiegend positiv (71.43%)\n",
      "___________________________________\n",
      "Der Artikel 'Mittelklasse, nur nicht beim Preis' ist überwiegend positiv (76.19%)\n",
      "___________________________________\n",
      "Der Artikel 'Bleibt doch noch ein bisschen' ist überwiegend positiv (66.67%)\n",
      "___________________________________\n",
      "Der Artikel 'Der Brandbeschleuniger im Weißen Haus' ist neutral\n",
      "___________________________________\n",
      "Der Artikel 'Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei' ist überwiegend positiv (67.44%)\n",
      "___________________________________\n",
      "Der Artikel 'Bankenmarkt' ist überwiegend positiv (64.0%)\n",
      "___________________________________\n",
      "Der Artikel 'Deutschland sucht das Super-SUV' ist überwiegend positiv (71.88%)\n",
      "___________________________________\n",
      "Der Artikel 'Die Mailänder Börse ist in Feierlaune' ist überwiegend positiv (83.33%)\n",
      "___________________________________\n",
      "Der Artikel 'Trump, Trump und nochmals Trump' ist überwiegend negativ (57.89%)\n",
      "___________________________________\n",
      "Der Artikel 'Basel IV' ist überwiegend positiv (61.11%)\n",
      "___________________________________\n",
      "Der Artikel 'Jetzt wird Bayern nervös' ist überwiegend positiv (60.53%)\n",
      "___________________________________\n",
      "Der Artikel 'BMW setzt noch einen drauf' ist überwiegend positiv (92.86%)\n",
      "___________________________________\n",
      "Der Artikel 'Klopp geht all in und gewinnt' ist überwiegend positiv (77.27%)\n",
      "___________________________________\n"
     ]
    }
   ],
   "source": [
    "bmw = stopwordsRemoved.get('BMW setzt noch einen drauf')\n",
    "sentimentAnalysis(stopwordsRemoved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Artikel 'BMW setzt noch einen drauf' ist überwiegend positiv (92.86%)\n",
    "\n",
    "['mächtige', 'wagte', 'stattliche', 'großem', 'wert', 'erneuerten', 'verantwortlichen', 'starkes', 'maximale', 'verstärkungen', 'spezielle', 'beeindruckte', 'ruhe']\n",
    "\n",
    "['schlechter']\n",
    "\n",
    "\n",
    "Der Artikel 'Der Vorwurf eines unerwünschten Kusses' ist neutral\n",
    "\n",
    "['mögliche', 'mögliche', 'erklärte', 'sicher']\n",
    "\n",
    "['vorwürfe', 'vorwürfe', 'vorwürfen', 'unangemessenes']\n",
    "\n",
    "\n",
    "Der Artikel 'Trump, Trump und nochmals Trump' ist überwiegend negativ (57.89%)\n",
    "\n",
    "['gewinnen', 'möglichst', 'kommunikativen', 'gepflegtere', 'wiederherstellung', 'guten', 'gelassene', 'möglichst']\n",
    "\n",
    "['schelten', 'unzufriedenen', 'tote', 'bizarre', 'sorgen', 'attacken', 'kriminelle', 'schwerer', 'drastische', 'bitterer', 'blutigen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-70-34194d82931d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-70-34194d82931d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Hier muss was passieren, dass das Zeigt\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Hier muss was passieren, dass das Zeigt\n",
    "am Beispiel von einem Text Zeigen \n",
    "print(tokenized[Dokumentname])\n",
    "print(\"--------------------------------------------------\")\n",
    "print(stopeords(tokenized[Dokumentname]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wo bin ich Übersicht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert Here -> Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(documents):\n",
    "    vocabulary = set()\n",
    "\n",
    "    for key in documents:\n",
    "        text = documents.get(key)\n",
    "        vocabulary = vocabulary.union(text)\n",
    "    \n",
    "    return(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto',\n",
       " 'fliegt',\n",
       " 'flugzeug',\n",
       " 'fährt',\n",
       " 'motorrad',\n",
       " 'schnell',\n",
       " 'schneller',\n",
       " 'zug'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_vocabulary = get_vocabulary(beispiel_stopwords)\n",
    "beispiel_vocabulary"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Wo bin ich Übersicht\n",
    "\n",
    "\n",
    "--- Was mache ich warum wann?\n",
    " --- SAS Skipt hat hier eine Tabelle ----\n",
    "\n",
    "- Entropie\n",
    "- Mutual Information (wenn zeit ist ggf. kann ich das machen)\n",
    "- bag of words\n",
    "- term_frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(documents, vocabulary):\n",
    "    import pandas as pd\n",
    "    bow = {}\n",
    "    \n",
    "    for key in documents:\n",
    "        document = documents.get(key)\n",
    "        dictTemp = dict.fromkeys(vocabulary, 0)\n",
    "\n",
    "        for token in document:\n",
    "            dictTemp[token]+=1\n",
    "        \n",
    "        bow[key] = dictTemp\n",
    "    \n",
    "    bowDF = pd.DataFrame(bow).T\n",
    "        \n",
    "    return(bow, bowDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto</th>\n",
       "      <th>fliegt</th>\n",
       "      <th>flugzeug</th>\n",
       "      <th>fährt</th>\n",
       "      <th>motorrad</th>\n",
       "      <th>schnell</th>\n",
       "      <th>schneller</th>\n",
       "      <th>zug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dokument_1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            auto  fliegt  flugzeug  fährt  motorrad  schnell  schneller  zug\n",
       "Dokument_1     2       0         0      1         1        1          0    0\n",
       "Dokument_2     1       0         0      1         0        0          1    1\n",
       "Dokument_3     0       1         1      0         0        0          0    0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_bow, beispiel_bowDF = bag_of_words(beispiel_stopwords, beispiel_vocabulary)\n",
    "beispiel_bowDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Frequencies (schlau sortiert?, dass mann auch was sieht top (10)!! nicht mehr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(bow, documents):\n",
    "    import pandas as pd\n",
    "    tfDict= {}\n",
    "    \n",
    "    for key in documents:\n",
    "        tfCount = {}\n",
    "        doc = documents.get(key)\n",
    "        wordCount = len(doc)\n",
    "        for word, count in bow.get(key).items():\n",
    "            tfCount[word] = count / float(wordCount)\n",
    "            \n",
    "        tfDict[key] = tfCount\n",
    "        \n",
    "    tfDF = pd.DataFrame(tfDict).T\n",
    "        \n",
    "    return(tfDict, tfDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto</th>\n",
       "      <th>fliegt</th>\n",
       "      <th>flugzeug</th>\n",
       "      <th>fährt</th>\n",
       "      <th>motorrad</th>\n",
       "      <th>schnell</th>\n",
       "      <th>schneller</th>\n",
       "      <th>zug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dokument_1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            auto  fliegt  flugzeug  fährt  motorrad  schnell  schneller   zug\n",
       "Dokument_1  0.40     0.0       0.0   0.20       0.2      0.2       0.00  0.00\n",
       "Dokument_2  0.25     0.0       0.0   0.25       0.0      0.0       0.25  0.25\n",
       "Dokument_3  0.00     0.5       0.5   0.00       0.0      0.0       0.00  0.00"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_tf, beispiel_tfDF = term_frequency(beispiel_bow, beispiel_stopwords)\n",
    "beispiel_tfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Frequencies (schlau sortiert?, dass mann auch was sieht top (10)!! nicht mehr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_document_frequency(bow):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(bow)\n",
    "    idfDict = dict.fromkeys(bow[next(iter(bow))].keys(),0)\n",
    "    i = 0\n",
    "    for key in bow:\n",
    "        doc = bow.get(key)\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] +=1\n",
    "        i = i + 1\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word]= math.log(N / float(val))\n",
    "    \n",
    "    return(idfDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'schneller': 1.0986122886681098,\n",
       " 'schnell': 1.0986122886681098,\n",
       " 'fährt': 0.4054651081081644,\n",
       " 'flugzeug': 1.0986122886681098,\n",
       " 'fliegt': 1.0986122886681098,\n",
       " 'auto': 0.4054651081081644,\n",
       " 'motorrad': 1.0986122886681098,\n",
       " 'zug': 1.0986122886681098}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_idf = inverse_document_frequency(beispiel_bow)\n",
    "beispiel_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Frequencies (schlau sortiert?, dass mann auch was sieht top (10)!! nicht mehr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency_inverse_document_frequency(tfBow, idfs):\n",
    "    import pandas as pd\n",
    "    tfidf = {}\n",
    "    tfidfDict = {}\n",
    "    for key in tfBow:\n",
    "        text = tfBow.get(key)\n",
    "        tfidf = {}\n",
    "        for word, val in text.items():\n",
    "            tfidf[word] = val * idfs[word]\n",
    "        tfidfDict[key] = tfidf\n",
    "    \n",
    "    tfidfDF = pd.DataFrame(tfidfDict).T\n",
    "    \n",
    "    return(tfidfDict, tfidfDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto</th>\n",
       "      <th>fliegt</th>\n",
       "      <th>flugzeug</th>\n",
       "      <th>fährt</th>\n",
       "      <th>motorrad</th>\n",
       "      <th>schnell</th>\n",
       "      <th>schneller</th>\n",
       "      <th>zug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dokument_1</th>\n",
       "      <td>0.810930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_2</th>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                auto    fliegt  flugzeug     fährt  motorrad   schnell  \\\n",
       "Dokument_1  0.810930  0.000000  0.000000  0.405465  1.098612  1.098612   \n",
       "Dokument_2  0.405465  0.000000  0.000000  0.405465  0.000000  0.000000   \n",
       "Dokument_3  0.000000  1.098612  1.098612  0.000000  0.000000  0.000000   \n",
       "\n",
       "            schneller       zug  \n",
       "Dokument_1   0.000000  0.000000  \n",
       "Dokument_2   1.098612  1.098612  \n",
       "Dokument_3   0.000000  0.000000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_tfidf, beispiel_tfidfDF = term_frequency_inverse_document_frequency(beispiel_bow, beispiel_idf)\n",
    "beispiel_tfidfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = get_vocabulary(stopwordsRemoved)\n",
    "bow, bowDF = bag_of_words(stopwordsRemoved, vocabulary)\n",
    "tf, tfDF = term_frequency(bow, stopwordsRemoved)\n",
    "idf = inverse_document_frequency(bow)\n",
    "tfidf, tfidfDF = term_frequency_inverse_document_frequency(bow, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der Frequencies (schlau sortiert?, dass mann auch was sieht top (10)!! nicht mehr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dann legts du die Dinger Unter / Nebeneinander zum Vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Plot zur Visualisierung der Unterschiede \n",
    "# https://stackoverflow.com/questions/8230638/parallel-coordinates-plot-in-matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ergbenis der sentiment Analyse als Wordcloud darstellen -- Positive Worte = Grüün negative Worte == root\n",
    "\n",
    "Koeffizienten Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(documents):\n",
    "    \n",
    "    with open('./SentimentAnalysis/positive.json') as positive:  \n",
    "        positiveWords = json.load(positive)\n",
    "    with open('./SentimentAnalysis/negative.json') as negative:  \n",
    "        negativeWords = json.load(negative)\n",
    "    \n",
    "    for doc in documents:\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        text = documents.get(doc)\n",
    "        for token in text:\n",
    "            if token in positiveWords:\n",
    "                positive += 1\n",
    "            elif token in negativeWords:\n",
    "                negative += 1\n",
    "        # Ich würde das hier durch alle Worte im Dokument ersetzen! summe = alle Worte\n",
    "        summe = positive + negative\n",
    "        if positive > negative:\n",
    "            print(\"Der Artikel '\" + doc + \"' ist überwiegend positiv (\" + str(round((positive/summe)*100, 2)) + \"%)\")\n",
    "        elif negative > positive:\n",
    "            print(\"Der Artikel '\" + doc + \"' ist überwiegend negativ (\" + str(round((negative/summe)*100, 2)) + \"%)\")\n",
    "        elif positive == negative:\n",
    "            print('Der Artikel ist neutral')\n",
    "        print('___________________________________')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = get_vocabulary(stopwordsRemoved)\n",
    "bow, bowDF = bag_of_words(stopwordsRemoved, vocabulary)\n",
    "tf, tfDF = term_frequency(bow, stopwordsRemoved)\n",
    "idf = inverse_document_frequency(bow)\n",
    "tfidf, tfidfDF = term_frequency_inverse_document_frequency(bow, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfDataFrame = tfidfDF.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellen einer Keywordsuche\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Keywordsuche](./Grafiken/KeywordSearch.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCHBEGRIFF: apple\n",
      "Gefunden in folgenden Dokumenten:\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "RANG: 1\n",
      "DOKUMENT: Hollywood-Stars präsentieren\n",
      "Weitere, wichtige Begriffe in \"Hollywood-Stars präsentieren\"\n",
      "\"kreditkarte\", bedeutsam in: \"Konkurrenz für Netflix\"\n",
      "\"nachrichtenportal\", bedeutsam in: \"Hollywood-Stars präsentieren\"\n",
      "\"tv\", bedeutsam in: \"Hollywood-Stars präsentieren\"\n",
      "\"verfügbar\", bedeutsam in: \"Hollywood-Stars präsentieren\"\n",
      "\"dienst\", bedeutsam in: \"Konkurrenz für Netflix\"\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "RANG: 2\n",
      "DOKUMENT: Konkurrenz für Netflix\n",
      "Weitere, wichtige Begriffe in \"Konkurrenz für Netflix\"\n",
      "\"konzern\", bedeutsam in: \"Konkurrenz für Netflix\"\n",
      "\"shows\", bedeutsam in: \"Konkurrenz für Netflix\"\n",
      "\"netflix\", bedeutsam in: \"Konkurrenz für Netflix\"\n",
      "\"inhalte\", bedeutsam in: \"Konkurrenz für Netflix\"\n",
      "\"zufolge\", bedeutsam in: \"Konkurrenz für Netflix\"\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "RANG: 3\n",
      "DOKUMENT: Bleibt doch noch ein bisschen\n",
      "Weitere, wichtige Begriffe in \"Bleibt doch noch ein bisschen\"\n",
      "\"google\", bedeutsam in: \"Bleibt doch noch ein bisschen\"\n",
      "\"thing\", bedeutsam in: \"Bleibt doch noch ein bisschen\"\n",
      "\"more\", bedeutsam in: \"Bleibt doch noch ein bisschen\"\n",
      "\"one\", bedeutsam in: \"Bleibt doch noch ein bisschen\"\n",
      "\"konzern\", bedeutsam in: \"Konkurrenz für Netflix\"\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "RANG: 4\n",
      "DOKUMENT: Ladematte AirPower\n",
      "Weitere, wichtige Begriffe in \"Ladematte AirPower\"\n",
      "\"airpower\", bedeutsam in: \"Ladematte AirPower\"\n",
      "\"matte\", bedeutsam in: \"Ladematte AirPower\"\n",
      "\"ladematte\", bedeutsam in: \"Ladematte AirPower\"\n",
      "\"geräten\", bedeutsam in: \"Ladematte AirPower\"\n",
      "\"problemen\", bedeutsam in: \"Ladematte AirPower\"\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "RANG: 5\n",
      "DOKUMENT: Lebensrettende Massnahmen für Apple TV\n",
      "Weitere, wichtige Begriffe in \"Lebensrettende Massnahmen für Apple TV\"\n",
      "\"tv\", bedeutsam in: \"Hollywood-Stars präsentieren\"\n",
      "\"laut\", bedeutsam in: \"Lebensrettende Massnahmen für Apple TV\"\n",
      "\"appletvbox\", bedeutsam in: \"Lebensrettende Massnahmen für Apple TV\"\n",
      "\"hdmistick\", bedeutsam in: \"Lebensrettende Massnahmen für Apple TV\"\n",
      "\"version\", bedeutsam in: \"Tesla im Fahrtest\"\n",
      "____________________________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def search_keyword(keyword, tfidfDataFrame):\n",
    "\n",
    "    searchList = []\n",
    "    for doc in tfidfDataFrame:\n",
    "        vec = tfidfDataFrame[doc]\n",
    "        if vec.get(keyword) != 0:\n",
    "            tfidf_value = vec.get(keyword)\n",
    "            searchList.append([tfidf_value, doc])\n",
    "    return sorted(searchList, reverse=True)\n",
    "\n",
    "def search_top_word_documents(keyword, tfidfDataFrame):\n",
    "    \n",
    "    topDocsList = []\n",
    "    docList = []\n",
    "    topWordDocuments = {}\n",
    "    for doc in tfidfDataFrame:\n",
    "        vec = tfidfDataFrame[doc]\n",
    "        if vec.get(keyword) != 0:\n",
    "            topDocsList.append(doc)\n",
    "        topWordDocuments[keyword] = topDocsList\n",
    "    return(topWordDocuments)\n",
    "\n",
    "def get_top_words(document, n, tfidfDataFrame):\n",
    "    \n",
    "    topDict = {}\n",
    "    topList = []\n",
    "    vec = tfidfDataFrame[document]\n",
    "    sorted_vec = vec.sort_values(ascending=False)\n",
    "    top = sorted_vec[0:n]\n",
    "    for i, row in top.iteritems():\n",
    "        if i != keyword:\n",
    "            topList.append(i)\n",
    "    topDict[document] = topList[0:n-2]\n",
    "    return(topDict)\n",
    "            \n",
    "def get_top_words_documents(docName, relDocs, tfidfDataFrame):\n",
    "    \n",
    "    wordList = []\n",
    "    topWordDocList = []\n",
    "    wordList = relDocs.get(docName)\n",
    "    for word in wordList:\n",
    "        topWordDocList.append(search_top_word_documents(word, tfidfDataFrame))\n",
    "    return(topWordDocList)\n",
    "    \n",
    "def related_docs(docs, n, tfidfDataFrame):\n",
    "    \n",
    "    relatedDocs = []\n",
    "    n += 2\n",
    "    for doc in docs:\n",
    "        docName = doc[1]\n",
    "        relDocs = get_top_words(docName, n, tfidfDataFrame)\n",
    "        topWordDocs = get_top_words_documents(docName, relDocs, tfidfDataFrame)\n",
    "        relatedDocs.append([doc[1], relDocs, topWordDocs])\n",
    "    return(relatedDocs)\n",
    "\n",
    "def keyword_search(keyword, tfidfDataFrame):\n",
    "    search = search_keyword(keyword, tfidfDataFrame)\n",
    "    complete = related_docs(search, 5, tfidfDataFrame)\n",
    "    return(complete)\n",
    "\n",
    "keyword = 'apple'\n",
    "result = keyword_search(keyword, tfidfDataFrame)\n",
    "\n",
    "i = 1\n",
    "\n",
    "print('SUCHBEGRIFF: ' + keyword)\n",
    "print('Gefunden in folgenden Dokumenten:')\n",
    "print('_'*100)\n",
    "print('')\n",
    "for res in result:\n",
    "    #print(x[0])\n",
    "    print('RANG: ' + str(i))\n",
    "    print('DOKUMENT: ' + res[0])\n",
    "    print('Weitere, wichtige Begriffe in \"' + res[0] + '\"')\n",
    "    topWords = res[1].get(res[0])\n",
    "    topDocuments = res[2]\n",
    "    for topW in topWords:\n",
    "        for topD in topDocuments:\n",
    "            if topD.get(topW) != None:\n",
    "                x = topD.get(topW)\n",
    "                print('\"' + str(topW) + '\"' + ', bedeutsam in: \"' + x[0] + '\"')\n",
    "    i+=1\n",
    "    print('_'*100)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wo bin ich Übersicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame.from_dict(documents, orient = 'index')\n",
    "dataframe.reset_index(level=0, inplace=True)\n",
    "dataframe.columns = ['file', 'token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = get_vocabulary(stopwordsRemoved)\n",
    "bow, bowDF = bag_of_words(stopwordsRemoved, vocabulary)\n",
    "tf, tfDF = term_frequency(bow, stopwordsRemoved)\n",
    "idf = inverse_document_frequency(bow)\n",
    "tfidf, tfidfDF = term_frequency_inverse_document_frequency(bow, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                               00       000  \\\n",
      "Zweite Bundesliga                                   0.0  3.218876  0.000000   \n",
      "Joachim Löw und die Nationalelf                     0.0  0.000000  0.000000   \n",
      "Konkurrenz für Netflix                              0.0  0.000000  0.000000   \n",
      "Blitz und Schatten                                  0.0  0.000000  0.000000   \n",
      "Ladematte AirPower                                  0.0  0.000000  0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...  0.0  0.000000  1.832581   \n",
      "Was Kim kann, kann Trump auch                       0.0  0.000000  0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor   0.0  0.000000  0.000000   \n",
      "Hollywood-Stars präsentieren                        0.0  0.000000  0.000000   \n",
      "Tesla im Fahrtest                                   0.0  0.000000  3.665163   \n",
      "Lebensrettende Massnahmen für Apple TV              0.0  0.000000  0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses              0.0  0.000000  0.000000   \n",
      "Natixis im Gespräch                                 0.0  0.000000  0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                  0.0  0.000000  3.665163   \n",
      "Bleibt doch noch ein bisschen                       0.0  0.000000  0.000000   \n",
      "Der Brandbeschleuniger im Weißen Haus               0.0  0.000000  0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...  0.0  0.000000  0.000000   \n",
      "Bankenmarkt                                         0.0  0.000000  0.000000   \n",
      "Deutschland sucht das Super-SUV                     0.0  0.000000  0.000000   \n",
      "Die Mailänder Börse ist in Feierlaune               0.0  0.000000  0.000000   \n",
      "Trump, Trump und nochmals Trump                     0.0  0.000000  0.000000   \n",
      "Basel IV                                            0.0  0.000000  0.000000   \n",
      "Jetzt wird Bayern nervös                            0.0  0.000000  0.000000   \n",
      "BMW setzt noch einen drauf                          0.0  0.000000  0.000000   \n",
      "Klopp geht all in und gewinnt                       0.0  0.000000  1.832581   \n",
      "\n",
      "                                                          02        03  \\\n",
      "Zweite Bundesliga                                   0.000000  0.000000   \n",
      "Joachim Löw und die Nationalelf                     2.525729  3.218876   \n",
      "Konkurrenz für Netflix                              0.000000  0.000000   \n",
      "Blitz und Schatten                                  0.000000  0.000000   \n",
      "Ladematte AirPower                                  0.000000  0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...  0.000000  0.000000   \n",
      "Was Kim kann, kann Trump auch                       0.000000  0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor   5.051457  0.000000   \n",
      "Hollywood-Stars präsentieren                        0.000000  0.000000   \n",
      "Tesla im Fahrtest                                   0.000000  0.000000   \n",
      "Lebensrettende Massnahmen für Apple TV              0.000000  0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses              0.000000  0.000000   \n",
      "Natixis im Gespräch                                 0.000000  0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                  0.000000  0.000000   \n",
      "Bleibt doch noch ein bisschen                       0.000000  0.000000   \n",
      "Der Brandbeschleuniger im Weißen Haus               0.000000  0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...  0.000000  0.000000   \n",
      "Bankenmarkt                                         0.000000  0.000000   \n",
      "Deutschland sucht das Super-SUV                     0.000000  0.000000   \n",
      "Die Mailänder Börse ist in Feierlaune               0.000000  0.000000   \n",
      "Trump, Trump und nochmals Trump                     0.000000  0.000000   \n",
      "Basel IV                                            0.000000  0.000000   \n",
      "Jetzt wird Bayern nervös                            0.000000  0.000000   \n",
      "BMW setzt noch einen drauf                          0.000000  0.000000   \n",
      "Klopp geht all in und gewinnt                       0.000000  0.000000   \n",
      "\n",
      "                                                          10       100  \\\n",
      "Zweite Bundesliga                                   0.000000  0.000000   \n",
      "Joachim Löw und die Nationalelf                     1.609438  0.000000   \n",
      "Konkurrenz für Netflix                              0.000000  0.000000   \n",
      "Blitz und Schatten                                  0.000000  0.000000   \n",
      "Ladematte AirPower                                  0.000000  0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...  0.000000  2.120264   \n",
      "Was Kim kann, kann Trump auch                       0.000000  0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor   3.218876  0.000000   \n",
      "Hollywood-Stars präsentieren                        0.000000  2.120264   \n",
      "Tesla im Fahrtest                                   0.000000  0.000000   \n",
      "Lebensrettende Massnahmen für Apple TV              0.000000  0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses              0.000000  0.000000   \n",
      "Natixis im Gespräch                                 0.000000  0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                  0.000000  0.000000   \n",
      "Bleibt doch noch ein bisschen                       0.000000  0.000000   \n",
      "Der Brandbeschleuniger im Weißen Haus               0.000000  0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...  1.609438  0.000000   \n",
      "Bankenmarkt                                         0.000000  0.000000   \n",
      "Deutschland sucht das Super-SUV                     1.609438  4.240527   \n",
      "Die Mailänder Börse ist in Feierlaune               0.000000  0.000000   \n",
      "Trump, Trump und nochmals Trump                     0.000000  0.000000   \n",
      "Basel IV                                            0.000000  0.000000   \n",
      "Jetzt wird Bayern nervös                            1.609438  0.000000   \n",
      "BMW setzt noch einen drauf                          0.000000  0.000000   \n",
      "Klopp geht all in und gewinnt                       0.000000  0.000000   \n",
      "\n",
      "                                                       10000       105  \\\n",
      "Zweite Bundesliga                                   0.000000  0.000000   \n",
      "Joachim Löw und die Nationalelf                     0.000000  0.000000   \n",
      "Konkurrenz für Netflix                              0.000000  0.000000   \n",
      "Blitz und Schatten                                  0.000000  0.000000   \n",
      "Ladematte AirPower                                  0.000000  0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...  0.000000  0.000000   \n",
      "Was Kim kann, kann Trump auch                       0.000000  0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor   0.000000  0.000000   \n",
      "Hollywood-Stars präsentieren                        0.000000  0.000000   \n",
      "Tesla im Fahrtest                                   0.000000  0.000000   \n",
      "Lebensrettende Massnahmen für Apple TV              0.000000  0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses              0.000000  0.000000   \n",
      "Natixis im Gespräch                                 0.000000  0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                  0.000000  0.000000   \n",
      "Bleibt doch noch ein bisschen                       0.000000  0.000000   \n",
      "Der Brandbeschleuniger im Weißen Haus               0.000000  0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...  0.000000  0.000000   \n",
      "Bankenmarkt                                         0.000000  0.000000   \n",
      "Deutschland sucht das Super-SUV                     0.000000  0.000000   \n",
      "Die Mailänder Börse ist in Feierlaune               0.000000  0.000000   \n",
      "Trump, Trump und nochmals Trump                     0.000000  0.000000   \n",
      "Basel IV                                            0.000000  0.000000   \n",
      "Jetzt wird Bayern nervös                            3.218876  0.000000   \n",
      "BMW setzt noch einen drauf                          0.000000  3.218876   \n",
      "Klopp geht all in und gewinnt                       0.000000  0.000000   \n",
      "\n",
      "                                                      109900    ...      \\\n",
      "Zweite Bundesliga                                   0.000000    ...       \n",
      "Joachim Löw und die Nationalelf                     0.000000    ...       \n",
      "Konkurrenz für Netflix                              0.000000    ...       \n",
      "Blitz und Schatten                                  0.000000    ...       \n",
      "Ladematte AirPower                                  0.000000    ...       \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...  0.000000    ...       \n",
      "Was Kim kann, kann Trump auch                       0.000000    ...       \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor   0.000000    ...       \n",
      "Hollywood-Stars präsentieren                        0.000000    ...       \n",
      "Tesla im Fahrtest                                   0.000000    ...       \n",
      "Lebensrettende Massnahmen für Apple TV              0.000000    ...       \n",
      "Der Vorwurf eines unerwünschten Kusses              0.000000    ...       \n",
      "Natixis im Gespräch                                 0.000000    ...       \n",
      "Mittelklasse, nur nicht beim Preis                  0.000000    ...       \n",
      "Bleibt doch noch ein bisschen                       0.000000    ...       \n",
      "Der Brandbeschleuniger im Weißen Haus               0.000000    ...       \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...  0.000000    ...       \n",
      "Bankenmarkt                                         0.000000    ...       \n",
      "Deutschland sucht das Super-SUV                     0.000000    ...       \n",
      "Die Mailänder Börse ist in Feierlaune               0.000000    ...       \n",
      "Trump, Trump und nochmals Trump                     0.000000    ...       \n",
      "Basel IV                                            0.000000    ...       \n",
      "Jetzt wird Bayern nervös                            0.000000    ...       \n",
      "BMW setzt noch einen drauf                          3.218876    ...       \n",
      "Klopp geht all in und gewinnt                       0.000000    ...       \n",
      "\n",
      "                                                    übertragenden  \\\n",
      "Zweite Bundesliga                                        0.000000   \n",
      "Joachim Löw und die Nationalelf                          0.000000   \n",
      "Konkurrenz für Netflix                                   0.000000   \n",
      "Blitz und Schatten                                       0.000000   \n",
      "Ladematte AirPower                                       0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...       0.000000   \n",
      "Was Kim kann, kann Trump auch                            0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor        0.000000   \n",
      "Hollywood-Stars präsentieren                             0.000000   \n",
      "Tesla im Fahrtest                                        0.000000   \n",
      "Lebensrettende Massnahmen für Apple TV                   0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses                   0.000000   \n",
      "Natixis im Gespräch                                      0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                       0.000000   \n",
      "Bleibt doch noch ein bisschen                            0.000000   \n",
      "Der Brandbeschleuniger im Weißen Haus                    0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...       0.000000   \n",
      "Bankenmarkt                                              0.000000   \n",
      "Deutschland sucht das Super-SUV                          0.000000   \n",
      "Die Mailänder Börse ist in Feierlaune                    0.000000   \n",
      "Trump, Trump und nochmals Trump                          0.000000   \n",
      "Basel IV                                                 0.000000   \n",
      "Jetzt wird Bayern nervös                                 0.000000   \n",
      "BMW setzt noch einen drauf                               0.000000   \n",
      "Klopp geht all in und gewinnt                            3.218876   \n",
      "\n",
      "                                                    übertrieben  überzeugen  \\\n",
      "Zweite Bundesliga                                      0.000000    0.000000   \n",
      "Joachim Löw und die Nationalelf                        0.000000    0.000000   \n",
      "Konkurrenz für Netflix                                 0.000000    0.000000   \n",
      "Blitz und Schatten                                     0.000000    0.000000   \n",
      "Ladematte AirPower                                     0.000000    0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...     0.000000    0.000000   \n",
      "Was Kim kann, kann Trump auch                          0.000000    0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor      0.000000    0.000000   \n",
      "Hollywood-Stars präsentieren                           0.000000    0.000000   \n",
      "Tesla im Fahrtest                                      0.000000    2.120264   \n",
      "Lebensrettende Massnahmen für Apple TV                 0.000000    0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses                 0.000000    0.000000   \n",
      "Natixis im Gespräch                                    0.000000    0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                     0.000000    0.000000   \n",
      "Bleibt doch noch ein bisschen                          0.000000    2.120264   \n",
      "Der Brandbeschleuniger im Weißen Haus                  0.000000    0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...     3.218876    0.000000   \n",
      "Bankenmarkt                                            0.000000    0.000000   \n",
      "Deutschland sucht das Super-SUV                        0.000000    0.000000   \n",
      "Die Mailänder Börse ist in Feierlaune                  0.000000    0.000000   \n",
      "Trump, Trump und nochmals Trump                        0.000000    0.000000   \n",
      "Basel IV                                               0.000000    0.000000   \n",
      "Jetzt wird Bayern nervös                               0.000000    0.000000   \n",
      "BMW setzt noch einen drauf                             0.000000    0.000000   \n",
      "Klopp geht all in und gewinnt                          0.000000    2.120264   \n",
      "\n",
      "                                                    überzeugt      üble  \\\n",
      "Zweite Bundesliga                                    0.000000  0.000000   \n",
      "Joachim Löw und die Nationalelf                      0.000000  0.000000   \n",
      "Konkurrenz für Netflix                               0.000000  0.000000   \n",
      "Blitz und Schatten                                   0.000000  0.000000   \n",
      "Ladematte AirPower                                   2.525729  0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...   0.000000  0.000000   \n",
      "Was Kim kann, kann Trump auch                        0.000000  0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor    0.000000  0.000000   \n",
      "Hollywood-Stars präsentieren                         0.000000  0.000000   \n",
      "Tesla im Fahrtest                                    0.000000  0.000000   \n",
      "Lebensrettende Massnahmen für Apple TV               0.000000  0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses               0.000000  0.000000   \n",
      "Natixis im Gespräch                                  0.000000  0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                   0.000000  0.000000   \n",
      "Bleibt doch noch ein bisschen                        0.000000  0.000000   \n",
      "Der Brandbeschleuniger im Weißen Haus                0.000000  0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...   2.525729  0.000000   \n",
      "Bankenmarkt                                          0.000000  0.000000   \n",
      "Deutschland sucht das Super-SUV                      0.000000  0.000000   \n",
      "Die Mailänder Börse ist in Feierlaune                0.000000  0.000000   \n",
      "Trump, Trump und nochmals Trump                      0.000000  0.000000   \n",
      "Basel IV                                             0.000000  0.000000   \n",
      "Jetzt wird Bayern nervös                             0.000000  3.218876   \n",
      "BMW setzt noch einen drauf                           0.000000  0.000000   \n",
      "Klopp geht all in und gewinnt                        0.000000  0.000000   \n",
      "\n",
      "                                                    üblicherweise     übrig  \\\n",
      "Zweite Bundesliga                                        0.000000  0.000000   \n",
      "Joachim Löw und die Nationalelf                          0.000000  0.000000   \n",
      "Konkurrenz für Netflix                                   2.525729  0.000000   \n",
      "Blitz und Schatten                                       0.000000  0.000000   \n",
      "Ladematte AirPower                                       0.000000  0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...       0.000000  0.000000   \n",
      "Was Kim kann, kann Trump auch                            0.000000  0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor        0.000000  0.000000   \n",
      "Hollywood-Stars präsentieren                             2.525729  0.000000   \n",
      "Tesla im Fahrtest                                        0.000000  0.000000   \n",
      "Lebensrettende Massnahmen für Apple TV                   0.000000  0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses                   0.000000  0.000000   \n",
      "Natixis im Gespräch                                      0.000000  0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                       0.000000  0.000000   \n",
      "Bleibt doch noch ein bisschen                            0.000000  0.000000   \n",
      "Der Brandbeschleuniger im Weißen Haus                    0.000000  0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...       0.000000  0.000000   \n",
      "Bankenmarkt                                              0.000000  3.218876   \n",
      "Deutschland sucht das Super-SUV                          0.000000  0.000000   \n",
      "Die Mailänder Börse ist in Feierlaune                    0.000000  0.000000   \n",
      "Trump, Trump und nochmals Trump                          0.000000  0.000000   \n",
      "Basel IV                                                 0.000000  0.000000   \n",
      "Jetzt wird Bayern nervös                                 0.000000  0.000000   \n",
      "BMW setzt noch einen drauf                               0.000000  0.000000   \n",
      "Klopp geht all in und gewinnt                            0.000000  0.000000   \n",
      "\n",
      "                                                       üppig   üppiger  \\\n",
      "Zweite Bundesliga                                   0.000000  0.000000   \n",
      "Joachim Löw und die Nationalelf                     0.000000  0.000000   \n",
      "Konkurrenz für Netflix                              0.000000  0.000000   \n",
      "Blitz und Schatten                                  3.218876  0.000000   \n",
      "Ladematte AirPower                                  0.000000  0.000000   \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...  0.000000  0.000000   \n",
      "Was Kim kann, kann Trump auch                       0.000000  0.000000   \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor   0.000000  0.000000   \n",
      "Hollywood-Stars präsentieren                        0.000000  0.000000   \n",
      "Tesla im Fahrtest                                   0.000000  0.000000   \n",
      "Lebensrettende Massnahmen für Apple TV              0.000000  0.000000   \n",
      "Der Vorwurf eines unerwünschten Kusses              0.000000  0.000000   \n",
      "Natixis im Gespräch                                 0.000000  0.000000   \n",
      "Mittelklasse, nur nicht beim Preis                  0.000000  0.000000   \n",
      "Bleibt doch noch ein bisschen                       0.000000  0.000000   \n",
      "Der Brandbeschleuniger im Weißen Haus               0.000000  0.000000   \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...  0.000000  0.000000   \n",
      "Bankenmarkt                                         0.000000  0.000000   \n",
      "Deutschland sucht das Super-SUV                     0.000000  3.218876   \n",
      "Die Mailänder Börse ist in Feierlaune               0.000000  0.000000   \n",
      "Trump, Trump und nochmals Trump                     0.000000  0.000000   \n",
      "Basel IV                                            0.000000  0.000000   \n",
      "Jetzt wird Bayern nervös                            0.000000  0.000000   \n",
      "BMW setzt noch einen drauf                          0.000000  0.000000   \n",
      "Klopp geht all in und gewinnt                       0.000000  0.000000   \n",
      "\n",
      "                                                            €  \n",
      "Zweite Bundesliga                                    0.000000  \n",
      "Joachim Löw und die Nationalelf                      0.000000  \n",
      "Konkurrenz für Netflix                               0.000000  \n",
      "Blitz und Schatten                                   0.000000  \n",
      "Ladematte AirPower                                   0.000000  \n",
      "Weißes Haus rechnet mit Schließung der Grenze z...   0.000000  \n",
      "Was Kim kann, kann Trump auch                        0.000000  \n",
      "Dramatischer Liverpool-Sieg durch spätes Eigentor    0.000000  \n",
      "Hollywood-Stars präsentieren                         0.000000  \n",
      "Tesla im Fahrtest                                    0.000000  \n",
      "Lebensrettende Massnahmen für Apple TV               0.000000  \n",
      "Der Vorwurf eines unerwünschten Kusses               0.000000  \n",
      "Natixis im Gespräch                                  0.000000  \n",
      "Mittelklasse, nur nicht beim Preis                   0.000000  \n",
      "Bleibt doch noch ein bisschen                        0.000000  \n",
      "Der Brandbeschleuniger im Weißen Haus                0.000000  \n",
      "Schweizer Banken Die Zeiten, um an den Finanzmä...   0.000000  \n",
      "Bankenmarkt                                          0.000000  \n",
      "Deutschland sucht das Super-SUV                      0.000000  \n",
      "Die Mailänder Börse ist in Feierlaune               12.875503  \n",
      "Trump, Trump und nochmals Trump                      0.000000  \n",
      "Basel IV                                             0.000000  \n",
      "Jetzt wird Bayern nervös                             0.000000  \n",
      "BMW setzt noch einen drauf                           0.000000  \n",
      "Klopp geht all in und gewinnt                        0.000000  \n",
      "\n",
      "[25 rows x 4599 columns]\n",
      "  (0, 1)\t3.2188758248682006\n",
      "  (0, 14)\t3.2188758248682006\n",
      "  (0, 41)\t2.120263536200091\n",
      "  (0, 70)\t6.437751649736401\n",
      "  (0, 89)\t3.2188758248682006\n",
      "  (0, 135)\t3.2188758248682006\n",
      "  (0, 155)\t2.5257286443082556\n",
      "  (0, 182)\t3.2188758248682006\n",
      "  (0, 426)\t3.2188758248682006\n",
      "  (0, 459)\t2.5257286443082556\n",
      "  (0, 557)\t3.2188758248682006\n",
      "  (0, 682)\t3.2188758248682006\n",
      "  (0, 795)\t3.2188758248682006\n",
      "  (0, 833)\t3.2188758248682006\n",
      "  (0, 859)\t3.2188758248682006\n",
      "  (0, 897)\t3.2188758248682006\n",
      "  (0, 915)\t3.2188758248682006\n",
      "  (0, 1012)\t2.5257286443082556\n",
      "  (0, 1025)\t2.5257286443082556\n",
      "  (0, 1041)\t6.437751649736401\n",
      "  (0, 1042)\t3.2188758248682006\n",
      "  (0, 1043)\t6.437751649736401\n",
      "  (0, 1051)\t2.120263536200091\n",
      "  (0, 1074)\t9.656627474604601\n",
      "  (0, 1217)\t3.2188758248682006\n",
      "  :\t:\n",
      "  (24, 4207)\t3.2188758248682006\n",
      "  (24, 4240)\t2.5257286443082556\n",
      "  (24, 4245)\t2.5257286443082556\n",
      "  (24, 4253)\t3.2188758248682006\n",
      "  (24, 4294)\t3.2188758248682006\n",
      "  (24, 4295)\t3.2188758248682006\n",
      "  (24, 4315)\t3.2188758248682006\n",
      "  (24, 4377)\t1.4271163556401458\n",
      "  (24, 4390)\t2.5257286443082556\n",
      "  (24, 4434)\t2.120263536200091\n",
      "  (24, 4447)\t3.2188758248682006\n",
      "  (24, 4465)\t3.2188758248682006\n",
      "  (24, 4478)\t1.0216512475319812\n",
      "  (24, 4488)\t3.2188758248682006\n",
      "  (24, 4500)\t3.2188758248682006\n",
      "  (24, 4514)\t3.2188758248682006\n",
      "  (24, 4523)\t3.2188758248682006\n",
      "  (24, 4527)\t3.2188758248682006\n",
      "  (24, 4528)\t3.2188758248682006\n",
      "  (24, 4529)\t3.2188758248682006\n",
      "  (24, 4531)\t2.5257286443082556\n",
      "  (24, 4547)\t3.2188758248682006\n",
      "  (24, 4551)\t3.2188758248682006\n",
      "  (24, 4589)\t3.2188758248682006\n",
      "  (24, 4591)\t2.120263536200091\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "print(tfidfDF)\n",
    "\n",
    "tfidfDF = scipy.sparse.csr_matrix(tfidfDF)\n",
    "\n",
    "print(tfidfDF)\n",
    "\n",
    "def kMeans_clustering(feature_matrix):\n",
    "    \n",
    "    km = KMeans(n_clusters=5, max_iter=10000)\n",
    "    km.fit(feature_matrix.todense())\n",
    "    clusters = km.labels_          \n",
    "    return km, clusters\n",
    "\n",
    "km_obj, clusters = kMeans_clustering(feature_matrix=tfidfDF)\n",
    "\n",
    "cluster = pd.DataFrame(clusters)\n",
    "\n",
    "dataframe['Cluster'] = cluster\n",
    "\n",
    "c = Counter(clusters)\n",
    "total_clusters=len(c)\n",
    "\n",
    "cluster_details = {}  \n",
    "    \n",
    "ordered_centroids = km_obj.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "print(len(ordered_centroids))\n",
    "\n",
    "topn_features=10\n",
    "\n",
    "feature_names = sorted(vocabulary)\n",
    "\n",
    "for cluster_num in range(total_clusters):\n",
    "    cluster_details[cluster_num] = {}\n",
    "    cluster_details[cluster_num]['cluster_num'] = cluster_num\n",
    "    key_features = [feature_names[index]\n",
    "                    for index\n",
    "                    in ordered_centroids[cluster_num, :topn_features]]\n",
    "    cluster_details[cluster_num]['key_features'] = key_features\n",
    "    files = dataframe[dataframe['Cluster'] == cluster_num]['file'].values.tolist()\n",
    "    cluster_details[cluster_num]['token'] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'cluster_num': 0,\n",
       "  'key_features': ['banken',\n",
       "   'bankenverband',\n",
       "   'outputfloor',\n",
       "   'ksa',\n",
       "   'regulierung',\n",
       "   'kreditvergabe',\n",
       "   'deutsche',\n",
       "   'deutschland',\n",
       "   'angewendet',\n",
       "   'aktiva'],\n",
       "  'token': ['Basel IV']},\n",
       " 1: {'cluster_num': 1,\n",
       "  'key_features': ['apple',\n",
       "   'trump',\n",
       "   'sparkassen',\n",
       "   'liverpool',\n",
       "   'löw',\n",
       "   'airpower',\n",
       "   'klopp',\n",
       "   'investmentbanking',\n",
       "   'fc',\n",
       "   'x5'],\n",
       "  'token': ['Zweite Bundesliga',\n",
       "   'Joachim Löw und die Nationalelf',\n",
       "   'Blitz und Schatten',\n",
       "   'Ladematte AirPower',\n",
       "   'Weißes Haus rechnet mit Schließung der Grenze zu Mexiko',\n",
       "   'Was Kim kann, kann Trump auch',\n",
       "   'Dramatischer Liverpool-Sieg durch spätes Eigentor',\n",
       "   'Lebensrettende Massnahmen für Apple TV',\n",
       "   'Der Vorwurf eines unerwünschten Kusses',\n",
       "   'Natixis im Gespräch',\n",
       "   'Mittelklasse, nur nicht beim Preis',\n",
       "   'Bleibt doch noch ein bisschen',\n",
       "   'Der Brandbeschleuniger im Weißen Haus',\n",
       "   'Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei',\n",
       "   'Bankenmarkt',\n",
       "   'Die Mailänder Börse ist in Feierlaune',\n",
       "   'Trump, Trump und nochmals Trump',\n",
       "   'Jetzt wird Bayern nervös',\n",
       "   'BMW setzt noch einen drauf',\n",
       "   'Klopp geht all in und gewinnt']},\n",
       " 2: {'cluster_num': 2,\n",
       "  'key_features': ['glc',\n",
       "   'bmw',\n",
       "   'coupé',\n",
       "   'mercedesbenz',\n",
       "   'porsche',\n",
       "   'suv',\n",
       "   'x7',\n",
       "   'cayenne',\n",
       "   'geländewagen',\n",
       "   'x5'],\n",
       "  'token': ['Deutschland sucht das Super-SUV']},\n",
       " 3: {'cluster_num': 3,\n",
       "  'key_features': ['model',\n",
       "   '3',\n",
       "   'tesla',\n",
       "   'reichweite',\n",
       "   'autopilot',\n",
       "   'aktuell',\n",
       "   'kilometer',\n",
       "   'wagen',\n",
       "   'autopiloten',\n",
       "   'smartphone'],\n",
       "  'token': ['Tesla im Fahrtest']},\n",
       " 4: {'cluster_num': 4,\n",
       "  'key_features': ['apple',\n",
       "   'kreditkarte',\n",
       "   'netflix',\n",
       "   'konzern',\n",
       "   'dienst',\n",
       "   'inhalte',\n",
       "   'montag',\n",
       "   'times',\n",
       "   'geräte',\n",
       "   'nachrichtenportal'],\n",
       "  'token': ['Konkurrenz für Netflix', 'Hollywood-Stars präsentieren']}}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame.from_dict(tokenized, orient = 'index')\n",
    "dataframe.reset_index(level=0, inplace=True)\n",
    "dataframe.columns = ['file', 'token']\n",
    "#dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def display_features(features, feature_names):\n",
    "    df = pd.DataFrame(data=features, columns=feature_names)\n",
    "    return df\n",
    "\n",
    "def tfidf_extractor(corpus, ngram_range=(1,1)):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(min_df=1, norm='l2', smooth_idf=True, use_idf=True, ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features\n",
    "\n",
    "tfidf_vectorizer, tfidf_features = tfidf_extractor(dataframe['token'])\n",
    "print(tfidf_features[0].shape)\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print(type(tfidf_features))\n",
    "print(tfidf_features.shape)\n",
    "df = display_features(np.round(tfidf_features.todense(), 4), feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'cluster_num': 0,\n",
       "  'key_features': ['der',\n",
       "   'die',\n",
       "   'und',\n",
       "   'bmw',\n",
       "   'x5',\n",
       "   'mit',\n",
       "   'das',\n",
       "   'x7',\n",
       "   'ps',\n",
       "   'ist'],\n",
       "  'token': ['Mittelklasse, nur nicht beim Preis',\n",
       "   'Deutschland sucht das Super-SUV',\n",
       "   'BMW setzt noch einen drauf']},\n",
       " 1: {'cluster_num': 1,\n",
       "  'key_features': ['der',\n",
       "   'die',\n",
       "   'in',\n",
       "   'und',\n",
       "   'liverpool',\n",
       "   'er',\n",
       "   'den',\n",
       "   'löw',\n",
       "   'fc',\n",
       "   'gegen'],\n",
       "  'token': ['Zweite Bundesliga',\n",
       "   'Joachim Löw und die Nationalelf',\n",
       "   'Dramatischer Liverpool-Sieg durch spätes Eigentor',\n",
       "   'Jetzt wird Bayern nervös',\n",
       "   'Klopp geht all in und gewinnt']},\n",
       " 2: {'cluster_num': 2,\n",
       "  'key_features': ['apple',\n",
       "   'der',\n",
       "   'die',\n",
       "   'und',\n",
       "   'wie',\n",
       "   'konzern',\n",
       "   'von',\n",
       "   'für',\n",
       "   'airpower',\n",
       "   'den'],\n",
       "  'token': ['Konkurrenz für Netflix',\n",
       "   'Ladematte AirPower',\n",
       "   'Hollywood-Stars präsentieren',\n",
       "   'Lebensrettende Massnahmen für Apple TV',\n",
       "   'Bleibt doch noch ein bisschen']},\n",
       " 3: {'cluster_num': 3,\n",
       "  'key_features': ['die',\n",
       "   'der',\n",
       "   'und',\n",
       "   'banken',\n",
       "   'in',\n",
       "   'den',\n",
       "   'sparkassen',\n",
       "   'das',\n",
       "   'von',\n",
       "   'bank'],\n",
       "  'token': ['Natixis im Gespräch',\n",
       "   'Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei',\n",
       "   'Bankenmarkt',\n",
       "   'Basel IV']},\n",
       " 4: {'cluster_num': 4,\n",
       "  'key_features': ['der',\n",
       "   'die',\n",
       "   'und',\n",
       "   'trump',\n",
       "   'in',\n",
       "   'zu',\n",
       "   'den',\n",
       "   'ist',\n",
       "   'im',\n",
       "   'von'],\n",
       "  'token': ['Blitz und Schatten',\n",
       "   'Weißes Haus rechnet mit Schließung der Grenze zu Mexiko',\n",
       "   'Was Kim kann, kann Trump auch',\n",
       "   'Tesla im Fahrtest',\n",
       "   'Der Vorwurf eines unerwünschten Kusses',\n",
       "   'Der Brandbeschleuniger im Weißen Haus',\n",
       "   'Die Mailänder Börse ist in Feierlaune',\n",
       "   'Trump, Trump und nochmals Trump']}}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "def kMeans_clustering(feature_matrix):\n",
    "    \n",
    "    km = KMeans(n_clusters=5, max_iter=10000)\n",
    "    km.fit(feature_matrix.todense())\n",
    "    clusters = km.labels_          \n",
    "    return km, clusters\n",
    "\n",
    "km_obj, clusters = kMeans_clustering(feature_matrix=tfidf_features)\n",
    "\n",
    "cluster = pd.DataFrame(clusters)\n",
    "\n",
    "dataframe['Cluster'] = cluster\n",
    "\n",
    "c = Counter(clusters)\n",
    "total_clusters=len(c)\n",
    "\n",
    "cluster_details = {}  \n",
    "    \n",
    "ordered_centroids = km_obj.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "topn_features=10\n",
    "\n",
    "#feature_names = sorted(vocabulary)\n",
    "\n",
    "for cluster_num in range(total_clusters):\n",
    "    cluster_details[cluster_num] = {}\n",
    "    cluster_details[cluster_num]['cluster_num'] = cluster_num\n",
    "    key_features = [feature_names[index]\n",
    "                    for index\n",
    "                    in ordered_centroids[cluster_num, :topn_features]]\n",
    "    cluster_details[cluster_num]['key_features'] = key_features\n",
    "    files = dataframe[dataframe['Cluster'] == cluster_num]['file'].values.tolist()\n",
    "    cluster_details[cluster_num]['token'] = files\n",
    "    \n",
    "cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
