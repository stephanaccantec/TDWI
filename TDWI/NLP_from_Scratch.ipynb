{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing \n",
    "![Was ist NLP](<https://s2.qwant.com/thumbr/0x380/c/e/10c54c87272bdae830c4378495ff38b0e0af52906cdb0b0f6836eb4ad110f0/NLP-word-cloud-e1432237783661.jpg?u=https%3A%2F%2Fwww.thoughtmodels.com%2Fwp-content%2Fuploads%2F2016%2F06%2FNLP-word-cloud-e1432237783661.jpg&q=0&b=1&p=0&a=1>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/Agenda/Agenda.jpg\" style=\"width:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiele\n",
    "### -Dokumenten-Korpus aus Zeitungsartikeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion zum Einlesen von Texten\n",
    "#speichern als Key-Value-Paar (Dictionary)\n",
    "\n",
    "def read_documents(fqn :str):\n",
    "    import glob, os\n",
    "    \n",
    "    #Korpus-Dictionary:\n",
    "    documents = {}\n",
    "    \n",
    "    #jedes Dokument im Verzeichnis wird eingelesen\n",
    "    for file in glob.glob(fqn):\n",
    "\n",
    "        filename = open(file, \"r\", encoding='cp1252')\n",
    "        text = str(filename.readlines())\n",
    "\n",
    "        path = os.path.basename(file)\n",
    "        extension = os.path.splitext(file)[1]\n",
    "        filename, extension = path.split('.')\n",
    "        \n",
    "        #Text mit dem Namen des Dokuments als Schlüssel\n",
    "        documents[filename] = text\n",
    "            \n",
    "    return(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Sport) Joachim Löw und die Nationalelf',\n",
       " '(Sport) Zweite Bundesliga',\n",
       " '(Politik ) Der Brandbeschleuniger im Weißen Haus',\n",
       " '(Politik ) Weißes Haus rechnet mit Schließung der Grenze zu Mexiko',\n",
       " '(Politik ) Der Vorwurf eines unerwünschten Kusses',\n",
       " '(Finanzen) Natixis im Gespräch',\n",
       " '(Motor) Blitz und Schatten',\n",
       " '(Finanzen) Bankenmarkt',\n",
       " '(Motor) Mittelklasse, nur nicht beim Preis',\n",
       " '(Motor) Tesla im Fahrtest',\n",
       " '(Apple) Bleibt doch noch ein bisschen',\n",
       " '(Finanzen) Basel IV',\n",
       " '(Apple) Lebensrettende Massnahmen für Apple TV',\n",
       " '(Motor) Deutschland sucht das Super-SUV',\n",
       " '(Politik ) Trump, Trump und nochmals Trump',\n",
       " '(Motor) BMW setzt noch einen drauf',\n",
       " '(Sport) Dramatischer Liverpool-Sieg durch spätes Eigentor',\n",
       " '(Sport) Klopp geht all in und gewinnt ',\n",
       " '(Sport) Jetzt wird Bayern nervös',\n",
       " '(Politik ) Was Kim kann, kann Trump auch',\n",
       " '(Finanzen) Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei',\n",
       " '(Finanzen) Die Mailänder Börse ist in Feierlaune',\n",
       " '(Apple) Konkurrenz für Netflix',\n",
       " '(Apple) Ladematte AirPower',\n",
       " '(Apple) Hollywood-Stars präsentieren']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documentsList = []\n",
    "\n",
    "#Aufruf der Funktion zum Einlesen der Dokumente\n",
    "documents = read_documents(\"./Artikel/*.txt\")\n",
    "for key in documents:\n",
    "    documentsList.append(key)\n",
    "    \n",
    "documentsList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Was ist Natural Language Processing?\n",
    "\n",
    "### -eine mit der Computerlinguistik verwandte Disziplin\n",
    "\n",
    "### -Verarbeitung natürlicher Sprache (gesprochen und als Text) durch Computer\n",
    "\n",
    "### -Interaktion zwischen Mensch und Maschine auf der Basis menschlicher Sprache\n",
    "\n",
    "### -Befähigt Software menschliche Sprache als Input zu erfassen und passende Ergebnisse als Output zur Verfügung zu stellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warum Natural Language Processing?\n",
    "\n",
    "### -alleine  durch  die  Nutzung  sozialer  Medien, bspw. durch Messenger-Nachrichten, Status-Updates, usw., entsteht pro Minute ein Datenvolumen von 2000 TB an Daten\n",
    "\n",
    "### -Informationen und Inhalte werden direkt vom Kunden erstellt\n",
    "\n",
    "### -Menschen unterschiedlicher Demographien, Regionen und Kulturen\n",
    "\n",
    "### -nützlich bei der Erstellung von Kundenprofilen, sowie dem Erkennen von Trends und Entwicklungen\n",
    "\n",
    "### -ermöglicht die Erstellung Sprach getriebener Software-Produkte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einsatz von Natural Language Processing\n",
    "\n",
    "### Sprachassistenten\n",
    "\n",
    "![Siri](<https://sophosnews.files.wordpress.com/2017/07/siri-1200.jpg?w=780&h=408&crop=1>)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## bessere Übersetzungen dank des mit Einbeziehens von Grammatik und Semantik\n",
    "\n",
    "![Google Tranlate](<http://icons.iconarchive.com/icons/marcus-roberto/google-play/256/Google-Translate-icon.png>)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## die \"beliebten\" Chatbots\n",
    "\n",
    "![Chatbot](<https://mobilemonkey.com/wp-content/uploads/2017/04/efYxWC6.jpg>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ein Anwendungsbeispiel: Named Entity Recognition\n",
    "\n",
    "## Was ist Named Entity Recognition, bzw. \"Eigennamenerkennung\"?\n",
    "### -automatische Identifikation und Klassifikation von Eigennamen\n",
    "\n",
    "### -ein Eigenname beschreibt eine real existierende Identität\n",
    "### -> Personen\n",
    "### -> Organisationen\n",
    "### -> Orte\n",
    "### -> etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispielsatz: Stephan Becker fährt mit seinem Auto zur TDWI nach München"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import de_core_news_sm\n",
    "nlp = de_core_news_sm.load()\n",
    "\n",
    "#Definieren eines Texts\n",
    "text = 'Stephan Becker fährt mit dem Auto zur TDWI nach München.'\n",
    "\n",
    "#Übergabe des Texts an die spaCy-Pipeline\n",
    "doc = nlp(text)\n",
    "\n",
    "sentences = [x for x in doc.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### automatisches Erkennen von Entitäten in Sätzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Stephan Becker\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " fährt mit dem Auto zur \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    TDWI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " nach \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    München\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(sentences[0].string), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### erkennen grammatikalischer Komponenten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"114-0\" class=\"displacy\" width=\"1250\" height=\"317.0\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Stephan</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">Becker</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">fährt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">mit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">dem</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Auto</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">zur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">TDWI</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">nach</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">München.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,122.0 160.0,122.0 160.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pnc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-1\" stroke-width=\"2px\" d=\"M190,182.0 C190,122.0 280.0,122.0 280.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,184.0 L182,172.0 198,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-2\" stroke-width=\"2px\" d=\"M310,182.0 C310,122.0 400.0,122.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,184.0 L408.0,172.0 392.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-3\" stroke-width=\"2px\" d=\"M550,182.0 C550,122.0 640.0,122.0 640.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550,184.0 L542,172.0 558,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-4\" stroke-width=\"2px\" d=\"M430,182.0 C430,62.0 645.0,62.0 645.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M645.0,184.0 L653.0,172.0 637.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-5\" stroke-width=\"2px\" d=\"M310,182.0 C310,2.0 770.0,2.0 770.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,184.0 L778.0,172.0 762.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-6\" stroke-width=\"2px\" d=\"M790,182.0 C790,122.0 880.0,122.0 880.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880.0,184.0 L888.0,172.0 872.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-7\" stroke-width=\"2px\" d=\"M910,182.0 C910,122.0 1000.0,122.0 1000.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">mnr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1000.0,184.0 L1008.0,172.0 992.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-114-0-8\" stroke-width=\"2px\" d=\"M1030,182.0 C1030,122.0 1120.0,122.0 1120.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-114-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120.0,184.0 L1128.0,172.0 1112.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp((sentences[0].string)), style='dep', jupyter = True, options = {'distance': 120})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsmöglichkeiten?\n",
    "\n",
    "-> z.B. zur Anonymisierung von Personen in Texten\n",
    "\n",
    "<img src=\"./Grafiken/NaturalEntityRecognition.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definieren eines Texts\n",
    "text = 'Stephan Becker fährt mit dem Auto zur TDWI nach München.'\n",
    "\n",
    "#Übergabe des Texts an die spaCy-Pipeline\n",
    "doc = nlp(text)\n",
    "\n",
    "#Liste aus welcher das zensierte Dokument neu aufgebaut wird\n",
    "censored = []\n",
    "\n",
    "#Iterieren über jedes Wort des zu zensierenden Texts\n",
    "for word in doc:\n",
    "    \n",
    "    #falls ein Wort mit dem Tag 'PER' als Name markiert wurde, wird dieser durch die Zeichenkombination 'XXXXX' ersetzt\n",
    "    if word.ent_type_ == 'PER' and len(word) > 1:\n",
    "        cens = 'X'*5\n",
    "        censored.append(cens)\n",
    "        \n",
    "    #andernfalls erfolgt eine unzensierte Übernahme\n",
    "    else:\n",
    "        censored.append(word.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['XXXXX', 'XXXXX', 'fährt', 'mit', 'dem', 'Auto', 'zur', 'TDWI', 'nach', 'München', '.']\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(censored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/Agenda/Normalisierung.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Normalisierung\n",
    "\n",
    "### Den  ersten  Schritt  bei  der  Aufbereitung  von  Textdaten,  stellt  die  sogenannte  Normalisierung  dar.  Durch  Bereinigen  und  Standardisieren  werden  Textdaten  bei  der  Textnormalisierung in eine standardisierte Form überführt, welche für weitere Analysen genutzt werden kann. Textnormalisierung ist ein Prozess, welcher sich meist aus einzelnen Schritten zusammensetzt, welche im Folgenden erläutert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dokument_1 = 'Das Auto fährt schnell. Ein Auto ist kein Motorrad.'\n",
    "Dokument_2 = 'Der Zug fährt schneller als das Auto'\n",
    "Dokument_3 = 'Ein Flugzeug fliegt'\n",
    "\n",
    "beispiel = {}\n",
    "beispiel['Dokument_1'] = Dokument_1\n",
    "beispiel['Dokument_2'] = Dokument_2\n",
    "beispiel['Dokument_3'] = Dokument_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenisierung\n",
    "\n",
    "### -Worte sind die kleinste Informationstragende Einheit in Sprachen\n",
    "### -Tokenisierung bedeutet die Zerlegung von Text in einzelne Worte, bzw. \"Token\"\n",
    "### -Üblicherweise der erste Schritt um Zugang zu der im Text enthaltenen Information zu erlangen\n",
    "\n",
    "### ABER:\n",
    "### -Satzstrukturen gehen verloren\n",
    "### -daher nicht für semantische Analysen wie Named Entity Recognition geeignet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ein einfaches Beispiel:\n",
    "\n",
    "'Das Auto fährt schnell. Ein Auto ist kein Motorrad.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Das', 'Auto', 'fährt', 'schnell.', 'Ein', 'Auto', 'ist', 'kein', 'Motorrad.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel.get('Dokument_1').split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ein einfaches \"Zerteilen\" des Satzes ist nicht ausreichend: \n",
    "### -Satzzeichen werden nicht von Worten getrennt: 'Angebot.'\n",
    "### -Zeilenumbrüche werden nicht ignoriert:  \"\\n',\", \"Euro.\\\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel eines simplen Tokenizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(documents):\n",
    "    tokenized = {}\n",
    "    \n",
    "    #Iterieren über jedes Dokument\n",
    "    for doc in documents:\n",
    "        \n",
    "        document = documents.get(doc)\n",
    "        \n",
    "        #Festlegen von Sonderzeichen, welche entfernt werden sollen\n",
    "        punctuations = ['(',')',';',':','[',']','{','}',',','.','-','``',\"''\",'!','\\\"','§','$','%','&','?','@','+','–','~','*','#','\\'','\\\\n','\\\\','„','“']\n",
    "        \n",
    "        #Liste der einzelnen, sauberen Token\n",
    "        cleaned = []\n",
    "        \n",
    "        #Zerteilen des Dokuments in zunächst unsaubere Token\n",
    "        token = document.split(' ')\n",
    "        \n",
    "        #Iterieren über Token-Liste\n",
    "        for t in token:\n",
    "            temp = t\n",
    "            \n",
    "            #Iterieren über Sonderzeichen-Liste\n",
    "            for p in punctuations:\n",
    "                \n",
    "                #falls ein Sonderzeichen vorhanden ist, wird es entfernt\n",
    "                if p in t:\n",
    "                    temp = temp.replace(p, '')\n",
    "                    \n",
    "            #alle Worte, bzw. Token werden kleingeschrieben übernommen\n",
    "            cleaned.append(temp.lower())\n",
    "            \n",
    "        tokenized[doc] = cleaned\n",
    "\n",
    "    return(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dokument_1': ['das',\n",
       "  'auto',\n",
       "  'fährt',\n",
       "  'schnell',\n",
       "  'ein',\n",
       "  'auto',\n",
       "  'ist',\n",
       "  'kein',\n",
       "  'motorrad'],\n",
       " 'Dokument_2': ['der', 'zug', 'fährt', 'schneller', 'als', 'das', 'auto'],\n",
       " 'Dokument_3': ['ein', 'flugzeug', 'fliegt']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Übergabe Zeitungsartikel\n",
    "tokenized = tokenizer(documents)\n",
    "\n",
    "#Übergabe Beispiel\n",
    "beispiel_tokenized = tokenizer(beispiel)\n",
    "beispiel_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords\n",
    "\n",
    "### Stopwords sind Worte welche häufig vorkommen, meist jedoch wenig an benötigter Information enthalten\n",
    "### -Bspw.: der, die, das, dem, dessen, etc.\n",
    "### -Aussortieren, um größe des Datensatzes zu reduzieren und eine mögliche Überlagerung der eigentlich interessanten Information zu verhindern\n",
    "### -es sind auch sogenannte Startwords möglich, mit deren Hilfe schnell und einfach untersucht werden kann, ob ein Text thematisch überhaupt interessant ist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beispiel Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords(tokenized):\n",
    "    \n",
    "    #Definieren einer Liste, welche alle unerwünschten Worte enthält\n",
    "    stopwords = [\"ab\",\"aber\",\"ach\",\"acht\",\"achte\",\"achten\",\"achter\",\"achtes\",\"ag\",\"alle\",\"allein\",\"allem\",\"allen\",\"aller\",\"allerdings\",\"alles\",\"allgemeinen\",\"als\",\"also\",\"am\",\"an\",\"ander\",\"andere\",\"anderem\",\"anderen\",\"anderer\",\"anderes\",\"anderm\",\"andern\",\"anderr\",\"anders\",\"au\",\"auch\",\"auf\",\"aus\",\"ausser\",\"ausserdem\",\"außer\",\"außerdem\",\"b\",\"bald\",\"bei\",\"beide\",\"beiden\",\"beim\",\"beispiel\",\"bekannt\",\"bereits\",\"besonders\",\"besser\",\"besten\",\"bin\",\"bis\",\"bisher\",\"bist\",\"c\",\"d\",\"d.h\",\"da\",\"dabei\",\"dadurch\",\"dafür\",\"dagegen\",\"daher\",\"dahin\",\"dahinter\",\"damals\",\"damit\",\"danach\",\"daneben\",\"dank\",\"dann\",\"daran\",\"darauf\",\"daraus\",\"darf\",\"darfst\",\"darin\",\"darum\",\"darunter\",\"darüber\",\"das\",\"dasein\",\"daselbst\",\"dass\",\"dasselbe\",\"davon\",\"davor\",\"dazu\",\"dazwischen\",\"daß\",\"dein\",\"deine\",\"deinem\",\"deinen\",\"deiner\",\"deines\",\"dem\",\"dementsprechend\",\"demgegenüber\",\"demgemäss\",\"demgemäß\",\"demselben\",\"demzufolge\",\"den\",\"denen\",\"denn\",\"denselben\",\"der\",\"deren\",\"derer\",\"derjenige\",\"derjenigen\",\"dermassen\",\"dermaßen\",\"derselbe\",\"derselben\",\"des\",\"deshalb\",\"desselben\",\"dessen\",\"deswegen\",\"dich\",\"die\",\"diejenige\",\"diejenigen\",\"dies\",\"diese\",\"dieselbe\",\"dieselben\",\"diesem\",\"diesen\",\"dieser\",\"dieses\",\"dir\",\"doch\",\"dort\",\"drei\",\"drin\",\"dritte\",\"dritten\",\"dritter\",\"drittes\",\"du\",\"durch\",\"durchaus\",\"durfte\",\"durften\",\"dürfen\",\"dürft\",\"e\",\"eben\",\"ebenso\",\"ehrlich\",\"ei\",\"ei,\",\"eigen\",\"eigene\",\"eigenen\",\"eigener\",\"eigenes\",\"ein\",\"einander\",\"eine\",\"einem\",\"einen\",\"einer\",\"eines\",\"einig\",\"einige\",\"einigem\",\"einigen\",\"einiger\",\"einiges\",\"einmal\",\"eins\",\"elf\",\"en\",\"ende\",\"endlich\",\"entweder\",\"er\",\"ernst\",\"erst\",\"erste\",\"ersten\",\"erster\",\"erstes\",\"es\",\"etwa\",\"etwas\",\"euch\",\"euer\",\"eure\",\"eurem\",\"euren\",\"eurer\",\"eures\",\"f\",\"folgende\",\"früher\",\"fünf\",\"fünfte\",\"fünften\",\"fünfter\",\"fünftes\",\"für\",\"g\",\"gab\",\"ganz\",\"ganze\",\"ganzen\",\"ganzer\",\"ganzes\",\"gar\",\"gedurft\",\"gegen\",\"gegenüber\",\"gehabt\",\"gehen\",\"geht\",\"gekannt\",\"gekonnt\",\"gemacht\",\"gemocht\",\"gemusst\",\"genug\",\"gerade\",\"gern\",\"gesagt\",\"geschweige\",\"gewesen\",\"gewollt\",\"geworden\",\"gibt\",\"ging\",\"gleich\",\"gott\",\"gross\",\"grosse\",\"grossen\",\"grosser\",\"grosses\",\"groß\",\"große\",\"großen\",\"großer\",\"großes\",\"gut\",\"gute\",\"guter\",\"gutes\",\"h\",\"hab\",\"habe\",\"haben\",\"habt\",\"hast\",\"hat\",\"hatte\",\"hatten\",\"hattest\",\"hattet\",\"heisst\",\"her\",\"heute\",\"hier\",\"hin\",\"hinter\",\"hoch\",\"hätte\",\"hätten\",\"i\",\"ich\",\"ihm\",\"ihn\",\"ihnen\",\"ihr\",\"ihre\",\"ihrem\",\"ihren\",\"ihrer\",\"ihres\",\"im\",\"immer\",\"in\",\"indem\",\"infolgedessen\",\"ins\",\"irgend\",\"ist\",\"j\",\"ja\",\"jahr\",\"jahre\",\"jahren\",\"je\",\"jede\",\"jedem\",\"jeden\",\"jeder\",\"jedermann\",\"jedermanns\",\"jedes\",\"jedoch\",\"jemand\",\"jemandem\",\"jemanden\",\"jene\",\"jenem\",\"jenen\",\"jener\",\"jenes\",\"jetzt\",\"k\",\"kam\",\"kann\",\"kannst\",\"kaum\",\"kein\",\"keine\",\"keinem\",\"keinen\",\"keiner\",\"keines\",\"kleine\",\"kleinen\",\"kleiner\",\"kleines\",\"kommen\",\"kommt\",\"konnte\",\"konnten\",\"kurz\",\"können\",\"könnt\",\"könnte\",\"l\",\"lang\",\"lange\",\"leicht\",\"leide\",\"lieber\",\"los\",\"m\",\"machen\",\"macht\",\"machte\",\"mag\",\"magst\",\"mahn\",\"mal\",\"man\",\"manche\",\"manchem\",\"manchen\",\"mancher\",\"manches\",\"mann\",\"mehr\",\"mein\",\"meine\",\"meinem\",\"meinen\",\"meiner\",\"meines\",\"mensch\",\"menschen\",\"mich\",\"mir\",\"mit\",\"mittel\",\"mochte\",\"mochten\",\"morgen\",\"muss\",\"musst\",\"musste\",\"mussten\",\"muß\",\"mußt\",\"möchte\",\"mögen\",\"möglich\",\"mögt\",\"müssen\",\"müsst\",\"müßt\",\"n\",\"na\",\"nach\",\"nachdem\",\"nahm\",\"natürlich\",\"neben\",\"nein\",\"neue\",\"neuen\",\"neun\",\"neunte\",\"neunten\",\"neunter\",\"neuntes\",\"nicht\",\"nichts\",\"nie\",\"niemand\",\"niemandem\",\"niemanden\",\"noch\",\"nun\",\"nur\",\"o\",\"ob\",\"oben\",\"oder\",\"offen\",\"oft\",\"ohne\",\"ordnung\",\"p\",\"q\",\"r\",\"recht\",\"rechte\",\"rechten\",\"rechter\",\"rechtes\",\"richtig\",\"rund\",\"s\",\"sa\",\"sache\",\"sagt\",\"sagte\",\"sah\",\"satt\",\"schlecht\",\"schluss\",\"schon\",\"sechs\",\"sechste\",\"sechsten\",\"sechster\",\"sechstes\",\"sehr\",\"sei\",\"seid\",\"seien\",\"sein\",\"seine\",\"seinem\",\"seinen\",\"seiner\",\"seines\",\"seit\",\"seitdem\",\"selbst\",\"sich\",\"sie\",\"sieben\",\"siebente\",\"siebenten\",\"siebenter\",\"siebentes\",\"sind\",\"so\",\"solang\",\"solche\",\"solchem\",\"solchen\",\"solcher\",\"solches\",\"soll\",\"sollen\",\"sollst\",\"sollt\",\"sollte\",\"sollten\",\"sondern\",\"sonst\",\"soweit\",\"sowie\",\"später\",\"startseite\",\"statt\",\"steht\",\"suche\",\"t\",\"tag\",\"tage\",\"tagen\",\"tat\",\"teil\",\"tel\",\"tritt\",\"trotzdem\",\"tun\",\"u\",\"uhr\",\"um\",\"und\",\"und?\",\"uns\",\"unse\",\"unsem\",\"unsen\",\"unser\",\"unsere\",\"unserer\",\"unses\",\"unter\",\"v\",\"vergangenen\",\"viel\",\"viele\",\"vielem\",\"vielen\",\"vielleicht\",\"vier\",\"vierte\",\"vierten\",\"vierter\",\"viertes\",\"vom\",\"von\",\"vor\",\"w\",\"wahr?\",\"wann\",\"war\",\"waren\",\"warst\",\"wart\",\"warum\",\"was\",\"weg\",\"wegen\",\"weil\",\"weit\",\"weiter\",\"weitere\",\"weiteren\",\"weiteres\",\"welche\",\"welchem\",\"welchen\",\"welcher\",\"welches\",\"wem\",\"wen\",\"wenig\",\"wenige\",\"weniger\",\"weniges\",\"wenigstens\",\"wenn\",\"wer\",\"werde\",\"werden\",\"werdet\",\"weshalb\",\"wessen\",\"wie\",\"wieder\",\"wieso\",\"will\",\"willst\",\"wir\",\"wird\",\"wirklich\",\"wirst\",\"wissen\",\"wo\",\"woher\",\"wohin\",\"wohl\",\"wollen\",\"wollt\",\"wollte\",\"wollten\",\"worden\",\"wurde\",\"wurden\",\"während\",\"währenddem\",\"währenddessen\",\"wäre\",\"würde\",\"würden\",\"x\",\"y\",\"z\",\"z.b\",\"zehn\",\"zehnte\",\"zehnten\",\"zehnter\",\"zehntes\",\"zeit\",\"zu\",\"zuerst\",\"zugleich\",\"zum\",\"zunächst\",\"zur\",\"zurück\",\"zusammen\",\"zwanzig\",\"zwar\",\"zwei\",\"zweite\",\"zweiten\",\"zweiter\",\"zweites\",\"zwischen\",\"zwölf\",\"über\",\"überhaupt\",\"übrigens\"]\n",
    "    \n",
    "    removed = {}\n",
    "    \n",
    "    #Iterieren über alle Dokumente\n",
    "    for doc in tokenized:\n",
    "        document = tokenized.get(doc)\n",
    "        \n",
    "        #Iterieren über Stopwords-Liste\n",
    "        no_stopwords = [token for token in document if not token in stopwords]\n",
    "        removed[doc] = no_stopwords\n",
    "    \n",
    "    return(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dokument_1': ['auto', 'fährt', 'schnell', 'auto', 'motorrad'],\n",
       " 'Dokument_2': ['zug', 'fährt', 'schneller', 'auto'],\n",
       " 'Dokument_3': ['flugzeug', 'fliegt']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Übergabe tokenisierte Zeitungsartikel\n",
    "stopwordsRemoved = stopwords(tokenized)\n",
    "\n",
    "#Übergabe tokenisierte Beispiele\n",
    "beispiel_stopwords = stopwords(beispiel_tokenized)\n",
    "beispiel_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/Agenda/Sentiment.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "### Sentiment = Gefühl, Empfindung\n",
    "### Möglichkeit um die \"Stimmung\" oder \"Gefühlslage\" in einem Text zu analysieren\n",
    "\n",
    "### Anwendung bspw. als Ergänzung zur Analyse der Stimmung von Investoren oder im Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktionsweise:\n",
    "\n",
    "### -Worte werden als positive oder negative Signale festgelegt\n",
    "### -Bspw. \"stark\", \"gut\", \"schnell\" als positive, oder \"schwach\", \"schlecht\", \"langsam\" als negative\n",
    "### -Überprüfung des Verhältnisses, in welchem positive und negative Worte in einem Text vorkommen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sentiment-Analyse](<./Grafiken/Sentiment_Analysis.jpg>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anwendungsbeispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(documents):\n",
    "    import json\n",
    "    \n",
    "    #Liste mit positiven Worten\n",
    "    with open('./SentimentAnalysis/positive.json') as positive:  \n",
    "        positiveWords = json.load(positive)\n",
    "        \n",
    "    #Liste mit negativen Worten\n",
    "    with open('./SentimentAnalysis/negative.json') as negative:  \n",
    "        negativeWords = json.load(negative)\n",
    "    \n",
    "    #Iterieren über alle Dokumente\n",
    "    for doc in documents:\n",
    "        \n",
    "        #Counter für positive sowie negative Worte pro Dokument\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        text = documents.get(doc)\n",
    "        \n",
    "        #Gesamtlänge des Dokuments\n",
    "        summe = len(text)\n",
    "        \n",
    "        #Überprüfen jedes einzelnen Token im Dokument, ob er positiv oder negativ ist\n",
    "        for token in text:\n",
    "            if token in positiveWords:\n",
    "                positive += 1\n",
    "            elif token in negativeWords:\n",
    "                negative += 1\n",
    "                \n",
    "        #Überprüfen, ob mehr positive oder negative Worte vorkamen\n",
    "        if positive > negative:\n",
    "            print(\"Der Artikel '\" + doc + \"' ist überwiegend positiv (\" + str(round((positive/summe)*100, 2)) + \"%)\")\n",
    "        elif negative > positive:\n",
    "            print(\"Der Artikel '\" + doc + \"' ist überwiegend negativ (\" + str(round((negative/summe)*100, 2)) + \"%)\")\n",
    "        elif positive == negative:\n",
    "            print(\"Der Artikel '\" + doc + \"' ist neutral\")\n",
    "        print('_'*150)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Artikel '(Sport) Joachim Löw und die Nationalelf' ist überwiegend positiv (1.24%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Sport) Zweite Bundesliga' ist überwiegend negativ (4.95%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Politik ) Der Brandbeschleuniger im Weißen Haus' ist neutral\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Politik ) Weißes Haus rechnet mit Schließung der Grenze zu Mexiko' ist überwiegend positiv (3.7%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Politik ) Der Vorwurf eines unerwünschten Kusses' ist neutral\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Finanzen) Natixis im Gespräch' ist überwiegend positiv (5.43%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Motor) Blitz und Schatten' ist überwiegend positiv (6.17%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Finanzen) Bankenmarkt' ist überwiegend positiv (4.46%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Motor) Mittelklasse, nur nicht beim Preis' ist überwiegend positiv (4.27%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Motor) Tesla im Fahrtest' ist überwiegend positiv (4.51%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Apple) Bleibt doch noch ein bisschen' ist überwiegend positiv (5.71%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Finanzen) Basel IV' ist überwiegend positiv (3.01%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Apple) Lebensrettende Massnahmen für Apple TV' ist überwiegend positiv (3.57%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Motor) Deutschland sucht das Super-SUV' ist überwiegend positiv (4.75%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Politik ) Trump, Trump und nochmals Trump' ist überwiegend negativ (4.78%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Motor) BMW setzt noch einen drauf' ist überwiegend positiv (4.63%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Sport) Dramatischer Liverpool-Sieg durch spätes Eigentor' ist überwiegend positiv (5.75%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Sport) Klopp geht all in und gewinnt ' ist überwiegend positiv (3.85%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Sport) Jetzt wird Bayern nervös' ist überwiegend positiv (3.9%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Politik ) Was Kim kann, kann Trump auch' ist überwiegend positiv (3.7%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Finanzen) Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei' ist überwiegend positiv (7.2%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Finanzen) Die Mailänder Börse ist in Feierlaune' ist überwiegend positiv (2.21%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Apple) Konkurrenz für Netflix' ist überwiegend positiv (4.35%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Apple) Ladematte AirPower' ist überwiegend negativ (6.09%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Der Artikel '(Apple) Hollywood-Stars präsentieren' ist überwiegend positiv (4.52%)\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n"
     ]
    }
   ],
   "source": [
    "sentimentAnalysis(stopwordsRemoved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisse im Detail:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Artikel 'BMW setzt noch einen drauf' ist überwiegend positiv (4.63%)\n",
    "\n",
    "## positiv: \n",
    "['mächtige', 'wagte', 'stattliche', 'großem', 'wert', 'erneuerten', 'verantwortlichen', 'starkes', 'maximale', 'verstärkungen', 'spezielle', \n",
    "\n",
    "## negativ: \n",
    "['beeindruckte', 'ruhe', 'schlechter']\n",
    "\n",
    "\n",
    "\n",
    "## Der Artikel 'Der Vorwurf eines unerwünschten Kusses' ist neutral\n",
    "\n",
    "## positiv:\n",
    "['mögliche', 'mögliche', 'erklärte', 'sicher']\n",
    "\n",
    "## negativ:\n",
    "['vorwürfe', 'vorwürfe', 'vorwürfen', 'unangemessenes']\n",
    "\n",
    "\n",
    "\n",
    "## Der Artikel 'Trump, Trump und nochmals Trump' ist überwiegend negativ (4,78%)\n",
    "\n",
    "## positiv:\n",
    "['gewinnen', 'möglichst', 'kommunikativen', 'gepflegtere', 'wiederherstellung', 'guten', 'gelassene', 'möglichst']\n",
    "\n",
    "## negativ:\n",
    "['schelten', 'unzufriedenen', 'tote', 'bizarre', 'sorgen', 'attacken', 'kriminelle', 'schwerer', 'drastische', 'bitterer', 'blutigen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/Agenda/Vektorisierung.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vektorisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herausforderungen\n",
    "\n",
    "## Typischerweise werden durch Algorithmen strukturierte, numerische Daten analysiert\n",
    "\n",
    "<img src=\"./Grafiken/Netzwerk_Daten.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Was sind strukturierte Daten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribut_1</th>\n",
       "      <th>Attribut_2</th>\n",
       "      <th>Attribut_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Attribut_1 Attribut_2 Attribut_3\n",
       "0          X          X          X\n",
       "1          X          X          X\n",
       "2          X          X          X"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attribut_1 = ['X','X','X']\n",
    "Attribut_2 = ['X','X','X']\n",
    "Attribut_3 = ['X','X','X']\n",
    "\n",
    "array = {}\n",
    "array['Attribut_1'] = Attribut_1\n",
    "array['Attribut_2'] = Attribut_2\n",
    "array['Attribut_3'] = Attribut_3\n",
    "\n",
    "import pandas as pd\n",
    "Dataframe = pd.DataFrame.from_dict(array)\n",
    "Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Länge</th>\n",
       "      <th>Breite</th>\n",
       "      <th>Höhe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Länge  Breite  Höhe\n",
       "0      3       9     4\n",
       "1      5       7     2\n",
       "2      8       3     7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Länge = [3,5,8]\n",
    "Breite = [9,7,3]\n",
    "Höhe = [4,2,7]\n",
    "\n",
    "maßearray = {}\n",
    "maßearray['Länge'] = Länge\n",
    "maßearray['Breite'] = Breite\n",
    "maßearray['Höhe'] = Höhe\n",
    "\n",
    "import pandas as pd\n",
    "MaßeDataframe = pd.DataFrame.from_dict(maßearray)\n",
    "MaßeDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Haus</th>\n",
       "      <th>Auto</th>\n",
       "      <th>Flugzeug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>groß</td>\n",
       "      <td>schnell</td>\n",
       "      <td>Triebwerk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breit</td>\n",
       "      <td>BMW</td>\n",
       "      <td>Airbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neu</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>fliegt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Haus     Auto   Flugzeug\n",
       "0   groß  schnell  Triebwerk\n",
       "1  breit      BMW     Airbus\n",
       "2    neu  Porsche     fliegt"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Haus = ['groß', 'breit', 'neu']\n",
    "Auto = ['schnell', 'BMW', 'Porsche']\n",
    "Flugzeug = ['Triebwerk', 'Airbus', 'fliegt']\n",
    "\n",
    "wortearray = {}\n",
    "wortearray['Haus'] = Haus\n",
    "wortearray['Auto'] = Auto\n",
    "wortearray['Flugzeug'] = Flugzeug\n",
    "WorteDataframe = pd.DataFrame.from_dict(wortearray)\n",
    "WorteDataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bildung des Vokabulars\n",
    "### -enthält jedes im Dokument, bzw. Dokumenten-Korpus, vorkommende Wort (Token) genau einmal\n",
    "### -ein Token ist ein Attribut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dokument_1': ['auto', 'fährt', 'schnell', 'auto', 'motorrad'],\n",
       " 'Dokument_2': ['zug', 'fährt', 'schneller', 'auto'],\n",
       " 'Dokument_3': ['flugzeug', 'fliegt']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### für das Vokabular folgt:\n",
    "## Vokabular = ['auto', fliegt', 'flugzeug', 'fährt', 'motorrad', 'schnell', 'schneller', 'zug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary(documents):\n",
    "    \n",
    "    vocabulary = set()\n",
    "    #Iterieren über alle Dokumente\n",
    "    \n",
    "    for key in documents:\n",
    "        \n",
    "        #Übernahme des gesamten Texts\n",
    "        text = documents.get(key)\n",
    "        \n",
    "        #Hinzufügen jener Worte zum Vokabular, welche noch nicht enthalten sinf\n",
    "        vocabulary = vocabulary.union(text)\n",
    "    \n",
    "    return(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'fliegt', 'motorrad', 'fährt', 'schnell', 'schneller', 'auto', 'flugzeug', 'zug'}\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_vocabulary = get_vocabulary(beispiel_stopwords)\n",
    "str(beispiel_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Überführung in einen Vektorraum\n",
    "## $VR=\\{W_1,W_2,\\dots,W_N\\}$\n",
    "## Anzahl der Worte bestimmt die Dimensinalität des Vektors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fliegt</th>\n",
       "      <th>motorrad</th>\n",
       "      <th>fährt</th>\n",
       "      <th>schnell</th>\n",
       "      <th>schneller</th>\n",
       "      <th>auto</th>\n",
       "      <th>flugzeug</th>\n",
       "      <th>zug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dokument_1</th>\n",
       "      <td>W_11</td>\n",
       "      <td>W_12</td>\n",
       "      <td>W_13</td>\n",
       "      <td>W_14</td>\n",
       "      <td>W_15</td>\n",
       "      <td>W_16</td>\n",
       "      <td>W_17</td>\n",
       "      <td>W_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_2</th>\n",
       "      <td>W_21</td>\n",
       "      <td>W_22</td>\n",
       "      <td>W_23</td>\n",
       "      <td>W_24</td>\n",
       "      <td>W_25</td>\n",
       "      <td>W_26</td>\n",
       "      <td>W_27</td>\n",
       "      <td>W_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_3</th>\n",
       "      <td>W_31</td>\n",
       "      <td>W_32</td>\n",
       "      <td>W_33</td>\n",
       "      <td>W_34</td>\n",
       "      <td>W_35</td>\n",
       "      <td>W_36</td>\n",
       "      <td>W_37</td>\n",
       "      <td>W_38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fliegt motorrad fährt schnell schneller  auto flugzeug   zug\n",
       "Dokument_1   W_11     W_12  W_13    W_14      W_15  W_16     W_17  W_18\n",
       "Dokument_2   W_21     W_22  W_23    W_24      W_25  W_26     W_27  W_28\n",
       "Dokument_3   W_31     W_32  W_33    W_34      W_35  W_36     W_37  W_38"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [('W_11', 'W_12', 'W_13', 'W_14', 'W_15', 'W_16', 'W_17', 'W_18'), ('W_21', 'W_22', 'W_23', 'W_24', 'W_25', 'W_26', 'W_27', 'W_28'), ('W_31', 'W_32', 'W_33', 'W_34', 'W_35', 'W_36', 'W_37', 'W_38')]\n",
    "df = pd.DataFrame(data, columns=beispiel_vocabulary, index=['Dokument_1', 'Dokument_2', 'Dokument_3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "### -einfacher Ansatz in welchem ein Dokument als ein \"Bag\" aus Worten (unabhängig von Folgen und Grammatik) repräsentiert wird\n",
    "### -die Gewichtung eines Wortes basiert auf der absoluten Häufigkeit, mit welcher es im Dokument vorkommt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(documents, vocabulary):\n",
    "    import pandas as pd\n",
    "    bow = {}\n",
    "    \n",
    "    #Iterieren über alles Dokuemente\n",
    "    for key in documents:\n",
    "        document = documents.get(key)\n",
    "        \n",
    "        #Erstellen eines temporären Dictionaries, jedes Attribut ist zu Beginn = 0\n",
    "        dictTemp = dict.fromkeys(vocabulary, 0)\n",
    "        \n",
    "        #Iterieren über alle Token\n",
    "        for token in document:\n",
    "            \n",
    "            #der Zähler (Value) wird bei Vorhandensein eines entsprechenden Tokens um +1 heraufgesetzt\n",
    "            dictTemp[token]+=1\n",
    "            \n",
    "        #die Ergebnisse werden für jedes Dokument in einem Dictionary gespeichert\n",
    "        bow[key] = dictTemp\n",
    "        \n",
    "    #Erstellen eines Dataframes zur besseren Veranschaulichung\n",
    "    bowDF = pd.DataFrame(bow).T\n",
    "        \n",
    "    return(bow, bowDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto</th>\n",
       "      <th>fliegt</th>\n",
       "      <th>flugzeug</th>\n",
       "      <th>fährt</th>\n",
       "      <th>motorrad</th>\n",
       "      <th>schnell</th>\n",
       "      <th>schneller</th>\n",
       "      <th>zug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dokument_1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            auto  fliegt  flugzeug  fährt  motorrad  schnell  schneller  zug\n",
       "Dokument_1     2       0         0      1         1        1          0    0\n",
       "Dokument_2     1       0         0      1         0        0          1    1\n",
       "Dokument_3     0       1         1      0         0        0          0    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_bow, beispiel_bowDF = bag_of_words(beispiel_stopwords, beispiel_vocabulary)\n",
    "beispiel_bowDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "### -Beurteilung der Relevanz von Worten innerhalb eines Dokumenten-Korpus\n",
    "### -Relevanz eines Wortes innerhalb eines Dokuments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency\n",
    "\n",
    "### -entspricht wie Bag-of-Words der absoluten Häufigkeit, mit welcher ein Termn in einem einzigen Dokuemnt vorkommt\n",
    "\n",
    "### auch relative Vorkommensheit möglich, um den Einfluss der Gesamtlänge des Dokuments zu reduzieren:\n",
    "\n",
    "### $tf(t,D) = \\frac{f_{t_D}}{max_{t'\\in D} f_{t_D}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(bow, documents):\n",
    "    import pandas as pd\n",
    "    tfDict= {}\n",
    "    \n",
    "    #Iterieren über alle Dokumente\n",
    "    for key in documents:\n",
    "        tfCount = {}\n",
    "        doc = documents.get(key)\n",
    "        \n",
    "        #Gesamtlänge des betrachteten Dokuments:\n",
    "        wordCount = len(doc)\n",
    "        \n",
    "        #Iterieren über die bereits vorhandenen Bag-of-Words Gewichtungen\n",
    "        for word, count in bow.get(key).items():\n",
    "            \n",
    "            #Bag-of-Words Count (Gewichtung) wird in Verhältnis zur Gesamtlänge des zugehörigen Dokuments gesetzt\n",
    "            tfCount[word] = count / float(wordCount)\n",
    "            \n",
    "        #die Ergebnisse werden für jedes Dokument in einem Dictionary gespeichert    \n",
    "        tfDict[key] = tfCount\n",
    "        \n",
    "    #Erstellen eines Dataframes zur besseren Veranschaulichung    \n",
    "    tfDF = pd.DataFrame(tfDict).T\n",
    "        \n",
    "    return(tfDict, tfDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto</th>\n",
       "      <th>fliegt</th>\n",
       "      <th>flugzeug</th>\n",
       "      <th>fährt</th>\n",
       "      <th>motorrad</th>\n",
       "      <th>schnell</th>\n",
       "      <th>schneller</th>\n",
       "      <th>zug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dokument_1</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            auto  fliegt  flugzeug  fährt  motorrad  schnell  schneller   zug\n",
       "Dokument_1  0.40     0.0       0.0   0.20       0.2      0.2       0.00  0.00\n",
       "Dokument_2  0.25     0.0       0.0   0.25       0.0      0.0       0.25  0.25\n",
       "Dokument_3  0.00     0.5       0.5   0.00       0.0      0.0       0.00  0.00"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_tf, beispiel_tfDF = term_frequency(beispiel_bow, beispiel_stopwords)\n",
    "beispiel_tfDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency\n",
    "\n",
    "### -inverse Dokumentenhäufigkeit\n",
    "### -Aussage über die Spezifität eines Wortes innerhalb eines Dokumenten-Korpus\n",
    "\n",
    "### $idf(t) = \\log \\frac{N}{\\sum{df(t)}}$\n",
    "\n",
    "### $N=$ Anzahl der Dokumente innerhalb des Korpus\n",
    "### $df(t)=$ Anzahl der Dokumente, welche einen spezifischen Term enthalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_document_frequency(bow):\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    \n",
    "    #Ermitteln der Anzahl an Dokumenten im Korpus\n",
    "    N = len(bow)\n",
    "    \n",
    "    #Übergabe des Vokabulars und setzen aller Werte = 0\n",
    "    idfDict = dict.fromkeys(bow[next(iter(bow))].keys(),0)\n",
    "    \n",
    "    #i = 0\n",
    "    for key in bow:\n",
    "        doc = bow.get(key)\n",
    "        \n",
    "        #Iterieren über Bag-of-Words Gewichtungen\n",
    "        for word, val in doc.items():\n",
    "            \n",
    "            #ist die Gewichtung größer Null, so ist ein Wort im entsprechenden Dokument vorhanden\n",
    "            if val > 0:\n",
    "                idfDict[word] +=1\n",
    "        #i = i + 1\n",
    "    for word, val in idfDict.items():\n",
    "        \n",
    "        #Erstellen der IDF (Logarithmus aus dem Verhältnis Gesamtanzahl Dokumente / Dokumente welche das Wort beinhalten)\n",
    "        idfDict[word]= math.log(N / float(val))\n",
    "    \n",
    "    return(idfDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fliegt': 1.0986122886681098,\n",
       " 'motorrad': 1.0986122886681098,\n",
       " 'fährt': 0.4054651081081644,\n",
       " 'schnell': 1.0986122886681098,\n",
       " 'schneller': 1.0986122886681098,\n",
       " 'auto': 0.4054651081081644,\n",
       " 'flugzeug': 1.0986122886681098,\n",
       " 'zug': 1.0986122886681098}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_idf = inverse_document_frequency(beispiel_bow)\n",
    "beispiel_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "$tfidf=tf\\times idf$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency_inverse_document_frequency(tfBow, idfs):\n",
    "    import pandas as pd\n",
    "    tfidf = {}\n",
    "    tfidfDict = {}\n",
    "    \n",
    "    #Iterieren über alle relativen Gewichtungen\n",
    "    for key in tfBow:\n",
    "        text = tfBow.get(key)\n",
    "        tfidf = {}\n",
    "        for word, val in text.items():\n",
    "            \n",
    "            #Bilden des Produkts aus Term Frequency und Inverse Document Frequency\n",
    "            tfidf[word] = val * idfs[word]\n",
    "        tfidfDict[key] = tfidf\n",
    "        \n",
    "    #Erstellen eines Dataframes zur besseren Veranschaulichung\n",
    "    tfidfDF = pd.DataFrame(tfidfDict).T\n",
    "    \n",
    "    return(tfidfDict, tfidfDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto</th>\n",
       "      <th>fliegt</th>\n",
       "      <th>flugzeug</th>\n",
       "      <th>fährt</th>\n",
       "      <th>motorrad</th>\n",
       "      <th>schnell</th>\n",
       "      <th>schneller</th>\n",
       "      <th>zug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dokument_1</th>\n",
       "      <td>0.810930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_2</th>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dokument_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                auto    fliegt  flugzeug     fährt  motorrad   schnell  \\\n",
       "Dokument_1  0.810930  0.000000  0.000000  0.405465  1.098612  1.098612   \n",
       "Dokument_2  0.405465  0.000000  0.000000  0.405465  0.000000  0.000000   \n",
       "Dokument_3  0.000000  1.098612  1.098612  0.000000  0.000000  0.000000   \n",
       "\n",
       "            schneller       zug  \n",
       "Dokument_1   0.000000  0.000000  \n",
       "Dokument_2   1.098612  1.098612  \n",
       "Dokument_3   0.000000  0.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beispiel_tfidf, beispiel_tfidfDF = term_frequency_inverse_document_frequency(beispiel_bow, beispiel_idf)\n",
    "beispiel_tfidfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Durchführen aller vorgestellten Schritte für die Zeitungsartikel\n",
    "vocabulary = get_vocabulary(stopwordsRemoved)\n",
    "bow, bowDF = bag_of_words(stopwordsRemoved, vocabulary)\n",
    "tf, tfDF = term_frequency(bow, stopwordsRemoved)\n",
    "idf = inverse_document_frequency(bow)\n",
    "tfidf, tfidfDF = term_frequency_inverse_document_frequency(bow, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>10000</th>\n",
       "      <th>105</th>\n",
       "      <th>109900</th>\n",
       "      <th>...</th>\n",
       "      <th>übertragenden</th>\n",
       "      <th>übertrieben</th>\n",
       "      <th>überzeugen</th>\n",
       "      <th>überzeugt</th>\n",
       "      <th>üble</th>\n",
       "      <th>üblicherweise</th>\n",
       "      <th>übrig</th>\n",
       "      <th>üppig</th>\n",
       "      <th>üppiger</th>\n",
       "      <th>€</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Sport) Joachim Löw und die Nationalelf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Zweite Bundesliga</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Der Brandbeschleuniger im Weißen Haus</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Weißes Haus rechnet mit Schließung der Grenze zu Mexiko</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.832581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Der Vorwurf eines unerwünschten Kusses</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Natixis im Gespräch</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) Blitz und Schatten</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Bankenmarkt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) Mittelklasse, nur nicht beim Preis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.665163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) Tesla im Fahrtest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.665163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Bleibt doch noch ein bisschen</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Basel IV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Lebensrettende Massnahmen für Apple TV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) Deutschland sucht das Super-SUV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.240527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Trump, Trump und nochmals Trump</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) BMW setzt noch einen drauf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Dramatischer Liverpool-Sieg durch spätes Eigentor</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.051457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Klopp geht all in und gewinnt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.832581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Jetzt wird Bayern nervös</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Was Kim kann, kann Trump auch</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Die Mailänder Börse ist in Feierlaune</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.875503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Konkurrenz für Netflix</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Ladematte AirPower</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Hollywood-Stars präsentieren</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 4599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               00       000  \\\n",
       "(Sport) Joachim Löw und die Nationalelf             0.0  0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                           0.0  3.218876  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.0  0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.0  0.000000  1.832581   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.0  0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.0  0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          0.0  0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.0  0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.0  0.000000  3.665163   \n",
       "(Motor) Tesla im Fahrtest                           0.0  0.000000  3.665163   \n",
       "(Apple) Bleibt doch noch ein bisschen               0.0  0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.0  0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.0  0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             0.0  0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.0  0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.0  0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  0.0  0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.0  0.000000  1.832581   \n",
       "(Sport) Jetzt wird Bayern nervös                    0.0  0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.0  0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.0  0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.0  0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.0  0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.0  0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.0  0.000000  0.000000   \n",
       "\n",
       "                                                          02        03  \\\n",
       "(Sport) Joachim Löw und die Nationalelf             2.525729  3.218876   \n",
       "(Sport) Zweite Bundesliga                           0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                           0.000000  0.000000   \n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  5.051457  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000  0.000000   \n",
       "\n",
       "                                                          10       100  \\\n",
       "(Sport) Joachim Löw und die Nationalelf             1.609438  0.000000   \n",
       "(Sport) Zweite Bundesliga                           0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000  2.120264   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                           0.000000  0.000000   \n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             1.609438  4.240527   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  3.218876  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    1.609438  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  1.609438  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000  2.120264   \n",
       "\n",
       "                                                       10000       105  \\\n",
       "(Sport) Joachim Löw und die Nationalelf             0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                           0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                           0.000000  0.000000   \n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.000000  3.218876   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    3.218876  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000  0.000000   \n",
       "\n",
       "                                                      109900    ...      \\\n",
       "(Sport) Joachim Löw und die Nationalelf             0.000000    ...       \n",
       "(Sport) Zweite Bundesliga                           0.000000    ...       \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000    ...       \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000    ...       \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000    ...       \n",
       "(Finanzen) Natixis im Gespräch                      0.000000    ...       \n",
       "(Motor) Blitz und Schatten                          0.000000    ...       \n",
       "(Finanzen) Bankenmarkt                              0.000000    ...       \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000    ...       \n",
       "(Motor) Tesla im Fahrtest                           0.000000    ...       \n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000    ...       \n",
       "(Finanzen) Basel IV                                 0.000000    ...       \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000    ...       \n",
       "(Motor) Deutschland sucht das Super-SUV             0.000000    ...       \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000    ...       \n",
       "(Motor) BMW setzt noch einen drauf                  3.218876    ...       \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  0.000000    ...       \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000    ...       \n",
       "(Sport) Jetzt wird Bayern nervös                    0.000000    ...       \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000    ...       \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.000000    ...       \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000    ...       \n",
       "(Apple) Konkurrenz für Netflix                      0.000000    ...       \n",
       "(Apple) Ladematte AirPower                          0.000000    ...       \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000    ...       \n",
       "\n",
       "                                                    übertragenden  \\\n",
       "(Sport) Joachim Löw und die Nationalelf                  0.000000   \n",
       "(Sport) Zweite Bundesliga                                0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus         0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...       0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses        0.000000   \n",
       "(Finanzen) Natixis im Gespräch                           0.000000   \n",
       "(Motor) Blitz und Schatten                               0.000000   \n",
       "(Finanzen) Bankenmarkt                                   0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis               0.000000   \n",
       "(Motor) Tesla im Fahrtest                                0.000000   \n",
       "(Apple) Bleibt doch noch ein bisschen                    0.000000   \n",
       "(Finanzen) Basel IV                                      0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV           0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV                  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump               0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                       0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...       0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt                    3.218876   \n",
       "(Sport) Jetzt wird Bayern nervös                         0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch                 0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...       0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune         0.000000   \n",
       "(Apple) Konkurrenz für Netflix                           0.000000   \n",
       "(Apple) Ladematte AirPower                               0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                     0.000000   \n",
       "\n",
       "                                                    übertrieben  überzeugen  \\\n",
       "(Sport) Joachim Löw und die Nationalelf                0.000000    0.000000   \n",
       "(Sport) Zweite Bundesliga                              0.000000    0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus       0.000000    0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...     0.000000    0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses      0.000000    0.000000   \n",
       "(Finanzen) Natixis im Gespräch                         0.000000    0.000000   \n",
       "(Motor) Blitz und Schatten                             0.000000    0.000000   \n",
       "(Finanzen) Bankenmarkt                                 0.000000    0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis             0.000000    0.000000   \n",
       "(Motor) Tesla im Fahrtest                              0.000000    2.120264   \n",
       "(Apple) Bleibt doch noch ein bisschen                  0.000000    2.120264   \n",
       "(Finanzen) Basel IV                                    0.000000    0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV         0.000000    0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV                0.000000    0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump             0.000000    0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                     0.000000    0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...     0.000000    0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt                  0.000000    2.120264   \n",
       "(Sport) Jetzt wird Bayern nervös                       0.000000    0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch               0.000000    0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...     3.218876    0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune       0.000000    0.000000   \n",
       "(Apple) Konkurrenz für Netflix                         0.000000    0.000000   \n",
       "(Apple) Ladematte AirPower                             0.000000    0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                   0.000000    0.000000   \n",
       "\n",
       "                                                    überzeugt      üble  \\\n",
       "(Sport) Joachim Löw und die Nationalelf              0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                            0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus     0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...   0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses    0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                       0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                           0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                               0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis           0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                            0.000000  0.000000   \n",
       "(Apple) Bleibt doch noch ein bisschen                0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                  0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV       0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV              0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump           0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                   0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...   0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt                0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                     0.000000  3.218876   \n",
       "(Politik ) Was Kim kann, kann Trump auch             0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...   2.525729  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune     0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                       0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                           2.525729  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                 0.000000  0.000000   \n",
       "\n",
       "                                                    üblicherweise     übrig  \\\n",
       "(Sport) Joachim Löw und die Nationalelf                  0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                                0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus         0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...       0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses        0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                           0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                               0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                                   0.000000  3.218876   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis               0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                                0.000000  0.000000   \n",
       "(Apple) Bleibt doch noch ein bisschen                    0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                      0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV           0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV                  0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump               0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                       0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...       0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt                    0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                         0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch                 0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...       0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune         0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                           2.525729  0.000000   \n",
       "(Apple) Ladematte AirPower                               0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                     2.525729  0.000000   \n",
       "\n",
       "                                                       üppig   üppiger  \\\n",
       "(Sport) Joachim Löw und die Nationalelf             0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                           0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          3.218876  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                           0.000000  0.000000   \n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             0.000000  3.218876   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000  0.000000   \n",
       "\n",
       "                                                            €  \n",
       "(Sport) Joachim Löw und die Nationalelf              0.000000  \n",
       "(Sport) Zweite Bundesliga                            0.000000  \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus     0.000000  \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...   0.000000  \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses    0.000000  \n",
       "(Finanzen) Natixis im Gespräch                       0.000000  \n",
       "(Motor) Blitz und Schatten                           0.000000  \n",
       "(Finanzen) Bankenmarkt                               0.000000  \n",
       "(Motor) Mittelklasse, nur nicht beim Preis           0.000000  \n",
       "(Motor) Tesla im Fahrtest                            0.000000  \n",
       "(Apple) Bleibt doch noch ein bisschen                0.000000  \n",
       "(Finanzen) Basel IV                                  0.000000  \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV       0.000000  \n",
       "(Motor) Deutschland sucht das Super-SUV              0.000000  \n",
       "(Politik ) Trump, Trump und nochmals Trump           0.000000  \n",
       "(Motor) BMW setzt noch einen drauf                   0.000000  \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...   0.000000  \n",
       "(Sport) Klopp geht all in und gewinnt                0.000000  \n",
       "(Sport) Jetzt wird Bayern nervös                     0.000000  \n",
       "(Politik ) Was Kim kann, kann Trump auch             0.000000  \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...   0.000000  \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    12.875503  \n",
       "(Apple) Konkurrenz für Netflix                       0.000000  \n",
       "(Apple) Ladematte AirPower                           0.000000  \n",
       "(Apple) Hollywood-Stars präsentieren                 0.000000  \n",
       "\n",
       "[25 rows x 4599 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Es lässt sich feststellen, welche Worte innerhalb eines Dokuments am wichtigsten sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Motor) BMW setzt noch einen drauf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>25.257286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>15.154372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>12.721581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liter</th>\n",
       "      <td>10.995489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps</th>\n",
       "      <td>9.162907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kostet</th>\n",
       "      <td>7.577186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variante</th>\n",
       "      <td>6.437752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>einstieg</th>\n",
       "      <td>6.437752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mittlere</th>\n",
       "      <td>6.437752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motoren</th>\n",
       "      <td>6.437752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          (Motor) BMW setzt noch einen drauf\n",
       "x5                                 25.257286\n",
       "x7                                 15.154372\n",
       "bmw                                12.721581\n",
       "liter                              10.995489\n",
       "ps                                  9.162907\n",
       "kostet                              7.577186\n",
       "variante                            6.437752\n",
       "einstieg                            6.437752\n",
       "mittlere                            6.437752\n",
       "motoren                             6.437752"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Isolieren eines Dokumenten-Vektors\n",
    "vektor = tfidfDF.loc[['(Motor) BMW setzt noch einen drauf']]\n",
    "\n",
    "#Transponieren des Dokumenten-Vektors\n",
    "vektorTransponiert = vektor.transpose()\n",
    "\n",
    "#Werte auf Basis ihrere Gewichtungen sortieren\n",
    "vektorSorted = vektorTransponiert.sort_values(by=['(Motor) BMW setzt noch einen drauf'], ascending=False)\n",
    "\n",
    "#Anzeigen des am höchsten gewichteten Token\n",
    "vektorSorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/Agenda/Keyword.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel: Keywordsuche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellen einer Keywordsuche\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/KeywordSearch.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "#Funktion zum Durchsuchen der Dokumente des Korpus nach dem gewünschen Wort\n",
    "\n",
    "def search_keyword(keyword, tfidfDataFrame):\n",
    "    \n",
    "    #Liste der Suchergebnisse\n",
    "    searchList = []\n",
    "    \n",
    "    #Iterieren über Dataframe mit TF-IDF Gewichtungen\n",
    "    for doc in tfidfDataFrame:\n",
    "        \n",
    "        #isolierte Betrachtung des Dokumenten Vektors\n",
    "        vec = tfidfDataFrame[doc]\n",
    "        \n",
    "        #falls das gesuchte Wort im Vektor vorhanden ist:\n",
    "        if vec.get(keyword) != 0:\n",
    "            \n",
    "            #Übernahme der zugehörigen Gewichtung im Dokument\n",
    "            tfidf_value = vec.get(keyword)\n",
    "            searchList.append([tfidf_value, doc])\n",
    "            \n",
    "    return sorted(searchList, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "#Suche nach verwandten Dokumenten\n",
    "\n",
    "def related_docs(docs, n, tfidfDataFrame):\n",
    "    \n",
    "    relatedDocs = []\n",
    "    n += 2\n",
    "    \n",
    "    #Iterieren über alle Dokumente in welchen das Suchwort gefunden wurde\n",
    "    for doc in docs:\n",
    "        \n",
    "        #Name des aktuell betrachteten Dokuments:\n",
    "        docName = doc[1]\n",
    "        \n",
    "        #Ermitteln der wichtigsten Worte im betrachteten Dokument:\n",
    "        relDocs = get_top_words(docName, n, tfidfDataFrame)\n",
    "        \n",
    "        #Ermitteln von Dokumenten, in welchen diese Worte ebenfalls eine hohe Bedeutung haben\n",
    "        topWordDocs = get_top_words_documents(docName, relDocs, tfidfDataFrame)\n",
    "        relatedDocs.append([doc[1], relDocs, topWordDocs])\n",
    "        \n",
    "    return(relatedDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "#Ermitteln der wichtigsten Worte eines Dokuments\n",
    "\n",
    "def get_top_words(document, n, tfidfDataFrame):\n",
    "    \n",
    "    topDict = {}\n",
    "    topList = []\n",
    "    \n",
    "    #Dokumenten-Vektor\n",
    "    vec = tfidfDataFrame[document]\n",
    "    \n",
    "    #Sortieren der Worte nach Gewichtungen:\n",
    "    sorted_vec = vec.sort_values(ascending=False)\n",
    "    top = sorted_vec[0:n]\n",
    "    \n",
    "    \n",
    "    for i, row in top.iteritems():\n",
    "        \n",
    "        #falls das gefundene Wort nicht dem eigentlichen Suchwort entspricht:\n",
    "        if i != keyword:\n",
    "            topList.append(i)\n",
    "            \n",
    "    #Übergabe der gewünschten Anzahl an Top-Words\n",
    "    topDict[document] = topList[0:n-2]\n",
    "    \n",
    "    #zurück zu 2\n",
    "    return(topDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "#Ermitteln verwandter Dokumente\n",
    "def get_top_words_documents(docName, relDocs, tfidfDataFrame):\n",
    "    \n",
    "    wordList = []\n",
    "    topWordDocList = []\n",
    "    wordList = relDocs.get(docName)\n",
    "    \n",
    "    #Iterieren über die Liste der wichtigsten Worte\n",
    "    for word in wordList:\n",
    "        \n",
    "        #Durchsuchen des Korpus nach Dokumenten, in welchen das gesuchte Wort ebenfalls relevant ist (5)\n",
    "        topWordDocList.append(search_top_word_documents(word, tfidfDataFrame))\n",
    "        \n",
    "    return(topWordDocList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "#Suche nach Dokumenten, welche das gesuchte Wort beinhalten\n",
    "\n",
    "def search_top_word_documents(keyword, tfidfDataFrame):\n",
    "    \n",
    "    topDocsList = []\n",
    "    docList = []\n",
    "    topWordDocuments = {}\n",
    "    \n",
    "    #erneutes Iteriere über alle Dokumente des Korpus:\n",
    "    for doc in tfidfDataFrame:\n",
    "        \n",
    "        #Dokumentenvektor\n",
    "        vec = tfidfDataFrame[doc]\n",
    "        \n",
    "        #Überprüfen, ob Wort vorhanden ist\n",
    "        if vec.get(keyword) != 0:\n",
    "            topDocsList.append(doc)\n",
    "        topWordDocuments[keyword] = topDocsList\n",
    "        \n",
    "    return(topWordDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Bitte ein Suchwort eingeben:  suv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCHBEGRIFF: suv\n",
      "Gefunden in folgenden Dokumenten:\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "RANG: 1\n",
      "DOKUMENT: (Motor) Deutschland sucht das Super-SUV\n",
      "Weitere, wichtige Begriffe in \"(Motor) Deutschland sucht das Super-SUV\":\n",
      "\"glc\", bedeutsam in: \"(Motor) Deutschland sucht das Super-SUV\"\n",
      "\"bmw\", bedeutsam in: \"(Motor) Tesla im Fahrtest\"\n",
      "\"coupé\", bedeutsam in: \"(Motor) Deutschland sucht das Super-SUV\"\n",
      "\"porsche\", bedeutsam in: \"(Motor) Deutschland sucht das Super-SUV\"\n",
      "\"mercedesbenz\", bedeutsam in: \"(Motor) Deutschland sucht das Super-SUV\"\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "RANG: 2\n",
      "DOKUMENT: (Motor) Mittelklasse, nur nicht beim Preis\n",
      "Weitere, wichtige Begriffe in \"(Motor) Mittelklasse, nur nicht beim Preis\":\n",
      "\"xc40\", bedeutsam in: \"(Motor) Mittelklasse, nur nicht beim Preis\"\n",
      "\"volvo\", bedeutsam in: \"(Motor) Mittelklasse, nur nicht beim Preis\"\n",
      "\"q3\", bedeutsam in: \"(Motor) Mittelklasse, nur nicht beim Preis\"\n",
      "\"audi\", bedeutsam in: \"(Motor) Mittelklasse, nur nicht beim Preis\"\n",
      "\"ps\", bedeutsam in: \"(Motor) Blitz und Schatten\"\n",
      "____________________________________________________________________________________________________\n",
      "\n",
      "RANG: 3\n",
      "DOKUMENT: (Motor) BMW setzt noch einen drauf\n",
      "Weitere, wichtige Begriffe in \"(Motor) BMW setzt noch einen drauf\":\n",
      "\"x5\", bedeutsam in: \"(Motor) Deutschland sucht das Super-SUV\"\n",
      "\"x7\", bedeutsam in: \"(Motor) Deutschland sucht das Super-SUV\"\n",
      "\"bmw\", bedeutsam in: \"(Motor) Tesla im Fahrtest\"\n",
      "\"liter\", bedeutsam in: \"(Motor) Blitz und Schatten\"\n",
      "\"ps\", bedeutsam in: \"(Motor) Blitz und Schatten\"\n",
      "____________________________________________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def keyword_search(keyword, tfidfDataFrame):\n",
    "    search = search_keyword(keyword, tfidfDataFrame)\n",
    "    complete = related_docs(search, 5, tfidfDataFrame)\n",
    "    return(complete)\n",
    "\n",
    "tfidfDataFrame = tfidfDF.transpose()\n",
    "\n",
    "keyword = input('Bitte ein Suchwort eingeben: ')\n",
    "result = keyword_search(keyword, tfidfDataFrame)\n",
    "\n",
    "i = 1\n",
    "\n",
    "print('SUCHBEGRIFF: ' + keyword)\n",
    "print('Gefunden in folgenden Dokumenten:')\n",
    "print('_'*100)\n",
    "print('')\n",
    "for res in result:\n",
    "    print('RANG: ' + str(i))\n",
    "    print('DOKUMENT: ' + res[0])\n",
    "    print('Weitere, wichtige Begriffe in \"' + res[0] + '\":')\n",
    "    topWords = res[1].get(res[0])\n",
    "    topDocuments = res[2]\n",
    "    for topW in topWords:\n",
    "        for topD in topDocuments:\n",
    "            if topD.get(topW) != None:\n",
    "                x = topD.get(topW)\n",
    "                print('\"' + str(topW) + '\"' + ', bedeutsam in: \"' + x[0] + '\"')\n",
    "    i+=1\n",
    "    print('_'*100)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/Agenda/Clustering.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exkurs: Clustering\n",
    "\n",
    "### -Clustering dient der Unterteilung von Daten in Gruppen ähnlicher Art\n",
    "### -die Daten innerhalb eines Clusters sollen möglichst ähnlich zueinander sein\n",
    "### -Cluster sollen zueinander möglichst unähnlich sein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ungeordnete Daten:\n",
    "<img src=\"./Grafiken/Data_Unsorted.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Gruppen, bzw. Cluster, unterteilte Daten:\n",
    "<img src=\"./Grafiken/Data_Clusterd.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Der k-Means Algorithmus\n",
    "### -einer der populärsten Clustering-Algorithmen\n",
    "### -die Anzahl der Cluster (k) wird initial festgelegt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## es werden k Zentroide als vorläufige Cluster-Mittelpunkte festeglegt:\n",
    "<img src=\"./Grafiken/Start_Centroids.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## anschließend erfolgt für jeden Datenpunkt die Berechnung der Distanzen zu den vorhandenen Zentroiden:\n",
    "<img src=\"./Grafiken/Centroid_Distances.jpg\" style=\"width:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ein Datenpunkt wird jenem Zentroid zugeordnet, zu welchem er die geringste Distanz besitzt:\n",
    "<img src=\"./Grafiken/Centroid_Assignment.jpg\" style=\"width:200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wurden alle Datenpunkte einem Zentroid zugeordnet, so werden diese auf Basis des Mittelwertes der Datenpunkte des eigenen Clusters neu verteilt:\n",
    "<img src=\"./Grafiken/Moved_Centroids.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## das Verfahren wird so oft wiederholt, bis keine Verschiebung der Zentroide mehr stattfindet\n",
    "<img src=\"./Grafiken/Final_Centroids.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/Agenda/Document-Clustering.jpg\" style=\"width:800px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel: Clustering\n",
    "\n",
    "<img src=\"./Grafiken/Clustering.jpg\" style=\"width:500px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame.from_dict(documents, orient = 'index')\n",
    "dataframe.reset_index(level=0, inplace=True)\n",
    "dataframe.columns = ['file', 'token']\n",
    "dataframe = dataframe.sort_values(by=['file'])\n",
    "dataframe = dataframe.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = get_vocabulary(stopwordsRemoved)\n",
    "bow, bowDF = bag_of_words(stopwordsRemoved, vocabulary)\n",
    "tf, tfDF = term_frequency(bow, stopwordsRemoved)\n",
    "idf = inverse_document_frequency(bow)\n",
    "tfidf, tfidfDF = term_frequency_inverse_document_frequency(bow, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>10000</th>\n",
       "      <th>105</th>\n",
       "      <th>109900</th>\n",
       "      <th>...</th>\n",
       "      <th>übertragenden</th>\n",
       "      <th>übertrieben</th>\n",
       "      <th>überzeugen</th>\n",
       "      <th>überzeugt</th>\n",
       "      <th>üble</th>\n",
       "      <th>üblicherweise</th>\n",
       "      <th>übrig</th>\n",
       "      <th>üppig</th>\n",
       "      <th>üppiger</th>\n",
       "      <th>€</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(Apple) Bleibt doch noch ein bisschen</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Hollywood-Stars präsentieren</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Konkurrenz für Netflix</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Ladematte AirPower</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Apple) Lebensrettende Massnahmen für Apple TV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Bankenmarkt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Basel IV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Die Mailänder Börse ist in Feierlaune</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.875503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Natixis im Gespräch</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Finanzen) Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) BMW setzt noch einen drauf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) Blitz und Schatten</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) Deutschland sucht das Super-SUV</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>4.240527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) Mittelklasse, nur nicht beim Preis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.665163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Motor) Tesla im Fahrtest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.665163</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Der Brandbeschleuniger im Weißen Haus</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Der Vorwurf eines unerwünschten Kusses</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Trump, Trump und nochmals Trump</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Was Kim kann, kann Trump auch</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Politik ) Weißes Haus rechnet mit Schließung der Grenze zu Mexiko</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.832581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Dramatischer Liverpool-Sieg durch spätes Eigentor</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.051457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Jetzt wird Bayern nervös</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Joachim Löw und die Nationalelf</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Klopp geht all in und gewinnt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.832581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.120264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Sport) Zweite Bundesliga</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 4599 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               00       000  \\\n",
       "(Apple) Bleibt doch noch ein bisschen               0.0  0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.0  0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.0  0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.0  0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.0  0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.0  0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.0  0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.0  0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.0  0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.0  0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.0  0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          0.0  0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             0.0  0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.0  0.000000  3.665163   \n",
       "(Motor) Tesla im Fahrtest                           0.0  0.000000  3.665163   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.0  0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.0  0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.0  0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.0  0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.0  0.000000  1.832581   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  0.0  0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    0.0  0.000000  0.000000   \n",
       "(Sport) Joachim Löw und die Nationalelf             0.0  0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.0  0.000000  1.832581   \n",
       "(Sport) Zweite Bundesliga                           0.0  3.218876  0.000000   \n",
       "\n",
       "                                                          02        03  \\\n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                           0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  5.051457  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    0.000000  0.000000   \n",
       "(Sport) Joachim Löw und die Nationalelf             2.525729  3.218876   \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                           0.000000  0.000000   \n",
       "\n",
       "                                                          10       100  \\\n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000  2.120264   \n",
       "(Apple) Konkurrenz für Netflix                      0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  1.609438  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             1.609438  4.240527   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                           0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000  2.120264   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  3.218876  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    1.609438  0.000000   \n",
       "(Sport) Joachim Löw und die Nationalelf             1.609438  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                           0.000000  0.000000   \n",
       "\n",
       "                                                       10000       105  \\\n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.000000  3.218876   \n",
       "(Motor) Blitz und Schatten                          0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                           0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    3.218876  0.000000   \n",
       "(Sport) Joachim Löw und die Nationalelf             0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                           0.000000  0.000000   \n",
       "\n",
       "                                                      109900    ...      \\\n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000    ...       \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000    ...       \n",
       "(Apple) Konkurrenz für Netflix                      0.000000    ...       \n",
       "(Apple) Ladematte AirPower                          0.000000    ...       \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000    ...       \n",
       "(Finanzen) Bankenmarkt                              0.000000    ...       \n",
       "(Finanzen) Basel IV                                 0.000000    ...       \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000    ...       \n",
       "(Finanzen) Natixis im Gespräch                      0.000000    ...       \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.000000    ...       \n",
       "(Motor) BMW setzt noch einen drauf                  3.218876    ...       \n",
       "(Motor) Blitz und Schatten                          0.000000    ...       \n",
       "(Motor) Deutschland sucht das Super-SUV             0.000000    ...       \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000    ...       \n",
       "(Motor) Tesla im Fahrtest                           0.000000    ...       \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000    ...       \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000    ...       \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000    ...       \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000    ...       \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000    ...       \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  0.000000    ...       \n",
       "(Sport) Jetzt wird Bayern nervös                    0.000000    ...       \n",
       "(Sport) Joachim Löw und die Nationalelf             0.000000    ...       \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000    ...       \n",
       "(Sport) Zweite Bundesliga                           0.000000    ...       \n",
       "\n",
       "                                                    übertragenden  \\\n",
       "(Apple) Bleibt doch noch ein bisschen                    0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                     0.000000   \n",
       "(Apple) Konkurrenz für Netflix                           0.000000   \n",
       "(Apple) Ladematte AirPower                               0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV           0.000000   \n",
       "(Finanzen) Bankenmarkt                                   0.000000   \n",
       "(Finanzen) Basel IV                                      0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune         0.000000   \n",
       "(Finanzen) Natixis im Gespräch                           0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...       0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                       0.000000   \n",
       "(Motor) Blitz und Schatten                               0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV                  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis               0.000000   \n",
       "(Motor) Tesla im Fahrtest                                0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus         0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses        0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump               0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch                 0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...       0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...       0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                         0.000000   \n",
       "(Sport) Joachim Löw und die Nationalelf                  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt                    3.218876   \n",
       "(Sport) Zweite Bundesliga                                0.000000   \n",
       "\n",
       "                                                    übertrieben  überzeugen  \\\n",
       "(Apple) Bleibt doch noch ein bisschen                  0.000000    2.120264   \n",
       "(Apple) Hollywood-Stars präsentieren                   0.000000    0.000000   \n",
       "(Apple) Konkurrenz für Netflix                         0.000000    0.000000   \n",
       "(Apple) Ladematte AirPower                             0.000000    0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV         0.000000    0.000000   \n",
       "(Finanzen) Bankenmarkt                                 0.000000    0.000000   \n",
       "(Finanzen) Basel IV                                    0.000000    0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune       0.000000    0.000000   \n",
       "(Finanzen) Natixis im Gespräch                         0.000000    0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...     3.218876    0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                     0.000000    0.000000   \n",
       "(Motor) Blitz und Schatten                             0.000000    0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV                0.000000    0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis             0.000000    0.000000   \n",
       "(Motor) Tesla im Fahrtest                              0.000000    2.120264   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus       0.000000    0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses      0.000000    0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump             0.000000    0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch               0.000000    0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...     0.000000    0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...     0.000000    0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                       0.000000    0.000000   \n",
       "(Sport) Joachim Löw und die Nationalelf                0.000000    0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt                  0.000000    2.120264   \n",
       "(Sport) Zweite Bundesliga                              0.000000    0.000000   \n",
       "\n",
       "                                                    überzeugt      üble  \\\n",
       "(Apple) Bleibt doch noch ein bisschen                0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                 0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                       0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                           2.525729  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV       0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                               0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                  0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune     0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                       0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...   2.525729  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                   0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                           0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV              0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis           0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                            0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus     0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses    0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump           0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch             0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...   0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...   0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                     0.000000  3.218876   \n",
       "(Sport) Joachim Löw und die Nationalelf              0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt                0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                            0.000000  0.000000   \n",
       "\n",
       "                                                    üblicherweise     übrig  \\\n",
       "(Apple) Bleibt doch noch ein bisschen                    0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                     2.525729  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                           2.525729  0.000000   \n",
       "(Apple) Ladematte AirPower                               0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV           0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                                   0.000000  3.218876   \n",
       "(Finanzen) Basel IV                                      0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune         0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                           0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...       0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                       0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                               0.000000  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV                  0.000000  0.000000   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis               0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                                0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus         0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses        0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump               0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch                 0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...       0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...       0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                         0.000000  0.000000   \n",
       "(Sport) Joachim Löw und die Nationalelf                  0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt                    0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                                0.000000  0.000000   \n",
       "\n",
       "                                                       üppig   üppiger  \\\n",
       "(Apple) Bleibt doch noch ein bisschen               0.000000  0.000000   \n",
       "(Apple) Hollywood-Stars präsentieren                0.000000  0.000000   \n",
       "(Apple) Konkurrenz für Netflix                      0.000000  0.000000   \n",
       "(Apple) Ladematte AirPower                          0.000000  0.000000   \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV      0.000000  0.000000   \n",
       "(Finanzen) Bankenmarkt                              0.000000  0.000000   \n",
       "(Finanzen) Basel IV                                 0.000000  0.000000   \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    0.000000  0.000000   \n",
       "(Finanzen) Natixis im Gespräch                      0.000000  0.000000   \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...  0.000000  0.000000   \n",
       "(Motor) BMW setzt noch einen drauf                  0.000000  0.000000   \n",
       "(Motor) Blitz und Schatten                          3.218876  0.000000   \n",
       "(Motor) Deutschland sucht das Super-SUV             0.000000  3.218876   \n",
       "(Motor) Mittelklasse, nur nicht beim Preis          0.000000  0.000000   \n",
       "(Motor) Tesla im Fahrtest                           0.000000  0.000000   \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus    0.000000  0.000000   \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses   0.000000  0.000000   \n",
       "(Politik ) Trump, Trump und nochmals Trump          0.000000  0.000000   \n",
       "(Politik ) Was Kim kann, kann Trump auch            0.000000  0.000000   \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...  0.000000  0.000000   \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...  0.000000  0.000000   \n",
       "(Sport) Jetzt wird Bayern nervös                    0.000000  0.000000   \n",
       "(Sport) Joachim Löw und die Nationalelf             0.000000  0.000000   \n",
       "(Sport) Klopp geht all in und gewinnt               0.000000  0.000000   \n",
       "(Sport) Zweite Bundesliga                           0.000000  0.000000   \n",
       "\n",
       "                                                            €  \n",
       "(Apple) Bleibt doch noch ein bisschen                0.000000  \n",
       "(Apple) Hollywood-Stars präsentieren                 0.000000  \n",
       "(Apple) Konkurrenz für Netflix                       0.000000  \n",
       "(Apple) Ladematte AirPower                           0.000000  \n",
       "(Apple) Lebensrettende Massnahmen für Apple TV       0.000000  \n",
       "(Finanzen) Bankenmarkt                               0.000000  \n",
       "(Finanzen) Basel IV                                  0.000000  \n",
       "(Finanzen) Die Mailänder Börse ist in Feierlaune    12.875503  \n",
       "(Finanzen) Natixis im Gespräch                       0.000000  \n",
       "(Finanzen) Schweizer Banken Die Zeiten, um an d...   0.000000  \n",
       "(Motor) BMW setzt noch einen drauf                   0.000000  \n",
       "(Motor) Blitz und Schatten                           0.000000  \n",
       "(Motor) Deutschland sucht das Super-SUV              0.000000  \n",
       "(Motor) Mittelklasse, nur nicht beim Preis           0.000000  \n",
       "(Motor) Tesla im Fahrtest                            0.000000  \n",
       "(Politik ) Der Brandbeschleuniger im Weißen Haus     0.000000  \n",
       "(Politik ) Der Vorwurf eines unerwünschten Kusses    0.000000  \n",
       "(Politik ) Trump, Trump und nochmals Trump           0.000000  \n",
       "(Politik ) Was Kim kann, kann Trump auch             0.000000  \n",
       "(Politik ) Weißes Haus rechnet mit Schließung d...   0.000000  \n",
       "(Sport) Dramatischer Liverpool-Sieg durch späte...   0.000000  \n",
       "(Sport) Jetzt wird Bayern nervös                     0.000000  \n",
       "(Sport) Joachim Löw und die Nationalelf              0.000000  \n",
       "(Sport) Klopp geht all in und gewinnt                0.000000  \n",
       "(Sport) Zweite Bundesliga                            0.000000  \n",
       "\n",
       "[25 rows x 4599 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfDF = tfidfDF.sort_index()\n",
    "tfidfDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kMeans-Clustering\n",
    "\n",
    "def kMeans_clustering(feature_matrix):\n",
    "    \n",
    "    #Import des kMeans-Objekts\n",
    "    from sklearn.cluster import KMeans\n",
    "    \n",
    "    #Festlegen der Parameter (k=5)\n",
    "    km = KMeans(n_clusters=5, max_iter=10000)\n",
    "    \n",
    "    #Übergabe des Korpus mit den TF-IDF-Gewichtungen\n",
    "    km.fit(feature_matrix.todense())\n",
    "    \n",
    "    #Übernahme der Cluster\n",
    "    clusters = km.labels_\n",
    "    \n",
    "    return km, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(tfidf_features, feature_names, dataframe):\n",
    "\n",
    "    from collections import Counter\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    #Aufruf der kMeans-Clustering Funktion\n",
    "    km_obj, clusters = kMeans_clustering(feature_matrix=tfidf_features)\n",
    "    \n",
    "    #Datframe welcher alle Clusterzugehörigkeiten enthält\n",
    "    cluster = pd.DataFrame(clusters)\n",
    "    \n",
    "    #Zuordnen der Cluster-Nummern zu einzelnen Dokumenten\n",
    "    dataframe['Cluster'] = cluster\n",
    "    \n",
    "    #Anzahl der Cluster\n",
    "    c = Counter(clusters)\n",
    "    total_clusters=len(c)\n",
    "\n",
    "    cluster_details = {}  \n",
    "    \n",
    "    ordered_centroids = km_obj.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    #Anzahl der Features, welche das jeweilige Cluster am besten beschreiben\n",
    "    topn_features=10\n",
    "\n",
    "    #Erstellen eines Dictionaries mit den Ergebnissen\n",
    "    for cluster_num in range(total_clusters):\n",
    "        cluster_details[cluster_num] = {}\n",
    "        cluster_details[cluster_num]['cluster_num'] = cluster_num\n",
    "        key_features = [feature_names[index]\n",
    "                        for index\n",
    "                        in ordered_centroids[cluster_num, :topn_features]]\n",
    "        cluster_details[cluster_num]['key_features'] = key_features\n",
    "        files = dataframe[dataframe['Cluster'] == cluster_num]['file'].values.tolist()\n",
    "        cluster_details[cluster_num]['file'] = files\n",
    "\n",
    "    #Ausgabe der Ergebnisse\n",
    "    for cluster in cluster_details:\n",
    "        print('Cluster: ' + str(cluster))\n",
    "        print(' ')\n",
    "        print('enthaltene Dokumente:')\n",
    "        print(cluster_details.get(cluster).get('file'))\n",
    "        print(' ')\n",
    "        print('Keyfeatures: ')\n",
    "        print(cluster_details.get(cluster).get('key_features'))\n",
    "        print(' ')\n",
    "        print('_'*150)\n",
    "        print('_'*150)\n",
    "        print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "#Scikit-learn erwrtet Sparse-Matrix, daher Umwandlung des Dataframes\n",
    "clustertfidfDF = scipy.sparse.csr_matrix(tfidfDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Apple) Bleibt doch noch ein bisschen', '(Apple) Lebensrettende Massnahmen für Apple TV', '(Finanzen) Basel IV', '(Finanzen) Die Mailänder Börse ist in Feierlaune', '(Finanzen) Natixis im Gespräch', '(Finanzen) Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei', '(Motor) BMW setzt noch einen drauf', '(Motor) Blitz und Schatten', '(Motor) Mittelklasse, nur nicht beim Preis', '(Politik ) Der Brandbeschleuniger im Weißen Haus', '(Politik ) Der Vorwurf eines unerwünschten Kusses', '(Politik ) Trump, Trump und nochmals Trump', '(Politik ) Was Kim kann, kann Trump auch', '(Politik ) Weißes Haus rechnet mit Schließung der Grenze zu Mexiko', '(Sport) Dramatischer Liverpool-Sieg durch spätes Eigentor', '(Sport) Jetzt wird Bayern nervös', '(Sport) Joachim Löw und die Nationalelf', '(Sport) Klopp geht all in und gewinnt ', '(Sport) Zweite Bundesliga']\n",
      " \n",
      "Keyfeatures: \n",
      "['banken', 'trump', 'liverpool', 'apple', 'löw', 'klopp', 'investmentbanking', 'fc', 'x5', 'ps']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Cluster: 1\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Finanzen) Bankenmarkt']\n",
      " \n",
      "Keyfeatures: \n",
      "['sparkassen', 'genossenschaftsbanken', 'volksbanken', 'kreditgeschäft', 'sparer', 'netzer', 'raiffeisenbanken', 'volks', 'regionalbanken', 'bayerischen']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Cluster: 2\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Motor) Tesla im Fahrtest']\n",
      " \n",
      "Keyfeatures: \n",
      "['model', '3', 'tesla', 'reichweite', 'autopilot', 'aktuell', 'kilometer', 'wagen', 'autopiloten', 'smartphone']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Cluster: 3\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Apple) Hollywood-Stars präsentieren', '(Apple) Konkurrenz für Netflix', '(Apple) Ladematte AirPower']\n",
      " \n",
      "Keyfeatures: \n",
      "['apple', 'airpower', 'konzern', 'kreditkarte', 'netflix', 'geräte', 'dienst', 'inhalte', 'montag', 'times']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Cluster: 4\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Motor) Deutschland sucht das Super-SUV']\n",
      " \n",
      "Keyfeatures: \n",
      "['glc', 'bmw', 'coupé', 'mercedesbenz', 'porsche', 'suv', 'x7', 'cayenne', 'geländewagen', 'x5']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Aufruf der Cluster-Funtkion\n",
    "clustering(clustertfidfDF, sorted(vocabulary), dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nutzung des TfidfVectorizers von Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anpassen der Stopwords Ergebnisse, da Vectorizer selber Tokenisierung vornimmt und einen String erwartet\n",
    "\n",
    "def stopwords_string(tokenized):\n",
    "    stopwords = [\"ab\",\"aber\",\"ach\",\"acht\",\"achte\",\"achten\",\"achter\",\"achtes\",\"ag\",\"alle\",\"allein\",\"allem\",\"allen\",\"aller\",\"allerdings\",\"alles\",\"allgemeinen\",\"als\",\"also\",\"am\",\"an\",\"ander\",\"andere\",\"anderem\",\"anderen\",\"anderer\",\"anderes\",\"anderm\",\"andern\",\"anderr\",\"anders\",\"au\",\"auch\",\"auf\",\"aus\",\"ausser\",\"ausserdem\",\"außer\",\"außerdem\",\"b\",\"bald\",\"bei\",\"beide\",\"beiden\",\"beim\",\"beispiel\",\"bekannt\",\"bereits\",\"besonders\",\"besser\",\"besten\",\"bin\",\"bis\",\"bisher\",\"bist\",\"c\",\"d\",\"d.h\",\"da\",\"dabei\",\"dadurch\",\"dafür\",\"dagegen\",\"daher\",\"dahin\",\"dahinter\",\"damals\",\"damit\",\"danach\",\"daneben\",\"dank\",\"dann\",\"daran\",\"darauf\",\"daraus\",\"darf\",\"darfst\",\"darin\",\"darum\",\"darunter\",\"darüber\",\"das\",\"dasein\",\"daselbst\",\"dass\",\"dasselbe\",\"davon\",\"davor\",\"dazu\",\"dazwischen\",\"daß\",\"dein\",\"deine\",\"deinem\",\"deinen\",\"deiner\",\"deines\",\"dem\",\"dementsprechend\",\"demgegenüber\",\"demgemäss\",\"demgemäß\",\"demselben\",\"demzufolge\",\"den\",\"denen\",\"denn\",\"denselben\",\"der\",\"deren\",\"derer\",\"derjenige\",\"derjenigen\",\"dermassen\",\"dermaßen\",\"derselbe\",\"derselben\",\"des\",\"deshalb\",\"desselben\",\"dessen\",\"deswegen\",\"dich\",\"die\",\"diejenige\",\"diejenigen\",\"dies\",\"diese\",\"dieselbe\",\"dieselben\",\"diesem\",\"diesen\",\"dieser\",\"dieses\",\"dir\",\"doch\",\"dort\",\"drei\",\"drin\",\"dritte\",\"dritten\",\"dritter\",\"drittes\",\"du\",\"durch\",\"durchaus\",\"durfte\",\"durften\",\"dürfen\",\"dürft\",\"e\",\"eben\",\"ebenso\",\"ehrlich\",\"ei\",\"ei,\",\"eigen\",\"eigene\",\"eigenen\",\"eigener\",\"eigenes\",\"ein\",\"einander\",\"eine\",\"einem\",\"einen\",\"einer\",\"eines\",\"einig\",\"einige\",\"einigem\",\"einigen\",\"einiger\",\"einiges\",\"einmal\",\"eins\",\"elf\",\"en\",\"ende\",\"endlich\",\"entweder\",\"er\",\"ernst\",\"erst\",\"erste\",\"ersten\",\"erster\",\"erstes\",\"es\",\"etwa\",\"etwas\",\"euch\",\"euer\",\"eure\",\"eurem\",\"euren\",\"eurer\",\"eures\",\"f\",\"folgende\",\"früher\",\"fünf\",\"fünfte\",\"fünften\",\"fünfter\",\"fünftes\",\"für\",\"g\",\"gab\",\"ganz\",\"ganze\",\"ganzen\",\"ganzer\",\"ganzes\",\"gar\",\"gedurft\",\"gegen\",\"gegenüber\",\"gehabt\",\"gehen\",\"geht\",\"gekannt\",\"gekonnt\",\"gemacht\",\"gemocht\",\"gemusst\",\"genug\",\"gerade\",\"gern\",\"gesagt\",\"geschweige\",\"gewesen\",\"gewollt\",\"geworden\",\"gibt\",\"ging\",\"gleich\",\"gott\",\"gross\",\"grosse\",\"grossen\",\"grosser\",\"grosses\",\"groß\",\"große\",\"großen\",\"großer\",\"großes\",\"gut\",\"gute\",\"guter\",\"gutes\",\"h\",\"hab\",\"habe\",\"haben\",\"habt\",\"hast\",\"hat\",\"hatte\",\"hatten\",\"hattest\",\"hattet\",\"heisst\",\"her\",\"heute\",\"hier\",\"hin\",\"hinter\",\"hoch\",\"hätte\",\"hätten\",\"i\",\"ich\",\"ihm\",\"ihn\",\"ihnen\",\"ihr\",\"ihre\",\"ihrem\",\"ihren\",\"ihrer\",\"ihres\",\"im\",\"immer\",\"in\",\"indem\",\"infolgedessen\",\"ins\",\"irgend\",\"ist\",\"j\",\"ja\",\"jahr\",\"jahre\",\"jahren\",\"je\",\"jede\",\"jedem\",\"jeden\",\"jeder\",\"jedermann\",\"jedermanns\",\"jedes\",\"jedoch\",\"jemand\",\"jemandem\",\"jemanden\",\"jene\",\"jenem\",\"jenen\",\"jener\",\"jenes\",\"jetzt\",\"k\",\"kam\",\"kann\",\"kannst\",\"kaum\",\"kein\",\"keine\",\"keinem\",\"keinen\",\"keiner\",\"keines\",\"kleine\",\"kleinen\",\"kleiner\",\"kleines\",\"kommen\",\"kommt\",\"konnte\",\"konnten\",\"kurz\",\"können\",\"könnt\",\"könnte\",\"l\",\"lang\",\"lange\",\"leicht\",\"leide\",\"lieber\",\"los\",\"m\",\"machen\",\"macht\",\"machte\",\"mag\",\"magst\",\"mahn\",\"mal\",\"man\",\"manche\",\"manchem\",\"manchen\",\"mancher\",\"manches\",\"mann\",\"mehr\",\"mein\",\"meine\",\"meinem\",\"meinen\",\"meiner\",\"meines\",\"mensch\",\"menschen\",\"mich\",\"mir\",\"mit\",\"mittel\",\"mochte\",\"mochten\",\"morgen\",\"muss\",\"musst\",\"musste\",\"mussten\",\"muß\",\"mußt\",\"möchte\",\"mögen\",\"möglich\",\"mögt\",\"müssen\",\"müsst\",\"müßt\",\"n\",\"na\",\"nach\",\"nachdem\",\"nahm\",\"natürlich\",\"neben\",\"nein\",\"neue\",\"neuen\",\"neun\",\"neunte\",\"neunten\",\"neunter\",\"neuntes\",\"nicht\",\"nichts\",\"nie\",\"niemand\",\"niemandem\",\"niemanden\",\"noch\",\"nun\",\"nur\",\"o\",\"ob\",\"oben\",\"oder\",\"offen\",\"oft\",\"ohne\",\"ordnung\",\"p\",\"q\",\"r\",\"recht\",\"rechte\",\"rechten\",\"rechter\",\"rechtes\",\"richtig\",\"rund\",\"s\",\"sa\",\"sache\",\"sagt\",\"sagte\",\"sah\",\"satt\",\"schlecht\",\"schluss\",\"schon\",\"sechs\",\"sechste\",\"sechsten\",\"sechster\",\"sechstes\",\"sehr\",\"sei\",\"seid\",\"seien\",\"sein\",\"seine\",\"seinem\",\"seinen\",\"seiner\",\"seines\",\"seit\",\"seitdem\",\"selbst\",\"sich\",\"sie\",\"sieben\",\"siebente\",\"siebenten\",\"siebenter\",\"siebentes\",\"sind\",\"so\",\"solang\",\"solche\",\"solchem\",\"solchen\",\"solcher\",\"solches\",\"soll\",\"sollen\",\"sollst\",\"sollt\",\"sollte\",\"sollten\",\"sondern\",\"sonst\",\"soweit\",\"sowie\",\"später\",\"startseite\",\"statt\",\"steht\",\"suche\",\"t\",\"tag\",\"tage\",\"tagen\",\"tat\",\"teil\",\"tel\",\"tritt\",\"trotzdem\",\"tun\",\"u\",\"uhr\",\"um\",\"und\",\"und?\",\"uns\",\"unse\",\"unsem\",\"unsen\",\"unser\",\"unsere\",\"unserer\",\"unses\",\"unter\",\"v\",\"vergangenen\",\"viel\",\"viele\",\"vielem\",\"vielen\",\"vielleicht\",\"vier\",\"vierte\",\"vierten\",\"vierter\",\"viertes\",\"vom\",\"von\",\"vor\",\"w\",\"wahr?\",\"wann\",\"war\",\"waren\",\"warst\",\"wart\",\"warum\",\"was\",\"weg\",\"wegen\",\"weil\",\"weit\",\"weiter\",\"weitere\",\"weiteren\",\"weiteres\",\"welche\",\"welchem\",\"welchen\",\"welcher\",\"welches\",\"wem\",\"wen\",\"wenig\",\"wenige\",\"weniger\",\"weniges\",\"wenigstens\",\"wenn\",\"wer\",\"werde\",\"werden\",\"werdet\",\"weshalb\",\"wessen\",\"wie\",\"wieder\",\"wieso\",\"will\",\"willst\",\"wir\",\"wird\",\"wirklich\",\"wirst\",\"wissen\",\"wo\",\"woher\",\"wohin\",\"wohl\",\"wollen\",\"wollt\",\"wollte\",\"wollten\",\"worden\",\"wurde\",\"wurden\",\"während\",\"währenddem\",\"währenddessen\",\"wäre\",\"würde\",\"würden\",\"x\",\"y\",\"z\",\"z.b\",\"zehn\",\"zehnte\",\"zehnten\",\"zehnter\",\"zehntes\",\"zeit\",\"zu\",\"zuerst\",\"zugleich\",\"zum\",\"zunächst\",\"zur\",\"zurück\",\"zusammen\",\"zwanzig\",\"zwar\",\"zwei\",\"zweite\",\"zweiten\",\"zweiter\",\"zweites\",\"zwischen\",\"zwölf\",\"über\",\"überhaupt\",\"übrigens\"]\n",
    "    \n",
    "    removed = {}\n",
    "    \n",
    "    for doc in tokenized:\n",
    "        document = tokenized.get(doc)\n",
    "        no_stopwords = [token for token in document if not token in stopwords]\n",
    "        removed[doc] = str(no_stopwords)\n",
    "    \n",
    "    return(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectorisierung mit Scikit-Learn\n",
    "\n",
    "def tfidf(corpus, ngram_range=(1,1)):\n",
    "    \n",
    "    #Import Vectorizer\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    #Festlegen von Parametern (u.A. Normierung L2)\n",
    "    vectorizer = TfidfVectorizer(min_df=1, norm='l2', smooth_idf=True, use_idf=True, ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Sport) Dramatischer Liverpool-Sieg durch spätes Eigentor', '(Sport) Jetzt wird Bayern nervös', '(Sport) Joachim Löw und die Nationalelf', '(Sport) Klopp geht all in und gewinnt ', '(Sport) Zweite Bundesliga']\n",
      " \n",
      "Keyfeatures: \n",
      "['liverpool', 'löw', 'fc', 'spiel', 'klopp', 'city', 'sieg', 'tor', 'tottenham', 'nachholspiel']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Cluster: 1\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Politik ) Der Brandbeschleuniger im Weißen Haus', '(Politik ) Der Vorwurf eines unerwünschten Kusses', '(Politik ) Trump, Trump und nochmals Trump', '(Politik ) Was Kim kann, kann Trump auch', '(Politik ) Weißes Haus rechnet mit Schließung der Grenze zu Mexiko']\n",
      " \n",
      "Keyfeatures: \n",
      "['trump', 'biden', 'präsidenten', 'flores', 'donald', 'haus', 'grenze', 'adorf', 'decker', 'horst']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Cluster: 2\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Apple) Bleibt doch noch ein bisschen', '(Apple) Hollywood-Stars präsentieren', '(Apple) Konkurrenz für Netflix', '(Apple) Ladematte AirPower', '(Apple) Lebensrettende Massnahmen für Apple TV']\n",
      " \n",
      "Keyfeatures: \n",
      "['apple', 'konzern', 'airpower', 'netflix', 'geräte', 'tv', 'inhalte', 'geräten', 'montag', 'iphone']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Cluster: 3\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Motor) BMW setzt noch einen drauf', '(Motor) Blitz und Schatten', '(Motor) Deutschland sucht das Super-SUV', '(Motor) Mittelklasse, nur nicht beim Preis', '(Motor) Tesla im Fahrtest']\n",
      " \n",
      "Keyfeatures: \n",
      "['bmw', 'x5', 'ps', 'model', 'x7', 'liter', 'euro', 'insignia', 'suv', 'coupé']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n",
      "Cluster: 4\n",
      " \n",
      "enthaltene Dokumente:\n",
      "['(Finanzen) Bankenmarkt', '(Finanzen) Basel IV', '(Finanzen) Die Mailänder Börse ist in Feierlaune', '(Finanzen) Natixis im Gespräch', '(Finanzen) Schweizer Banken Die Zeiten, um an den Finanzmärkten mutig zu sein, sind erst einmal vorbei']\n",
      " \n",
      "Keyfeatures: \n",
      "['banken', 'sparkassen', 'bank', 'investmentbanking', 'unternehmen', 'deutschland', 'vincent', 'piazza', 'mrd', 'affari']\n",
      " \n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "stopwordsString = stopwords_string(tokenized)\n",
    "\n",
    "featureDF = pd.DataFrame.from_records(stopwordsString, index=['token']).T\n",
    "\n",
    "\n",
    "#Aufruf der Vectorizer-Funktion\n",
    "tfidf_vectorizer, tfidf_features = tfidf(featureDF['token'])\n",
    "\n",
    "#Feature Names entsprechen dem Vokabular\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "#Ertsellen eines Dataframes mit den TF-IDF Gewichtungen\n",
    "scikit_learn_df = pd.DataFrame(np.round(tfidf_features.todense(), 4), columns=feature_names)\n",
    "\n",
    "#Aufruf der Clustering-Funktion\n",
    "clustering(tfidf_features, feature_names, dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warum unterscheiden sich die Ergebnisse so stark?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich der Ergebnisse der Vektorisierung:\n",
    "### Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>konzern</th>\n",
       "      <td>0.1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unternehmen</th>\n",
       "      <td>0.1551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>0.1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>0.1345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "apple        0.4032\n",
       "konzern      0.1861\n",
       "unternehmen  0.1551\n",
       "more         0.1345\n",
       "google       0.1345"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vektor = scikit_learn_df.loc[[0]]\n",
    "vektorTransponiert = vektor.transpose()\n",
    "vektorSorted = vektorTransponiert.sort_values(by=[0], ascending=False)\n",
    "vektorSorted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eigener Vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(Motor) BMW setzt noch einen drauf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>25.257286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x7</th>\n",
       "      <td>15.154372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>12.721581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liter</th>\n",
       "      <td>10.995489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps</th>\n",
       "      <td>9.162907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       (Motor) BMW setzt noch einen drauf\n",
       "x5                              25.257286\n",
       "x7                              15.154372\n",
       "bmw                             12.721581\n",
       "liter                           10.995489\n",
       "ps                               9.162907"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vektor = tfidfDF.loc[['(Motor) BMW setzt noch einen drauf']]\n",
    "vektorTransponiert = vektor.transpose()\n",
    "vektorSorted = vektorTransponiert.sort_values(by=['(Motor) BMW setzt noch einen drauf'], ascending=False)\n",
    "vektorSorted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Scikit-learn nutzt die L-2 Normalisierung (auch als Hilbertraum L2 bekannt). Daher bewegen dich die Werte zwischen 0 und 1.\n",
    "### die Summe aller quadrierten Werte eines Dokumenten-Vektors ist hierbei genau 1.\n",
    "### durch diese Art der Skalierung wird der Einfluss der Länge eines Dokuments weiter reduziert.\n",
    "### Anwendung führt also zu wesentlich besseren Ergebnissen\n",
    "\n",
    "# -> die Wahl einer passenden Vektorisierung ist also maßgeblich für die Qualität einer Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Grafiken/Agenda/Abschluss.jpg\" style=\"width:400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hier fehlt noch ein Rausschmeisser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "beispiel_tfidf, beispiel_tfidfDF = term_frequency_inverse_document_frequency(beispiel_bow, beispiel_idf)\n",
    "beispiel_tfidfDF\n",
    "value_list=beispiel_tfidfDF.values.tolist()\n",
    "taget_value = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-c65fe281a780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_tree'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = dtc.fit(value_list,taget_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beispiel_tfidf, beispiel_tfidfDF = term_frequency_inverse_document_frequency(beispiel_bow, beispiel_idf)\n",
    "beispiel_tfidfDF\n",
    "value_list=beispiel_tfidfDF.values.tolist()\n",
    "taget_value = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once trained, you can plot the tree with the plot_tree function:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plot_tree(dtc, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dictonary = {'Politik':1,'Apple':2,'Motor:':3,'Sport':4,'Finanzen':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = [4,4,1,1,1,5,4,5,3,3,2,5,2,3,1,3,4,4,4,1,5,5,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = dtc.fit(tfidfDF.values.tolist(),target_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once trained, you can plot the tree with the plot_tree function:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plot_tree(dtc, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
